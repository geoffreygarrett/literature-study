@article{Berner2007,
    abstract = {Range measurements are used to improve the trajectory models of spacecraft tracked by the deep space network. The unique challenge of deep-space ranging is that the two-way delay is long, typically many minutes, and the signal-to-noise ratio is small. Accurate measurements are made under these circumstances by means of long correlations that incorporate Doppler rate-aiding. This processing is done with commercial digital signal processors, providing a flexibility in signal design that can accommodate both the traditional sequential ranging signal and pseudonoise range codes. Accurate range determination requires the calibration of the delay within the tracking station. Measurements with a standard deviation of 1 m have been made. {\textcopyright} 2006 IEEE.},
    author = {Berner, Jeff B. and Bryant, Scott H. and Kinman, Peter W.},
    doi = {10.1109/JPROC.2007.905128},
    issn = {00189219},
    journal = {Proceedings of the IEEE},
    keywords = {Deep Space Network,Pseudonoise ranging,Range measurement,Sequential ranging},
    mendeley-groups = {Thesis Refactored},
    number = {11},
    pages = {2202--2214},
    title = {{Range measurement as practiced in the deep space network}},
    volume = {95},
    year = {2007}
}

% Izzo ellipsoidal gravitational potential 1
@article{Ivory1809,
    author = {J. Ivory.},
    journal = {Philosophical Transactions of the Royal Society of London},
    pages = {345--372},
    title = {{On the Attractions of homogeneous Ellipsoids}},
    volume = {99},
    year = {1809}
}

% Izzo ellipsoidal gravitational potential 2
@book{MacMillan1958,
    author = {W. D. MacMillan,},
    title = {{The Theory of the Potential}},
    year = {1958}
}

% Izzo ellipsoidal gravitational potential 3
@book{Danby1992,
    author = {J. Danby,},
    publisher = {Richmond: Willman-Bell},
    title = {{Fundamentals of Celestial Mechanics}},
    edition = {2},
    volume = {1},
    year = {1992}
}

%
@article{Geodesy1994,
    author = {Geodesy, Planetary},
    keywords = {gravitational potential,phobos,spherical harmonics,topography},
    mendeley-groups = {Thesis Refactored/Ellipsoidal Gravitational Potential},
    pages = {331--364},
    title = {{Balmino Gravitational Potential Harmonics from the Shape of an Homogenous Body (1994)}},
    year = {1994}
}

% MEE: THIS IS NOT THE CORRECT CITATION FOR THIS. IT IS A SUMMARY
@article{Equinoctial,
    abstract = {Modified equinoctial orbital elements},
    author = {Equinoctial, Modified and Elements, Orbital},
    pages = {1--8},
    title = {{Modified equinoctial orbital elements}},
    url = {http://www.cdeagle.com/pdf/mee.pdf}
}


%
@book{Montenbruck2000,
    abstract = {In most of the recent determinations of the geocentric gravitational coefficient (GM) of the earth, the laser ranging data to the Lageos satellite have had the greatest influence on the solution. These data, however, have generally been processed with a small but significant error in one of the range corrections. In a new determination of GM using the corrected center-of-mass offset, a value of 398600.4415 cu km/sq sec (including the mass of the atmosphere) has been obtained, with an estimated uncertainty (1 sigma of 0.0008 cu km/sq sec.},
    author = {Montenbruck, Oliver and Gill, Eberhard},
    booktitle = {Satellite Orbits},
    doi = {10.1007/978-3-642-58351-3},
    file = {:home/ggarrett/Downloads/Oliver Montenbruck, Eberhard Gill - Satellite Orbits_ Models, Methods and Applications-Springer (2005).pdf:pdf},
    isbn = {354067280X},
    mendeley-groups = {Thesis Refactored},
    title = {{Satellite Orbits}},
    year = {2000}
}

% Bellman and "Curse of dimensionality"
@book{bellman1957dynamic,
    title = {Dynamic Programming},
    author = {Bellman, R. and Rand Corporation and Karreman Mathematics Research Collection},
    isbn = {9780691079516},
    lccn = {57005444},
    series = {Rand Corporation research study},
    url = {https://books.google.co.za/books?id=wdtoPwAACAAJ},
    year = {1957},
    publisher = {Princeton University Press}
}

@book{moulton1970introduction,
    title = {An Introduction to Celestial Mechanics},
    author = {Moulton, F.R.},
    isbn = {9780486646879},
    lccn = {79103400},
    series = {Dover books in astronomy},
    url = {https://books.google.co.za/books?id=URPSrBntwdAC},
    year = {1970},
    publisher = {Dover Publications}
}

% WERTZ!
@book{wertz2002mission,
    title = {Mission Geometry; Orbit and Constellation Design and Management: Spacecraft Orbit and Attitude Systems},
    author = {Wertz, J.R.},
    isbn = {9780792371489},
    lccn = {2001054290},
    series = {Space Technology Library},
    url = {https://books.google.co.za/books?id=8VH6wAEACAAJ},
    year = {2002},
    publisher = {Springer Netherlands}
}

@book{bellman1961adaptive,
    title = {Adaptive Control Processes: A Guided Tour},
    author = {Bellman, R. and Bellman, R.E. and Karreman Mathematics Research Collection},
    isbn = {9780691079011},
    lccn = {lc60005740},
    series = {Princeton Legacy Library},
    url = {https://books.google.co.za/books?id=POAmAAAAMAAJ},
    year = {1961},
    publisher = {Princeton University Press}
}


% RL PSACECRAFT GUIDANCE CUBES
@article{Hovell2021,
    doi = {10.2514/1.a34838},
    url = {https://doi.org/10.2514/1.a34838},
    year = {2021},
    month = mar,
    publisher = {American Institute of Aeronautics and Astronautics ({AIAA})},
    volume = {58},
    number = {2},
    pages = {254--264},
    author = {Kirk Hovell and Steve Ulrich},
    title = {Deep Reinforcement Learning for Spacecraft Proximity Operations Guidance},
    journal = {Journal of Spacecraft and Rockets}
}

@book{Dirkx2015,
    abstract = {Measurements of the motion of natural (and artificial) bodies in the solar system provide key input on their interior structre and properties. Currently, the most accurate measurements of solar system dynamics are performed using radiometric tracking systems on planetary missions, providing range measurement with an accuracy in the order of 1 m. Laser ranging to Earth-orbiting satellites equipped with laser retroreflectors provides range data with (sub-)cm accuracy. Extending this technology to planetary missions, however, requires the use of an active space segment equipped with a laser detector and transmitter (for a two-way system). The feasibility of such measurements have been demonstrated at planetary distances, and used operationally (with a one-way system) for the Lunar Reconaissance Orbiter (LRO) mission. The topic of this dissertation is the analysis of the application of interplanetary laser ranging (ILR) to improve the science return from next-generation space missions, with a focus on planetary science objectives. We have simulated laser ranging data for a variety of mission and system architectures, analyzing the influence of both model and measurement uncertainties. Our simulations show that the single-shot measurement precision is relatively inconsequential compared to the systematic range errors, providing a strong rationale for the consistent use of single-photon signal-intensity operation. We find that great advances in planetary geodesy (tidal, rotational characteristics, etc.) could be achieved by ILR. However, the laser data should be accompanied by commensurate improvements in other measurements and data analysis models to maximize the system's science return. The science return from laser ranging data will be especially strong for planetary landers, with a radio system remaining the preferred choice for many orbiter missions. Furthermore, we conclude that the science case for a one-way laser ranging is relatively weak compared to next-generation radiometric tracking systems, requiring the development of much more accurate space-based clocks.},
    author = {Dirkx, D.},
    isbn = {9789462991927},
    mendeley-groups = {Thesis Refactored/Estimation},
    title = {{Interplanetary Laser Ranging}},
    url = {https://repository.tudelft.nl/islandora/object/uuid:bd728e02-f403-4cea-9e2b-65b04b47b3f7?collection=research},
    year = {2015}
}


% Izzo RL Spacecarft
@article{Willis2016,
    abstract = {We use neural reinforcement learning to control a spacecraft around a small celestial body whose gravity field is unknown. The small body is assumed to be a triaxial ellipsoid and its density and dimensions are left unknown within large bounds. We experiment with different proprioceptive capabilities of the spacecraft emphasising lightweight neuromorphic systems for optic flow detection. We find that even in such a highly uncertain environment and using limited perception capabilities, our approach is able to deliver a control strategy able to hover above the asteroid surface with small residual drift.},
    author = {Willis, Stefan and Izzo, Dario and Hennes, Daniel},
    file = {:home/ggarrett/Downloads/ACT-RPR-MAD-2016-NAPA-HoveringOnSmallBodies.pdf:pdf},
    isbn = {9780877036333},
    issn = {00653438},
    journal = {Advances in the Astronautical Sciences},
    mendeley-groups = {Master Thesis/Similar,Master Thesis/Izzo,Thesis Refactored},
    pages = {1351--1368},
    title = {{Reinforcement learning for spacecraft maneuvering near small bodies}},
    volume = {158},
    year = {2016}
}

% Numerical computation of ellipsoid integrals
@article{Johansson2019,
    abstract = {We describe algorithms to compute elliptic functions and their relatives (Jacobi theta functions, modular forms, elliptic integrals, and the arithmetic-geometric mean) numerically to arbitrary precision with rigorous error bounds for arbitrary complex variables. Implementations in ball arithmetic are available in the open source Arb library. We discuss the algorithms from a concrete implementation point of view, with focus on performance at tens to thousands of digits of precision.},
    archivePrefix = {arXiv},
    arxivId = {1806.06725},
    author = {Johansson, Fredrik},
    doi = {10.1007/978-3-030-04480-0_12},
    eprint = {1806.06725},
    file = {:home/ggarrett/Downloads/1806.06725.pdf:pdf},
    mendeley-groups = {Thesis Refactored/Ellipsoidal Gravitational Potential/Numerical Mathematics},
    pages = {269--293},
    title = {{Numerical Evaluation of Elliptic Functions, Elliptic Integrals and Modular Forms}},
    year = {2019}
}

% Computer vision vs DL.
@article{Mahony-et-al-2020,
    title = {Advances in Computer Vision},
    authors = {Niall O' Mahony, Sean Campbell, Anderson Carvalho, Suman
 Harapanahalli, Gustavo Velasco-Hernandez, Lenka Krpalkova, Daniel Riordan,
 Joseph Walsh },
    ISBN = {9783030177959},
    ISSN = {2194-5365},
    url = {http://dx.doi.org/10.1007/978-3-030-17795-9},
    DOI = {10.1007/978-3-030-17795-9},
    journal = {Advances in Intelligent Systems and Computing},
    publisher = {Springer International Publishing},
    year = {2020}
}


% machine learning: coin
@ARTICLE{5392560,

    author = {Samuel, A. L.},

    journal = {IBM Journal of Research and Development},

    title = {Some Studies in Machine Learning Using the Game of Checkers},

    year = {1959},

    volume = {3},

    number = {3},

    pages = {210-229},

    doi = {10.1147/rd.33.0210} }

% deep learning: coin
@inproceedings{Rina1986,
    author = {Dechter, Rina},
    year = {1986},
    month = {01},
    pages = {178-185},
    title = {Learning While Searching in Constraint-Satisfaction-Problems.},
    journal = {AAAI}
}

% ai boom
@misc{hardy_2016, title = {Reasons to Believe the A.I. Boom Is Real}, url = {https://www.nytimes.com/2016/07/19/technology/reasons-to-believe-the-ai-boom-is-real.html}, journal = {The New York Times}, publisher = {The New York Times}, author = {Hardy, Quentin}, year = {2016}, month = {Jul} }


% the explosion of DL
@INPROCEEDINGS{5206848,

    author = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},

    booktitle = {2009 IEEE Conference on Computer Vision and Pattern Recognition},

    title = {ImageNet: A large-scale hierarchical image database},

    year = {2009},

    %    volume = {},
    %
    %    number = {},

    pages = {248-255},

    doi = {10.1109/CVPR.2009.5206848} }


% Machine Learning
@book{Mitchell97,
    abstract = {This book covers the field of machine learning, which is the study of algorithms that allow computer programs to automatically improve through experience. This exciting addition to the McGraw-Hill Series in Computer Science focuses on the concepts and techniques that contribute to the rapidly changing field of machine learning---including probability and statistics, artificial intelligence, and neural networks---unifying them all in a logical and coherent manner.},
    added-at = {2017-05-08T14:37:30.000+0200},
    address = {New York},
    author = {Mitchell, Tom M.},
    biburl = {https://www.bibsonomy.org/bibtex/23e79734ee1a6e49aee02ffd108224d1c/flint63},
    file = {eBook:1900-99/Mitchell97.pdf:PDF;McGraw-Hill Product page:http\://www.mhprofessional.com/product.php?isbn=0070428077:URL;Amazon Search inside:http\://www.amazon.de/gp/reader/0070428077/:URL},
    groups = {public},
    interhash = {479a66c32badb3a455fbdcf8e6633a5d},
    intrahash = {3e79734ee1a6e49aee02ffd108224d1c},
    isbn = {978-0-07-042807-2},
    keywords = {01624 105 book shelf ai learn algorithm},
    publisher = {McGraw-Hill},
    timestamp = {2017-07-13T17:10:10.000+0200},
    title = {Machine Learning},
    username = {flint63},
    year = 1997,
}

@book{Mitchell97LearningAlgorithm,
    abstract = {This book covers the field of machine learning, which is the study of algorithms that allow computer programs to automatically improve through experience. This exciting addition to the McGraw-Hill Series in Computer Science focuses on the concepts and techniques that contribute to the rapidly changing field of machine learning---including probability and statistics, artificial intelligence, and neural networks---unifying them all in a logical and coherent manner.},
    added-at = {2017-05-08T14:37:30.000+0200},
    address = {New York},
    author = {Mitchell, Tom M.},
    biburl = {https://www.bibsonomy.org/bibtex/23e79734ee1a6e49aee02ffd108224d1c/flint63},
    file = {eBook:1900-99/Mitchell97.pdf:PDF;McGraw-Hill Product page:http\://www.mhprofessional.com/product.php?isbn=0070428077:URL;Amazon Search inside:http\://www.amazon.de/gp/reader/0070428077/:URL},
    groups = {public},
    interhash = {479a66c32badb3a455fbdcf8e6633a5d},
    intrahash = {3e79734ee1a6e49aee02ffd108224d1c},
    isbn = {978-0-07-042807-2},
    keywords = {01624 105 book shelf ai learn algorithm},
    publisher = {McGraw-Hill},
    timestamp = {2017-07-13T17:10:10.000+0200},
    title = {Machine Learning},
    username = {flint63},
    year = 1997,
    pages = {97},
}

@book{Goodfellow-et-al-2016,
    title = {Deep Learning},
    author = {Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher = {MIT Press},
    note = {\url{http://www.deeplearningbook.org}},
    year = {2016}
}

@article{Taeihagh2019,
    abstract = {The benefits of autonomous vehicles (AVs) are widely acknowledged, but there are concerns about the extent of these benefits and AV risks and unintended consequences. In this article, we first examine AVs and different categories of the technological risks associated with them. We then explore strategies that can be adopted to address these risks, and explore emerging responses by governments for addressing AV risks. Our analyses reveal that, thus far, governments have in most instances avoided stringent measures in order to promote AV developments and the majority of responses are non-binding and focus on creating councils or working groups to better explore AV implications. The US has been active in introducing legislations to address issues related to privacy and cybersecurity. The UK and Germany, in particular, have enacted laws to address liability issues; other countries mostly acknowledge these issues, but have yet to implement specific strategies. To address privacy and cybersecurity risks strategies ranging from introduction or amendment of non-AV specific legislation to creating working groups have been adopted. Much less attention has been paid to issues such as environmental and employment risks, although a few governments have begun programmes to retrain workers who might be negatively affected.},
    author = {Taeihagh, Araz and Lim, Hazel Si Min},
    doi = {10.1080/01441647.2018.1494640},
    file = {:home/ggarrett/Downloads/1807.05720.pdf:pdf},
    issn = {14645327},
    journal = {Transport Reviews},
    keywords = {Autonomous vehicles,automated driving,cybersecurity,governance,incumbent industries,liability,policy,privacy,risks,safety},
    mendeley-groups = {Thesis Refactored/Machine Learning/Autonomous Vehicles},
    number = {1},
    pages = {103--128},
    title = {{Governing autonomous vehicles: emerging responses for safety, liability, privacy, cybersecurity, and industry risks}},
    volume = {39},
    year = {2019}
}


% perceptron origin
@Techreport{Rosenblatt_1957_6098,
    author = {Rosenblatt, F.},
    address = {Ithaca, New York},
    institution = {Cornell Aeronautical Laboratory},
    month = {January},
    number = {85-460-1},
    title = {The perceptron - A perceiving and recognizing automaton},
    year = {1957},
    title_with_no_special_chars = {The Perceptron A perceiving and recognizing automaton}
}

% origin of perceptron
@article{doi:10.1177/030631296026003005,
    author = {Mikel Olazaran},
    title = {A Sociological Study of the Official History of the Perceptrons Controversy},
    journal = {Social Studies of Science},
    volume = {26},
    number = {3},
    pages = {611-659},
    year = {1996},
    doi = {10.1177/030631296026003005},
    URL = {https://doi.org/10.1177/030631296026003005},
    eprint = {https://doi.org/10.1177/030631296026003005},
    abstract = { In this paper, I analyze the controversy within Artificial Intelligence (AI) which surrounded the `perceptron' project (and neural nets in general) in the late 1950s and early 1960s. I devote particular attention to the proofs and arguments of Minsky and Papert, which were interpreted as showing that further progress in neural nets was not possible, and that this approach to AI had to be abandoned. I maintain that this official interpretation of the debate was a result of the emergence, institutionalization and (importantly) legitimation of the symbolic AI approach (with its resource allocation system and authority structure). At the `research-area' level, there was considerable interpretative flexibility. This interpretative flexibility was further demonstrated by the revival of neural nets in the late 1980s, and subsequent rewriting of the official history of the debate. }
}

% criticism of perceptrons
@book{minsky69perceptrons,
    added-at = {2008-05-16T13:57:01.000+0200},
    address = {Cambridge, MA, USA},
    author = {Minsky, Marvin and Papert, Seymour},
}

% supervised: Dimensionality Reduction
@misc{vogelstein2021supervised,
    title = {Supervised Dimensionality Reduction for Big Data},
    author = {Joshua T. Vogelstein and Eric Bridgeford and Minh Tang and Da Zheng and Christopher Douville and Randal Burns and Mauro Maggioni},
    year = {2021},
    eprint = {1709.01233},
    archivePrefix = {arXiv},
    primaryClass = {stat.ML}
}

% unsupervised learning
@incollection{barlow1999ul,
    added-at = {2008-09-26T11:17:56.000+0200},
    author = {Barlow, H B},
    biburl = {https://www.bibsonomy.org/bibtex/22284e571c9a95e9e81776c58fc3b1dc9/yish},
    booktitle = {Unsupervised Learning: Foundations of Neural Computation},
    editor = {Hinton, Geoffrey E. and Sejnowski, Terrence Joseph},
    interhash = {5e64abe200a2085f210bc836aa8cc6b1},
    intrahash = {2284e571c9a95e9e81776c58fc3b1dc9},
    keywords = {algorithmic computational learning machine unsupervised wleformativeeassessment},
    pages = {1-17},
    publisher = {Bradford Company Scituate, MA, USA},
    timestamp = {2008-09-26T11:18:38.000+0200},
    title = {Unsupervised learning: introduction},
    url = {http://books.google.com/books?id=yj04Y0lje4cC},
    year = 1999
}




% semi-supervised
@book{books/mit/06/CSZ2006,
    added-at = {2019-07-22T00:00:00.000+0200},
    biburl = {https://www.bibsonomy.org/bibtex/265ac136f8b3a44d77fcf9ec42829296a/dblp},
    editor = {Chapelle, Olivier and Schölkopf, Bernhard and Zien, Alexander},
    ee = {https://doi.org/10.7551/mitpress/9780262033589.001.0001},
    interhash = {90eecf83da2790cac977f375160081fe},
    intrahash = {65ac136f8b3a44d77fcf9ec42829296a},
    isbn = {9780262033589},
    keywords = {dblp},
    publisher = {The MIT Press},
    timestamp = {2019-09-17T12:36:24.000+0200},
    title = {Semi-Supervised Learning},
    url = {http://dblp.uni-trier.de/db/books/collections/CSZ2006.html},
    year = 2006
}

% semi-supervised anomaly detection.
@article{DBLP:journals/corr/abs-1805-06725,
    author = {Samet Akcay and
 Amir Atapour Abarghouei and
 Toby P. Breckon},
    title = {GANomaly: Semi-Supervised Anomaly Detection via Adversarial Training},
    journal = {CoRR},
    volume = {abs/1805.06725},
    year = {2018},
    url = {http://arxiv.org/abs/1805.06725},
    eprinttype = {arXiv},
    eprint = {1805.06725},
    timestamp = {Mon, 13 Aug 2018 16:46:23 +0200},
    biburl = {https://dblp.org/rec/journals/corr/abs-1805-06725.bib},
    bibsource = {dblp computer science bibliography, https://dblp.org}
}

% semi-supervised clustering
@article{Bair2013,
    title = {Semi-supervised clustering methods},
    volume = {5},
    ISSN = {1939-5108},
    url = {http://dx.doi.org/10.1002/wics.1270},
    DOI = {10.1002/wics.1270},
    number = {5},
    journal = {Wiley Interdisciplinary Reviews: Computational Statistics},
    publisher = {Wiley},
    author = {Bair, Eric},
    year = {2013},
    month = {Jul},
    pages = {349–361}
}

% semi-supervised: dimensionality reduciton
@inproceedings{Zhang2007,
    author = {Zhang, Daoqiang and Zhou, Zhi-Hua and Chen, Songcan},
    year = {2007},
    month = {04},
    %    pages = {},
    title = {Semi-Supervised Dimensionality Reduction},
    journal = {SIAM Data Mining},
    doi = {10.1137/1.9781611972771.73}
}

% example of structures parsing task:
@InProceedings{pmlr-v15-collobert11a,
    title = {Deep Learning for Efficient Discriminative Parsing},
    author = {Collobert, Ronan},
    booktitle = {Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
    pages = {224--232},
    year = {2011},
    editor = {Gordon, Geoffrey and Dunson, David and Dudík, Miroslav},
    volume = {15},
    series = {Proceedings of Machine Learning Research},
    address = {Fort Lauderdale, FL, USA},
    month = {11--13 Apr},
    publisher = {PMLR},
    pdf = {http://proceedings.mlr.press/v15/collobert11a/collobert11a.pdf},
    url = {https://proceedings.mlr.press/v15/collobert11a.html},
    abstract = {We propose a new fast purely discriminative algorithm for natural language parsing, based on a “deep” recurrent convolutional graph transformer network (GTN). Assuming a decomposition of a parse tree into a stack of “levels”, the network predicts a level of the tree taking into account predictions of previous levels. Using only few basic text features, we show similar performance (in F1 score) to existing pure discriminative parsers and existing “benchmark” parsers (like Collins parser, probabilistic context-free grammars based), with a huge speed advantage. [pdf][supplementary]}
}

% aviation anomaly detection
@Article{Basora2019,
    AUTHOR = {Basora, Luis and Olive, Xavier and Dubot, Thomas},
    TITLE = {Recent Advances in Anomaly Detection Methods Applied to Aviation},
    JOURNAL = {Aerospace},
    VOLUME = {6},
    YEAR = {2019},
    NUMBER = {11},
    ARTICLE-NUMBER = {117},
    URL = {https://www.mdpi.com/2226-4310/6/11/117},
    ISSN = {2226-4310},
    ABSTRACT = {Anomaly detection is an active area of research with numerous methods and applications. This survey reviews the state-of-the-art of data-driven anomaly detection techniques and their application to the aviation domain. After a brief introduction to the main traditional data-driven methods for anomaly detection, we review the recent advances in the area of neural networks, deep learning and temporal-logic based learning. In particular, we cover unsupervised techniques applicable to time series data because of their relevance to the aviation domain, where the lack of labeled data is the most usual case, and the nature of flight trajectories and sensor data is sequential, or temporal. The advantages and disadvantages of each method are presented in terms of computational efficiency and detection efficacy. The second part of the survey explores the application of anomaly detection techniques to aviation and their contributions to the improvement of the safety and performance of flight operations and aviation systems. As far as we know, some of the presented methods have not yet found an application in the aviation domain. We review applications ranging from the identification of significant operational events in air traffic operations to the prediction of potential aviation system failures for predictive maintenance.},
    DOI = {10.3390/aerospace6110117}
}

@INPROCEEDINGS{Janakiraman2016,
    author = {Janakiraman, Vijay Manikandan and Nielsen, David},
    booktitle = {2016 International Joint Conference on Neural Networks (IJCNN)},
    title = {Anomaly detection in aviation data using extreme learning machines},
    year = {2016},
    volume = {},
    number = {},
    pages = {1993-2000},
    doi = {10.1109/IJCNN.2016.7727444} }

% GPT-3 synthesis examples
@article{DBLP:journals/corr/abs-2005-14165,
    author = {Tom B. Brown and
 Benjamin Mann and
 Nick Ryder and
 Melanie Subbiah and
 Jared Kaplan and
 Prafulla Dhariwal and
 Arvind Neelakantan and
 Pranav Shyam and
 Girish Sastry and
 Amanda Askell and
 Sandhini Agarwal and
 Ariel Herbert{-}Voss and
 Gretchen Krueger and
 Tom Henighan and
 Rewon Child and
 Aditya Ramesh and
 Daniel M. Ziegler and
 Jeffrey Wu and
 Clemens Winter and
 Christopher Hesse and
 Mark Chen and
 Eric Sigler and
 Mateusz Litwin and
 Scott Gray and
 Benjamin Chess and
 Jack Clark and
 Christopher Berner and
 Sam McCandlish and
 Alec Radford and
 Ilya Sutskever and
 Dario Amodei},
    title = {Language Models are Few-Shot Learners},
    journal = {CoRR},
    volume = {abs/2005.14165},
    year = {2020},
    url = {https://arxiv.org/abs/2005.14165},
    eprinttype = {arXiv},
    eprint = {2005.14165},
    timestamp = {Wed, 03 Jun 2020 11:36:54 +0200},
    biburl = {https://dblp.org/rec/journals/corr/abs-2005-14165.bib},
    bibsource = {dblp computer science bibliography, https://dblp.org}
}

% credit card fraud
@article{DBLP:journals/corr/abs-2108-10005,
    author = {Pooja Tiwari and
 Simran Mehta and
 Nishtha Sakhuja and
 Jitendra Kumar and
 Ashutosh Kumar Singh},
    title = {Credit Card Fraud Detection using Machine Learning: {A} Study},
    journal = {CoRR},
    volume = {abs/2108.10005},
    year = {2021},
    url = {https://arxiv.org/abs/2108.10005},
    eprinttype = {arXiv},
    eprint = {2108.10005},
    timestamp = {Fri, 27 Aug 2021 15:02:29 +0200},
    biburl = {https://dblp.org/rec/journals/corr/abs-2108-10005.bib},
    bibsource = {dblp computer science bibliography, https://dblp.org}
}
% imputation of missing values: machine learning
@Article{Emmanuel2021,
    author = {Emmanuel, Tlamelo
 and Maupong, Thabiso
 and Mpoeleng, Dimane
 and Semong, Thabo
 and Mphago, Banyatsang
 and Tabona, Oteng},
    title = {A survey on missing data in machine learning},
    journal = {Journal of Big Data},
    year = {2021},
    month = {Oct},
    day = {27},
    volume = {8},
    number = {1},
    pages = {140},
    abstract = {Machine learning has been the corner stone in analysing and extracting information from data and often a problem of missing values is encountered. Missing values occur because of various factors like missing completely at random, missing at random or missing not at random. All these may result from system malfunction during data collection or human error during data pre-processing. Nevertheless, it is important to deal with missing values before analysing data since ignoring or omitting missing values may result in biased or misinformed analysis. In literature there have been several proposals for handling missing values. In this paper, we aggregate some of the literature on missing data particularly focusing on machine learning techniques. We also give insight on how the machine learning approaches work by highlighting the key features of missing values imputation techniques, how they perform, their limitations and the kind of data they are most suitable for. We propose and evaluate two methods, the k nearest neighbor and an iterative imputation method (missForest) based on the random forest algorithm. Evaluation is performed on the Iris and novel power plant fan data with induced missing values at missingness rate of 5{\%} to 20{\%}. We show that both missForest and the k nearest neighbor can successfully handle missing values and offer some possible future research direction.},
    issn = {2196-1115},
    doi = {10.1186/s40537-021-00516-9},
    url = {https://doi.org/10.1186/s40537-021-00516-9}
}

% no free lunch theorem  : https://machinelearningmastery.com/no-free-lunch-theorem-for-machine-learning/
@ARTICLE{585893,
    author = {Wolpert, D.H. and Macready, W.G.},
    journal = {IEEE Transactions on Evolutionary Computation},
    title = {No free lunch theorems for optimization},
    year = {1997},
    volume = {1},
    number = {1},
    pages = {67-82},
    doi = {10.1109/4235.585893} }

% no free lunch theorem  : https://machinelearningmastery.com/no-free-lunch-theorem-for-machine-learning/
@book{luke2012essentials,
    title = {Essentials of Metaheuristics (Second Edition)},
    author = {Luke, S.},
    isbn = {9781300549628},
    url = {https://books.google.co.za/books?id=5FDdsgEACAAJ},
    year = {2012},
    publisher = {Lulu.com}
}

@incollection{Wolpert2002,
    doi = {10.1007/978-1-4471-0123-9_3},
    url = {https://doi.org/10.1007/978-1-4471-0123-9_3},
    year = {2002},
    publisher = {Springer London},
    pages = {25--42},
    author = {David H. Wolpert},
    title = {The Supervised Learning No-Free-Lunch Theorems},
    booktitle = {Soft Computing and Industry}
}

% imputation of missing frames from a video
@article{huang2020rife,
    title = {RIFE: Real-Time Intermediate Flow Estimation for Video Frame Interpolation},
    author = {Huang, Zhewei and Zhang, Tianyuan and Heng, Wen and Shi, Boxin and Zhou, Shuchang},
    journal = {arXiv preprint arXiv:2011.06294},
    year = {2020}
}

@report{Wolpert1997,
    abstract = {A framework is developed to explore the connection between effective optimization algorithms and the problems they are solving. A number of "no free lunch" (NFL) theorems are presented which establish that for any algorithm, any elevated performance over one class of problems is offset by performance over another class. These theorems result in a geometric interpretation of what it means for an algorithm to be well suited to an optimization problem. Applications of the NFL theorems to information-theoretic aspects of optimization and benchmark measures of performance are also presented. Other issues addressed include time-varying optimization problems and a priori "head-to-head" minimax distinctions between optimization algorithms, distinctions that result despite the NFL theorems' enforcing of a type of uniformity over all algorithms.},
    author = {David H Wolpert and William G Macready},
    issue = {1},
    journal = {IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION},
    keywords = {Index Terms-Evolutionary algorithms,information theory,optimization},
    pages = {67},
    title = {No Free Lunch Theorems for Optimization},
    volume = {1},
    year = {1997},
}

@book{Domingos15,
    abstract = {Society is changing, one learning algorithm at a time, from search engines to online dating, personalized medicine to predicting the stock market. But learning algorithms are not just about Big Data - these algorithms take raw data and make it useful by creating more algorithms. This is something new under the sun: a technology that builds itself. In this book, Domingos reveals how machine learning is remaking business, politics, science and war. And he takes us on an awe-inspiring quest to find 'The Master Algorithm' - a universal learner capable of deriving all knowledge from data.},
    added-at = {2018-04-15T13:17:55.000+0200},
    address = {New York},
    author = {Domingos, Pedro},
    biburl = {https://www.bibsonomy.org/bibtex/2b48e9f824f83e98a132511b244ed8ad0/flint63},
    file = {eBook:2015/Domingos15.pdf:PDF;Basic Books Product Page:https\://www.basicbooks.com/titles/pedro-domingos/the-master-algorithm/9780465065707/:URL;Penguin Books Paperback:https\://www.penguin.co.uk/books/269590/the-master-algorithm/:URL;Amazon Search inside:http\://www.amazon.de/gp/reader/0465065708/:URL},
    groups = {public},
    interhash = {3d8bc19852ad9cab7580e2e00322a9c2},
    intrahash = {b48e9f824f83e98a132511b244ed8ad0},
    isbn = {978-0-465-06570-7},
    keywords = {01801 105 book shelf numerical ai science economy data information knowledge processing learn algorithm zzz.big},
    publisher = {Basic Books},
    timestamp = {2018-04-16T11:32:18.000+0200},
    title = {The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World},
    username = {flint63},
    year = 2015
}
@book{hastie2009elements,
    title = {The Elements of Statistical Learning: Data Mining, Inference, and Prediction},
    author = {Hastie, T. and Tibshirani, R. and Friedman, J.H.},
    isbn = {9780387848846},
    lccn = {2008941148},
    series = {Springer series in statistics},
    url = {https://books.google.co.za/books?id=eBSgoAEACAAJ},
    year = {2009},
    publisher = {Springer}
}

% regularization can improve generalization
@inproceedings{NIPS1991_8eefcfdf,
    author = {Krogh, Anders and Hertz, John},
    booktitle = {Advances in Neural Information Processing Systems},
    editor = {J. Moody and S. Hanson and R. P. Lippmann},
    pages = {},
    publisher = {Morgan-Kaufmann},
    title = {A Simple Weight Decay Can Improve Generalization},
    url = {https://proceedings.neurips.cc/paper/1991/file/8eefcfdf5990e441f0fb6f3fad709e21-Paper.pdf},
    volume = {4},
    year = {1992}
}

% elastic net penality
@ARTICLE{ZouHastie2005,
    title = {Regularization and variable selection via the elastic net},
    author = {Zou, Hui and Hastie, Trevor},
    year = {2005},
    journal = {Journal of the Royal Statistical Society Series B},
    volume = {67},
    number = {2},
    pages = {301-320},
    abstract = {Summary. We propose the elastic net, a new regularization and variable selection method. Real world data and a simulation study show that the elastic net often outperforms the lasso, while enjoying a similar sparsity of representation. In addition, the elastic net encourages a grouping effect, where strongly correlated predictors tend to be in or out of the model together. The elastic net is particularly useful when the number of predictors (p) is much bigger than the number of observations (n). By contrast, the lasso is not a very satisfactory variable selection method in the p≫n case. An algorithm called LARS‐EN is proposed for computing elastic net regularization paths efficiently, much like algorithm LARS does for the lasso.},
    url = {https://EconPapers.repec.org/RePEc:bla:jorssb:v:67:y:2005:i:2:p:301-320}
}

% cross validation
@Inbook{Refaeilzadeh2009,
    author = "Refaeilzadeh, Payam
              and Tang, Lei
              and Liu, Huan",
    editor = "LIU, LING
              and {\"O}ZSU, M. TAMER",
    title = "Cross-Validation",
    bookTitle = "Encyclopedia of Database Systems",
    year = "2009",
    publisher = "Springer US",
    address = "Boston, MA",
    pages = "532--538",
    isbn = "978-0-387-39940-9",
    doi = "10.1007/978-0-387-39940-9_565",
    url = "https://doi.org/10.1007/978-0-387-39940-9_565"
}


%https://towardsdatascience.com/regularization-in-machine-learning-76441ddcf99a
%https://towardsdatascience.com/l1-and-l2-regularization-methods-ce25e7fc831c