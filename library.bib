@article{Berner2007,
  title           = {{Range measurement as practiced in the deep space network}},
  author          = {Berner, Jeff B. and Bryant, Scott H. and Kinman, Peter W.},
  year            = 2007,
  journal         = {Proceedings of the IEEE},
  volume          = 95,
  number          = 11,
  pages           = {2202--2214},
  doi             = {10.1109/JPROC.2007.905128},
  issn            = {00189219},
  abstract        = {Range measurements are used to improve the trajectory models of spacecraft tracked by the deep space network. The unique challenge of deep-space ranging is that the two-way delay is long, typically many minutes, and the signal-to-noise ratio is small. Accurate measurements are made under these circumstances by means of long correlations that incorporate Doppler rate-aiding. This processing is done with commercial digital signal processors, providing a flexibility in signal design that can accommodate both the traditional sequential ranging signal and pseudonoise range codes. Accurate range determination requires the calibration of the delay within the tracking station. Measurements with a standard deviation of 1 m have been made. {\textcopyright} 2006 IEEE.},
  keywords        = {Deep Space Network,Pseudonoise ranging,Range measurement,Sequential ranging},
  mendeley-groups = {Thesis Refactored}
}
@article{Patera2001,
   abstract = {A method of calculating the collision probability between two orbiting objects given the respective state vectors and error covariance matrices is developed. The methodology is valid for the general case and does not require simplifying assumptions. It is computationally efficient and applicable to satellites of irregular shape. Analytical techniques are used to reduce the problem to that of integrating a two-dimensional symmetric probability density over a region representing the combined hard body of the colliding objects. The symmetric form of the probability density enables the two-dimensional integral to be reduced to a one-dimensional path integral that permits easy numerical implementation and reduces computational effort. Test case results are in good agreement with those generated by other collision probability tools.},
   author = {R. P. Patera},
   doi = {10.2514/2.4771},
   issn = {15333884},
   issue = {4},
   journal = {Journal of Guidance, Control, and Dynamics},
   pages = {716-722},
   publisher = {American Inst. Aeronautics and Astronautics Inc.},
   title = {General method for calculating satellite collision probability},
   volume = {24},
   year = {2001},
}


% Izzo ellipsoidal gravitational potential 1
@article{Ivory1809,
  title   = {{On the Attractions of homogeneous Ellipsoids}},
  author  = {J. Ivory.},
  year    = 1809,
  journal = {Philosophical Transactions of the Royal Society of London},
  volume  = 99,
  pages   = {345--372}
}
% Izzo ellipsoidal gravitational potential 2
@book{MacMillan1958,
  title  = {{The Theory of the Potential}},
  author = {W. D. MacMillan},
  year   = 1958
}
% Izzo ellipsoidal gravitational potential 3
@book{Danby1992,
  title     = {{Fundamentals of Celestial Mechanics}},
  author    = {J. Danby},
  year      = 1992,
  publisher = {Richmond: Willman-Bell},
  volume    = 1,
  edition   = 2
}
%
@article{Geodesy1994,
  title           = {{Balmino Gravitational Potential Harmonics from the Shape of an Homogenous Body (1994)}},
  author          = {Geodesy, Planetary},
  year            = 1994,
  pages           = {331--364},
  keywords        = {gravitational potential,phobos,spherical harmonics,topography},
  mendeley-groups = {Thesis Refactored/Ellipsoidal Gravitational Potential}
}
@book{Montenbruck2000,
  title           = {{Satellite Orbits}},
  author          = {Montenbruck, Oliver and Gill, Eberhard},
  year            = 2000,
  booktitle       = {Satellite Orbits},
  doi             = {10.1007/978-3-642-58351-3},
  isbn            = {354067280X},
  abstract        = {In most of the recent determinations of the geocentric gravitational coefficient (GM) of the earth, the laser ranging data to the Lageos satellite have had the greatest influence on the solution. These data, however, have generally been processed with a small but significant error in one of the range corrections. In a new determination of GM using the corrected center-of-mass offset, a value of 398600.4415 cu km/sq sec (including the mass of the atmosphere) has been obtained, with an estimated uncertainty (1 sigma of 0.0008 cu km/sq sec.},
  mendeley-groups = {Thesis Refactored}
}
% Bellman and "Curse of dimensionality"
@book{bellman1957dynamic,
  title     = {Dynamic Programming},
  author    = {Bellman, R. and Rand Corporation and Karreman Mathematics Research Collection},
  year      = 1957,
  publisher = {Princeton University Press},
  series    = {Rand Corporation research study},
  isbn      = 9780691079516,
  url       = {https://books.google.co.za/books?id=wdtoPwAACAAJ},
  lccn      = 57005444
}
@book{moulton1970introduction,
  title     = {An Introduction to Celestial Mechanics},
  author    = {Moulton, F.R.},
  year      = 1970,
  publisher = {Dover Publications},
  series    = {Dover books in astronomy},
  isbn      = 9780486646879,
  url       = {https://books.google.co.za/books?id=URPSrBntwdAC},
  lccn      = 79103400
}
% WERTZ!
@book{wertz2002mission,
  title     = {Mission Geometry; Orbit and Constellation Design and Management: Spacecraft Orbit and Attitude Systems},
  author    = {Wertz, J.R.},
  year      = 2002,
  publisher = {Springer Netherlands},
  series    = {Space Technology Library},
  isbn      = 9780792371489,
  url       = {https://books.google.co.za/books?id=8VH6wAEACAAJ},
  lccn      = 2001054290
}
@book{bellman1961adaptive,
  title     = {Adaptive Control Processes: A Guided Tour},
  author    = {Bellman, R. and Bellman, R.E. and Karreman Mathematics Research Collection},
  year      = 1961,
  publisher = {Princeton University Press},
  series    = {Princeton Legacy Library},
  isbn      = 9780691079011,
  url       = {https://books.google.co.za/books?id=POAmAAAAMAAJ},
  lccn      = {lc60005740}
}
% RL PSACECRAFT GUIDANCE CUBES
@article{Hovell2021,
  title     = {Deep Reinforcement Learning for Spacecraft Proximity Operations Guidance},
  author    = {Kirk Hovell and Steve Ulrich},
  year      = 2021,
  month     = 3,
  journal   = {Journal of Spacecraft and Rockets},
  publisher = {American Institute of Aeronautics and Astronautics ({AIAA})},
  volume    = 58,
  number    = 2,
  pages     = {254--264},
  doi       = {10.2514/1.a34838},
  url       = {https://doi.org/10.2514/1.a34838}
}
@book{Dirkx2015,
  title           = {{Interplanetary Laser Ranging}},
  author          = {Dirkx, D.},
  year            = 2015,
  isbn            = 9789462991927,
  url             = {https://repository.tudelft.nl/islandora/object/uuid:bd728e02-f403-4cea-9e2b-65b04b47b3f7?collection=research},
  abstract        = {Measurements of the motion of natural (and artificial) bodies in the solar system provide key input on their interior structre and properties. Currently, the most accurate measurements of solar system dynamics are performed using radiometric tracking systems on planetary missions, providing range measurement with an accuracy in the order of 1 m. Laser ranging to Earth-orbiting satellites equipped with laser retroreflectors provides range data with (sub-)cm accuracy. Extending this technology to planetary missions, however, requires the use of an active space segment equipped with a laser detector and transmitter (for a two-way system). The feasibility of such measurements have been demonstrated at planetary distances, and used operationally (with a one-way system) for the Lunar Reconaissance Orbiter (LRO) mission. The topic of this dissertation is the analysis of the application of interplanetary laser ranging (ILR) to improve the science return from next-generation space missions, with a focus on planetary science objectives. We have simulated laser ranging data for a variety of mission and system architectures, analyzing the influence of both model and measurement uncertainties. Our simulations show that the single-shot measurement precision is relatively inconsequential compared to the systematic range errors, providing a strong rationale for the consistent use of single-photon signal-intensity operation. We find that great advances in planetary geodesy (tidal, rotational characteristics, etc.) could be achieved by ILR. However, the laser data should be accompanied by commensurate improvements in other measurements and data analysis models to maximize the system's science return. The science return from laser ranging data will be especially strong for planetary landers, with a radio system remaining the preferred choice for many orbiter missions. Furthermore, we conclude that the science case for a one-way laser ranging is relatively weak compared to next-generation radiometric tracking systems, requiring the development of much more accurate space-based clocks.},
  mendeley-groups = {Thesis Refactored/Estimation}
}
% Izzo RL Spacecarft
@article{Willis2016,
  title           = {{Reinforcement learning for spacecraft maneuvering near small bodies}},
  author          = {Willis, Stefan and Izzo, Dario and Hennes, Daniel},
  year            = 2016,
  journal         = {Advances in the Astronautical Sciences},
  volume          = 158,
  pages           = {1351--1368},
  isbn            = 9780877036333,
  issn            = {00653438},
  abstract        = {We use neural reinforcement learning to control a spacecraft around a small celestial body whose gravity field is unknown. The small body is assumed to be a triaxial ellipsoid and its density and dimensions are left unknown within large bounds. We experiment with different proprioceptive capabilities of the spacecraft emphasising lightweight neuromorphic systems for optic flow detection. We find that even in such a highly uncertain environment and using limited perception capabilities, our approach is able to deliver a control strategy able to hover above the asteroid surface with small residual drift.},
  mendeley-groups = {Master Thesis/Similar,Master Thesis/Izzo,Thesis Refactored}
}
% Numerical computation of ellipsoid integrals
@article{Johansson2019,
  title           = {{Numerical Evaluation of Elliptic Functions, Elliptic Integrals and Modular Forms}},
  author          = {Johansson, Fredrik},
  year            = 2019,
  pages           = {269--293},
  doi             = {10.1007/978-3-030-04480-0_12},
  abstract        = {We describe algorithms to compute elliptic functions and their relatives (Jacobi theta functions, modular forms, elliptic integrals, and the arithmetic-geometric mean) numerically to arbitrary precision with rigorous error bounds for arbitrary complex variables. Implementations in ball arithmetic are available in the open source Arb library. We discuss the algorithms from a concrete implementation point of view, with focus on performance at tens to thousands of digits of precision.},
  archiveprefix   = {arXiv},
  arxivid         = {1806.06725},
  eprint          = {1806.06725},
  mendeley-groups = {Thesis Refactored/Ellipsoidal Gravitational Potential/Numerical Mathematics}
}
% Computer vision vs DL.
@article{Mahony-et-al-2020,
  title     = {Advances in Computer Vision},
  year      = 2020,
  journal   = {Advances in Intelligent Systems and Computing},
  publisher = {Springer International Publishing},
  doi       = {10.1007/978-3-030-17795-9},
  isbn      = 9783030177959,
  issn      = {2194-5365},
  url       = {http://dx.doi.org/10.1007/978-3-030-17795-9},
  authors   = {Niall O' Mahony, Sean Campbell, Anderson Carvalho, Suman Harapanahalli, Gustavo Velasco-Hernandez, Lenka Krpalkova, Daniel Riordan, Joseph Walsh}
}
% machine learning: coin
@article{5392560,
  title   = {Some Studies in Machine Learning Using the Game of Checkers},
  author  = {Samuel, A. L.},
  year    = 1959,
  journal = {IBM Journal of Research and Development},
  volume  = 3,
  number  = 3,
  pages   = {210--229},
  doi     = {10.1147/rd.33.0210}
}
% deep learning: coin
@inproceedings{Rina1986,
  title   = {Learning While Searching in Constraint-Satisfaction-Problems.},
  author  = {Dechter, Rina},
  year    = 1986,
  month   = {01},
  journal = {AAAI},
  pages   = {178--185}
}
% ai boom
@misc{hardy_2016,
  title     = {Reasons to Believe the A.I. Boom Is Real},
  author    = {Hardy, Quentin},
  year      = 2016,
  month     = 7,
  journal   = {The New York Times},
  publisher = {The New York Times},
  url       = {https://www.nytimes.com/2016/07/19/technology/reasons-to-believe-the-ai-boom-is-real.html}
}
% the explosion of DL
@inproceedings{5206848,
  title     = {ImageNet: A large-scale hierarchical image database},
  author    = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},
  year      = 2009,
  booktitle = {2009 IEEE Conference on Computer Vision and Pattern Recognition},
  pages     = {248--255},
  doi       = {10.1109/CVPR.2009.5206848}
}
% Machine Learning
@book{Mitchell97,
  title     = {Machine Learning},
  author    = {Mitchell, Tom M.},
  year      = 1997,
  publisher = {McGraw-Hill},
  address   = {New York},
  isbn      = {978-0-07-042807-2},
  abstract  = {This book covers the field of machine learning, which is the study of algorithms that allow computer programs to automatically improve through experience. This exciting addition to the McGraw-Hill Series in Computer Science focuses on the concepts and techniques that contribute to the rapidly changing field of machine learning---including probability and statistics, artificial intelligence, and neural networks---unifying them all in a logical and coherent manner.},
  added-at  = {2017-05-08T14:37:30.000+0200},
  biburl    = {https://www.bibsonomy.org/bibtex/23e79734ee1a6e49aee02ffd108224d1c/flint63},
  groups    = {public},
  interhash = {479a66c32badb3a455fbdcf8e6633a5d},
  intrahash = {3e79734ee1a6e49aee02ffd108224d1c},
  keywords  = {01624 105 book shelf ai learn algorithm},
  timestamp = {2017-07-13T17:10:10.000+0200},
  username  = {flint63}
}
@book{Mitchell97LearningAlgorithm,
  title     = {Machine Learning},
  author    = {Mitchell, Tom M.},
  year      = 1997,
  publisher = {McGraw-Hill},
  address   = {New York},
  pages     = 97,
  isbn      = {978-0-07-042807-2},
  abstract  = {This book covers the field of machine learning, which is the study of algorithms that allow computer programs to automatically improve through experience. This exciting addition to the McGraw-Hill Series in Computer Science focuses on the concepts and techniques that contribute to the rapidly changing field of machine learning---including probability and statistics, artificial intelligence, and neural networks---unifying them all in a logical and coherent manner.},
  added-at  = {2017-05-08T14:37:30.000+0200},
  biburl    = {https://www.bibsonomy.org/bibtex/23e79734ee1a6e49aee02ffd108224d1c/flint63},
  groups    = {public},
  interhash = {479a66c32badb3a455fbdcf8e6633a5d},
  intrahash = {3e79734ee1a6e49aee02ffd108224d1c},
  keywords  = {01624 105 book shelf ai learn algorithm},
  timestamp = {2017-07-13T17:10:10.000+0200},
  username  = {flint63}
}
@book{Goodfellow-et-al-2016,
  title     = {Deep Learning},
  author    = {Ian Goodfellow and Yoshua Bengio and Aaron Courville},
  year      = 2016,
  publisher = {MIT Press},
  note      = {http://www.deeplearningbook.org}
}
@article{Taeihagh2019,
  title           = {{Governing autonomous vehicles: emerging responses for safety, liability, privacy, cybersecurity, and industry risks}},
  author          = {Taeihagh, Araz and Lim, Hazel Si Min},
  year            = 2019,
  journal         = {Transport Reviews},
  volume          = 39,
  number          = 1,
  pages           = {103--128},
  doi             = {10.1080/01441647.2018.1494640},
  issn            = 14645327,
  abstract        = {The benefits of autonomous vehicles (AVs) are widely acknowledged, but there are concerns about the extent of these benefits and AV risks and unintended consequences. In this article, we first examine AVs and different categories of the technological risks associated with them. We then explore strategies that can be adopted to address these risks, and explore emerging responses by governments for addressing AV risks. Our analyses reveal that, thus far, governments have in most instances avoided stringent measures in order to promote AV developments and the majority of responses are non-binding and focus on creating councils or working groups to better explore AV implications. The US has been active in introducing legislations to address issues related to privacy and cybersecurity. The UK and Germany, in particular, have enacted laws to address liability issues; other countries mostly acknowledge these issues, but have yet to implement specific strategies. To address privacy and cybersecurity risks strategies ranging from introduction or amendment of non-AV specific legislation to creating working groups have been adopted. Much less attention has been paid to issues such as environmental and employment risks, although a few governments have begun programmes to retrain workers who might be negatively affected.},
  keywords        = {Autonomous vehicles,automated driving,cybersecurity,governance,incumbent industries,liability,policy,privacy,risks,safety},
  mendeley-groups = {Thesis Refactored/Machine Learning/Autonomous Vehicles}
}
% perceptron origin
@techreport{Rosenblatt_1957_6098,
  title       = {The perceptron - A perceiving and recognizing automaton},
  author      = {Rosenblatt, F.},
  year        = 1957,
  month       = {January},
  address     = {Ithaca, New York},
  number      = {85-460-1},
  institution = {Cornell Aeronautical Laboratory}
}
% origin of perceptron
@article{doi:10.1177/030631296026003005,
  title    = {A Sociological Study of the Official History of the Perceptrons Controversy},
  author   = {Mikel Olazaran},
  year     = 1996,
  journal  = {Social Studies of Science},
  volume   = 26,
  number   = 3,
  pages    = {611--659},
  doi      = {10.1177/030631296026003005},
  url      = {https://doi.org/10.1177/030631296026003005},
  eprint   = {\url{https://doi.org/10.1177/030631296026003005}},
  abstract = {In this paper, I analyze the controversy within Artificial Intelligence (AI) which surrounded the `perceptron' project (and neural nets in general) in the late 1950s and early 1960s. I devote particular attention to the proofs and arguments of Minsky and Papert, which were interpreted as showing that further progress in neural nets was not possible, and that this approach to AI had to be abandoned. I maintain that this official interpretation of the debate was a result of the emergence, institutionalization and (importantly) legitimation of the symbolic AI approach (with its resource allocation system and authority structure). At the `research-area' level, there was considerable interpretative flexibility. This interpretative flexibility was further demonstrated by the revival of neural nets in the late 1980s, and subsequent rewriting of the official history of the debate.}
}
% criticism of perceptrons
@book{minsky69perceptrons,
  author   = {Minsky, Marvin and Papert, Seymour},
  address  = {Cambridge, MA, USA},
  added-at = {2008-05-16T13:57:01.000+0200}
}
% supervised: Dimensionality Reduction
@misc{vogelstein2021supervised,
  title         = {Supervised Dimensionality Reduction for Big Data},
  author        = {Joshua T. Vogelstein and Eric Bridgeford and Minh Tang and Da Zheng and Christopher Douville and Randal Burns and Mauro Maggioni},
  year          = 2021,
  eprint        = {1709.01233},
  archiveprefix = {arXiv},
  primaryclass  = {stat.ML}
}
% unsupervised learning
@incollection{barlow1999ul,
  title     = {Unsupervised learning: introduction},
  author    = {Barlow, H B},
  year      = 1999,
  booktitle = {Unsupervised Learning: Foundations of Neural Computation},
  publisher = {Bradford Company Scituate, MA, USA},
  pages     = {1--17},
  url       = {http://books.google.com/books?id=yj04Y0lje4cC},
  added-at  = {2008-09-26T11:17:56.000+0200},
  biburl    = {https://www.bibsonomy.org/bibtex/22284e571c9a95e9e81776c58fc3b1dc9/yish},
  editor    = {Hinton, Geoffrey E. and Sejnowski, Terrence Joseph},
  interhash = {5e64abe200a2085f210bc836aa8cc6b1},
  intrahash = {2284e571c9a95e9e81776c58fc3b1dc9},
  keywords  = {algorithmic computational learning machine unsupervised wleformativeeassessment},
  timestamp = {2008-09-26T11:18:38.000+0200}
}
% semi-supervised
@book{books/mit/06/CSZ2006,
  title     = {Semi-Supervised Learning},
  year      = 2006,
  publisher = {The MIT Press},
  isbn      = 9780262033589,
  url       = {http://dblp.uni-trier.de/db/books/collections/CSZ2006.html},
  added-at  = {2019-07-22T00:00:00.000+0200},
  biburl    = {https://www.bibsonomy.org/bibtex/265ac136f8b3a44d77fcf9ec42829296a/dblp},
  editor    = {Chapelle, Olivier and Sch\"{o}lkopf, Bernhard and Zien, Alexander},
  ee        = {\url{https://doi.org/10.7551/mitpress/9780262033589.001.0001}},
  interhash = {90eecf83da2790cac977f375160081fe},
  intrahash = {65ac136f8b3a44d77fcf9ec42829296a},
  keywords  = {dblp},
  timestamp = {2019-09-17T12:36:24.000+0200}
}
% semi-supervised anomaly detection.
@article{DBLP:journals/corr/abs-1805-06725,
  title      = {GANomaly: Semi-Supervised Anomaly Detection via Adversarial Training},
  author     = {Samet Akcay and Amir Atapour Abarghouei and Toby P. Breckon},
  year       = 2018,
  journal    = {CoRR},
  volume     = {abs/1805.06725},
  url        = {http://arxiv.org/abs/1805.06725},
  eprinttype = {arXiv},
  eprint     = {1805.06725},
  timestamp  = {Mon, 13 Aug 2018 16:46:23 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1805-06725.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}
% semi-supervised clustering
@article{Bair2013,
  title     = {Semi-supervised clustering methods},
  author    = {Bair, Eric},
  year      = 2013,
  month     = {Jul},
  journal   = {Wiley Interdisciplinary Reviews: Computational Statistics},
  publisher = {Wiley},
  volume    = 5,
  number    = 5,
  pages     = {349–361},
  doi       = {10.1002/wics.1270},
  issn      = {1939-5108},
  url       = {http://dx.doi.org/10.1002/wics.1270}
}
% semi-supervised: dimensionality reduciton
@inproceedings{Zhang2007,
  title   = {Semi-Supervised Dimensionality Reduction},
  author  = {Zhang, Daoqiang and Zhou, Zhi-Hua and Chen, Songcan},
  year    = 2007,
  month   = {04},
  journal = {SIAM Data Mining},
  doi     = {10.1137/1.9781611972771.73}
}
% example of structures parsing task:
@inproceedings{pmlr-v15-collobert11a,
  title     = {Deep Learning for Efficient Discriminative Parsing},
  author    = {Collobert, Ronan},
  year      = 2011,
  month     = 4,
  booktitle = {Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
  publisher = {PMLR},
  address   = {Fort Lauderdale, FL, USA},
  series    = {Proceedings of Machine Learning Research},
  volume    = 15,
  pages     = {224--232},
  url       = {https://proceedings.mlr.press/v15/collobert11a.html},
  editor    = {Gordon, Geoffrey and Dunson, David and Dud\'{\i}k, Miroslav},
  pdf       = {\url{http://proceedings.mlr.press/v15/collobert11a/collobert11a.pdf}},
  abstract  = {We propose a new fast purely discriminative algorithm for natural language parsing, based on a ``deep'' recurrent convolutional graph transformer network (GTN). Assuming a decomposition of a parse tree into a stack of ``levels'', the network predicts a level of the tree taking into account predictions of previous levels. Using only few basic text features, we show similar performance (in F1 score) to existing pure discriminative parsers and existing ``benchmark'' parsers (like Collins parser, probabilistic context-free grammars based), with a huge speed advantage. [pdf][supplementary]}
}
% aviation anomaly detection
@article{Basora2019,
  title          = {Recent Advances in Anomaly Detection Methods Applied to Aviation},
  author         = {Basora, Luis and Olive, Xavier and Dubot, Thomas},
  year           = 2019,
  journal        = {Aerospace},
  volume         = 6,
  number         = 11,
  doi            = {10.3390/aerospace6110117},
  issn           = {2226-4310},
  url            = {https://www.mdpi.com/2226-4310/6/11/117},
  article-number = 117,
  abstract       = {Anomaly detection is an active area of research with numerous methods and applications. This survey reviews the state-of-the-art of data-driven anomaly detection techniques and their application to the aviation domain. After a brief introduction to the main traditional data-driven methods for anomaly detection, we review the recent advances in the area of neural networks, deep learning and temporal-logic based learning. In particular, we cover unsupervised techniques applicable to time series data because of their relevance to the aviation domain, where the lack of labeled data is the most usual case, and the nature of flight trajectories and sensor data is sequential, or temporal. The advantages and disadvantages of each method are presented in terms of computational efficiency and detection efficacy. The second part of the survey explores the application of anomaly detection techniques to aviation and their contributions to the improvement of the safety and performance of flight operations and aviation systems. As far as we know, some of the presented methods have not yet found an application in the aviation domain. We review applications ranging from the identification of significant operational events in air traffic operations to the prediction of potential aviation system failures for predictive maintenance.}
}
@inproceedings{Janakiraman2016,
  title     = {Anomaly detection in aviation data using extreme learning machines},
  author    = {Janakiraman, Vijay Manikandan and Nielsen, David},
  year      = 2016,
  booktitle = {2016 International Joint Conference on Neural Networks (IJCNN)},
  volume    = {},
  number    = {},
  pages     = {1993--2000},
  doi       = {10.1109/IJCNN.2016.7727444}
}

% GPT-3 synthesis examples
@article{Brown2020,
  title      = {Language Models are Few-Shot Learners},
  author     = {Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert{-}Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
  year       = 2020,
  journal    = {CoRR},
  volume     = {abs/2005.14165},
  url        = {https://arxiv.org/abs/2005.14165},
  eprinttype = {arXiv},
  eprint     = {2005.14165},
  timestamp  = {Wed, 03 Jun 2020 11:36:54 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2005-14165.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

% hinge loss svm
@article{Zhang2008,
  abstract = {The Support Vector Machine (SVM) is a popular classification paradigm in machine learning and has achieved great success in real applications. However, the standard SVM can not select variables automatically and therefore its solution typically utilizes all the input variables without discrimination. This makes it difficult to identify important predictor variables, which is often one of the primary goals in data analysis. In this paper, we propose two novel types of regularization in the context of the multicategory SVM (MSVM) for simultaneous classification and variable selection. The MSVM generally requires estimation of multiple discriminating functions and applies the argmax rule for prediction. For each individual variable, we propose to characterize its importance by the supnorm of its coefficient vector associated with different functions, and then minimize the MSVM hinge loss function subject to a penalty on the sum of supnorms. To further improve the supnorm penalty, we propose the adaptive regularization, which allows different weights imposed on different variables according to their relative importance. Both types of regularization automate variable selection in the process of building classifiers, and lead to sparse multiclassifiers with enhanced interpretability and improved accuracy, especially for high dimensional low sample size data. One big advantage of the sup-norm penalty is its easy implementation via standard linear programming. Several simulated examples and one real gene data analysis demonstrate the outstanding performance of the adaptive supnorm penalty in various data settings. © 2008, Institute of Mathematical Statistics. All rights reserved.},
  author   = {H.H. Zhang and Y. Liu and Y. Wu and J. Zhu},
  doi      = {10.1214/08-EJS122},
  journal  = {Electronic Journal of Statistics},
  pages    = {149-167},
  title    = {Variable selection for the multicategory SVM via adaptive sup-norm regularization},
  volume   = {2},
  year     = {2008}
}


% hingle loss SVM
@article{Liu2007,
  abstract = {The Support Vector Machine (SVM) has become one of the most popular machine learning techniques in recent years. The success of the SVM is mostly due to its elegant margin concept and theory in binary classification. Generalization to the multicategory setting, however, is not trivial. There are a number of different multicategory extensions of the SVM in the literature. In this paper, we review several commonly used extensions and Fisher consistency of these extensions. For inconsistent extensions, we propose two approaches to make them Fisher consistent, one is to add bounded constraints and the other is to truncate unbounded hinge losses.},
  author   = {Y. Liu},
  journal  = {Journal of Machine Learning Research},
  pages    = {291-298},
  title    = {Fisher consistency of multicategory Support Vector Machines},
  volume   = {2},
  year     = {2007}
}


% hingle loss and svm
@article{Wu2007,
  abstract = {The support vector machine (SVM) has been widely applied for classification problems in both machine learning and statistics. Despite its popularity, however, SVM has some drawbacks in certain situations. In particular, the SVM classifier can be very sensitive to outliers in the training sample. Moreover, the number of support vectors (SVs) can be very large in many applications. To circumvent these drawbacks, we propose the robust truncated hinge loss SVM (RSVM), which uses a truncated hinge loss. The RSVM is shown to be more robust to outliers and to deliver more accurate classifiers using a smaller set of SVs than the standard SVM. Our theoretical results show that the RSVM is Fisher-consistent, even when there is no dominating class, a scenario that is particularly challenging for multicategory classification. Similar results are obtained for a class of margin-based classifiers. © 2007 American Statistical Association.},
  author   = {Y. Wu and Y. Liu},
  doi      = {10.1198/016214507000000617},
  issue    = {479},
  journal  = {Journal of the American Statistical Association},
  pages    = {974-983},
  title    = {Robust truncated hinge loss support vector machines},
  volume   = {102},
  year     = {2007}
}


% credit card fraud
@article{Tiwari2021,
  title      = {Credit Card Fraud Detection using Machine Learning: {A} Study},
  author     = {Pooja Tiwari and Simran Mehta and Nishtha Sakhuja and Jitendra Kumar and Ashutosh Kumar Singh},
  year       = 2021,
  journal    = {CoRR},
  volume     = {abs/2108.10005},
  url        = {https://arxiv.org/abs/2108.10005},
  eprinttype = {arXiv},
  eprint     = {2108.10005},
  timestamp  = {Fri, 27 Aug 2021 15:02:29 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2108-10005.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

% ML Climate change
@article{Rolnick2023,
  abstract  = {Climate change is one of the greatest challenges facing humanity, and we, as machine learning (ML) experts, may wonder how we can help. Here we describe how ML can be a powerful tool in reducing greenhouse gas emissions and helping society adapt to a changing climate. From smart grids to disaster management, we identify high impact problems where existing gaps can be filled by ML, in collaboration with other fields. Our recommendations encompass exciting research questions as well as promising business opportunities. We call on the ML community to join the global effort against climate change.},
  author    = {David Rolnick and Priya L. Donti and Lynn H. Kaack and Kelly Kochanski and Alexandre Lacoste and Kris Sankaran and Andrew Slavin Ross and Nikola Milojevic-Dupont and Natasha Jaques and Anna Waldman-Brown and Alexandra Sasha Luccioni and Tegan Maharaj and Evan D. Sherwin and S. Karthik Mukkavilli and Konrad P. Kording and Carla P. Gomes and Andrew Y. Ng and Demis Hassabis and John C. Platt and Felix Creutzig and Jennifer Chayes and Yoshua Bengio},
  doi       = {10.1145/3485128},
  issn      = {15577341},
  issue     = {2},
  journal   = {ACM Computing Surveys},
  keywords  = {Climate change,adaptation,artificial intelligence,machine learning,mitigation},
  month     = {3},
  publisher = {Association for Computing Machinery},
  title     = {Tackling Climate Change with Machine Learning},
  volume    = {55},
  year      = {2023}
}


% genomics datastics ML
@article{Libbrecht2015,
  abstract = {The field of machine learning includes the development and application of computer algorithms that improve with experience.Machine learning methods can be divided into supervised, semi-supervised and unsupervised methods. Supervised methods are trained on examples with labels (for example, 'gene' or 'not gene') and are then used to predict these labels on other examples, whereas unsupervised methods find patterns in data sets without the use of labels. Semi-supervised methods combine these two approaches, leveraging patterns in unlabelled data to improve power in the prediction of labels.Different machine learning methods may be required for an application, depending on whether one is interested in interpreting the output model or is simply concerned with predictive power. Generative models, which posit a probabilistic distribution over input data, are generally best for interpretability, whereas discriminative models, which seek only to model labels, are generally best for predictive power.Prior information can be added to a model in order to train the model more effectively when it is provided with limited data, to limit the complexity of the model or to incorporate data that are not used by the model directly. Prior information can be incorporated explicitly in a probabilistic model or implicitly through the choice of features or similarity measures.The choice of an appropriate performance measure depends strongly on the application task. Machine learning methods are most effective when they optimize an appropriate performance measure.Network estimation methods are appropriate when the data contain complex dependencies among examples. These methods work best when they take into account the confounding effects of indirect relationships.},
  author   = {Maxwell W Libbrecht and William Stafford Noble},
  doi      = {10.1038/nrg3920},
  issn     = {1471-0064},
  issue    = {6},
  journal  = {Nature Reviews Genetics},
  pages    = {321-332},
  title    = {Machine learning applications in genetics and genomics},
  volume   = {16},
  url      = {https://doi.org/10.1038/nrg3920},
  year     = {2015}
}


% ML in medicine
@article{Kourou2015,
  abstract  = {Cancer has been characterized as a heterogeneous disease consisting of many different subtypes. The early diagnosis and prognosis of a cancer type have become a necessity in cancer research, as it can facilitate the subsequent clinical management of patients. The importance of classifying cancer patients into high or low risk groups has led many research teams, from the biomedical and the bioinformatics field, to study the application of machine learning (ML) methods. Therefore, these techniques have been utilized as an aim to model the progression and treatment of cancerous conditions. In addition, the ability of ML tools to detect key features from complex datasets reveals their importance. A variety of these techniques, including Artificial Neural Networks (ANNs), Bayesian Networks (BNs), Support Vector Machines (SVMs) and Decision Trees (DTs) have been widely applied in cancer research for the development of predictive models, resulting in effective and accurate decision making. Even though it is evident that the use of ML methods can improve our understanding of cancer progression, an appropriate level of validation is needed in order for these methods to be considered in the everyday clinical practice. In this work, we present a review of recent ML approaches employed in the modeling of cancer progression. The predictive models discussed here are based on various supervised ML techniques as well as on different input features and data samples. Given the growing trend on the application of ML methods in cancer research, we present here the most recent publications that employ these techniques as an aim to model cancer risk or patient outcomes.},
  author    = {Konstantina Kourou and Themis P. Exarchos and Konstantinos P. Exarchos and Michalis V. Karamouzis and Dimitrios I. Fotiadis},
  doi       = {10.1016/J.CSBJ.2014.11.005},
  issn      = {2001-0370},
  journal   = {Computational and Structural Biotechnology Journal},
  keywords  = {Cancer recurrence,Cancer survival,Cancer susceptibility,Machine learning,Predictive models},
  month     = {1},
  pages     = {8-17},
  pmid      = {25750696},
  publisher = {Elsevier},
  title     = {Machine learning applications in cancer prognosis and prediction},
  volume    = {13},
  year      = {2015}
}


% ML in medicine
@article{Abbasi2019,
  abstract = {Abstract Machine learning leverages statistical and computer science principles to develop algorithms capable of improving performance through interpretation of data rather than through explicit instructions. Alongside widespread use in image recognition, language processing, and data mining, machine learning techniques have received increasing attention in medical applications, ranging from automated imaging analysis to disease forecasting. This review examines the parallel progress made in epilepsy, highlighting applications in automated seizure detection from electroencephalography (EEG), video, and kinetic data, automated imaging analysis and pre-surgical planning, prediction of medication response, and prediction of medical and surgical outcomes using a wide variety of data sources. A brief overview of commonly used machine learning approaches, as well as challenges in further application of machine learning techniques in epilepsy, is also presented. With increasing computational capabilities, availability of effective machine learning algorithms, and accumulation of larger datasets, clinicians and researchers will increasingly benefit from familiarity with these techniques and the significant progress already made in their application in epilepsy.},
  author   = {Bardia Abbasi and Daniel M Goldenholz},
  doi      = {https://doi.org/10.1111/epi.16333},
  issue    = {10},
  journal  = {Epilepsia},
  keywords = {artificial intelligence,deep learning,epilepsy imaging,epilepsy surgery,seizure detection},
  pages    = {2037-2047},
  title    = {Machine learning applications in epilepsy},
  volume   = {60},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1111/epi.16333},
  year     = {2019}
}


% ML in medicine
@article{May2021,
  author    = {Mike May},
  doi       = {10.1038/S41591-020-01197-2},
  issn      = {1546170X},
  issue     = {1},
  journal   = {Nature medicine},
  month     = {1},
  pages     = {2-3},
  pmid      = {33442003},
  publisher = {NLM (Medline)},
  title     = {Eight ways machine learning is assisting medicine},
  volume    = {27},
  year      = {2021}
}


% ML in medicine
@article{Rajkomar2019,
  abstract  = {A 49-year-old patient notices a painless rash on his shoulder but does not seek care. Months later, his wife asks him to see a doctor, who diagnoses a seborrheic keratosis. Later, when the patient undergoes a screening colonoscopy, a nurse notices a dark macule on his shoulder and advises him to have it evaluated. One month later, the patient sees a dermatologist, who obtains a biopsy specimen of the lesion. The findings reveal a noncancerous pigmented lesion. Still concerned, the dermatologist requests a second reading of the biopsy specimen, and invasive melanoma is diagnosed. An oncologist initiates treatment with systemic chemotherapy. A physician friend asks the patient why he is not receiving immunotherapy. W hat if every medical decision, whether made by an intensivist or a community health worker, was instantly reviewed by a team of relevant experts who provided guidance if the decision seemed amiss? Patients with newly diagnosed, uncomplicated hypertension would receive the medications that are known to be most effective rather than the one that is most familiar to the prescriber. 1,2 Inadvertent overdoses and errors in prescribing would be largely eliminated. 3,4 Patients with mysterious and rare ailments could be directed to renowned experts in fields related to the suspected diagnosis. 5 Such a system seems far-fetched. There are not enough medical experts to staff it, it would take too long for experts to read through a patient's history, and concerns related to privacy laws would stop efforts before they started. 6 Yet, this is the promise of machine learning in medicine: the wisdom contained in the decisions made by nearly all clinicians and the outcomes of billions of patients should inform the care of each patient. That is, every diagnosis, management decision, and therapy should be personalized on the basis of all known information about a patient, in real time, incorporating lessons from a collective experience. This framing emphasizes that machine learning is not just a new tool, such as a new drug or medical device. Rather, it is the fundamental technology required to meaningfully process data that exceed the capacity of the human brain to comprehend ; increasingly, this overwhelming store of information pertains to both vast clinical databases and even the data generated regarding a single patient. 7 Nearly 50 years ago, a Special Article in the Journal stated that computing would be "augmenting and, in some cases, largely replacing the intellectual functions of the physician." 8 Yet, in early 2019, surprisingly little in health care is driven by machine learning. Rather than report the myriad proof-of-concept models (of retrospective data) that have been tested, here we describe the core structural changes and paradigm shifts in the health care system that are necessary to enable the full promise of machine learning in medicine (see video). M achine Le a r ning E x pl a ined Traditionally, software engineers have distilled knowledge in the form of explicit computer code that instructs computers exactly how to process data and how to A video overview of machine learning is available at NEJM.org},
  author    = {Alvin Rajkomar and Jeffrey Dean and Isaac Kohane},
  doi       = {10.1056/NEJMRA1814259/SUPPL_FILE/NEJMRA1814259_DISCLOSURES.PDF},
  issn      = {0028-4793},
  issue     = {14},
  journal   = {New England Journal of Medicine},
  month     = {4},
  pages     = {1347-1358},
  pmid      = {30943338},
  publisher = {Massachusetts Medical Society},
  title     = {Machine Learning in Medicine},
  volume    = {380},
  year      = {2019}
}


% ML in medicine
@article{Singh2019,
  abstract  = {Machine learning techniques can extensively apply in the solution of the medicine domain problems by applying classification models and systems that can support medical personnel in the diagnosis and predication of diagnosis diseases. Though, it's hard to extract knowledge and information from medical records and data because this data and information is in mixed, unorganized, and high dimensional. This data also contains noise in collected data and outliers exist in collected data. Main applicable method will be used applies by checking different machine learning techniques. The performance of machine learning technique is checked by verifying and validating machine learning techniques' performances through accuracy. Present research paper has been discussing about the usability and applicability of different machine learning techniques i.e. decision tree algorithm, support vector machine method, random forest method, evolutionary algorithms based models and swarm intelligence based techniques in the diagnosis and treatment of the diseases. Advance medical diagnosis criteria generates confidence in diagnosis by using imagining techniques in the diagnosis of a disease is extensively used by doctors. In view of the fact that analyzing medical images is very complex and difficult task, by using machine learning methods for analysis of imaging will support and give major help in disease diagnosis. Application of different Machine learning methods is used by applying its techniques on big data for interpretation for diagnosis because machine learning methods show their capability and shows their easiness to solve the problems of bioinformatics domain.},
  author    = {Preeti Singh and S. P. Singh and D. S. Singh},
  doi       = {10.1109/CICT48419.2019.9066250},
  isbn      = {9781728153988},
  journal   = {2019 IEEE Conference on Information and Communication Technology, CICT 2019},
  keywords  = {Decision Tree,Machine Learning,Medicine,Random Forest,Support Vector Machine},
  month     = {12},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  title     = {An introduction and review on machine learning applications in medicine and healthcare},
  year      = {2019}
}


% A Review of Machine Learning and Deep Learning Applications
@inproceedings{Shinde2018,
  abstract = {Machine learning is one of the fields in the modern computing world. A plenty of research has been undertaken to make machines intelligent. Learning is a natural human behavior which has been made an essential aspect of the machines as well. There are various techniques devised for the same. Traditional machine learning algorithms have been applied in many application areas. Researchers have put many efforts to improve the accuracy of that machinelearning algorithms. Another dimension was given thought which leads to deep learning concept. Deep learning is a subset of machine learning. So far few applications of deep learning have been explored. This is definitely going to cater to solving issues in several new application domains, sub-domains using deep learning. A review of these past and future application domains, sub-domains, and applications of machine learning and deep learning are illustrated in this paper.},
  author   = {Pramila P Shinde and Seema Shah},
  doi      = {10.1109/ICCUBEA.2018.8697857},
  journal  = {2018 Fourth International Conference on Computing Communication Control and Automation (ICCUBEA)},
  month    = {8},
  pages    = {1-6},
  title    = {A Review of Machine Learning and Deep Learning Applications},
  year     = {2018}
}

% imputation of missing values: machine learning
@article{Emmanuel2021,
  title    = {A survey on missing data in machine learning},
  author   = {Emmanuel, Tlamelo and Maupong, Thabiso and Mpoeleng, Dimane and Semong, Thabo and Mphago, Banyatsang and Tabona, Oteng},
  year     = 2021,
  month    = {Oct},
  day      = 27,
  journal  = {Journal of Big Data},
  volume   = 8,
  number   = 1,
  pages    = 140,
  doi      = {10.1186/s40537-021-00516-9},
  issn     = {2196-1115},
  url      = {https://doi.org/10.1186/s40537-021-00516-9},
  abstract = {Machine learning has been the corner stone in analysing and extracting information from data and often a problem of missing values is encountered. Missing values occur because of various factors ukf ture there have been several proposals for handling missing values. In this paper, we aggregate some of the literature on missing data particularly focusing on machine learning techniques. We also give insight on how the machine learning approaches work by highlighting the key features of missing values imputation techniques, how they perform, their limitations and the kind of data they are most suitable for. We propose and evaluate two methods, the k nearest neighbor and an iterative imputation method (missForest) based on the random forest algorithm. Evaluation is performed on the Iris and novel power plant fan data with induced missing values at missingness rate of 5{\%} to 20{\%}. We show that both missForest and the k nearest neighbor can successfully handle missing values and offer some possible future research direction.}
}
% no free lunch theorem  : https://machinelearningmastery.com/no-free-lunch-theorem-for-machine-learning/
@article{585893,
  title   = {No free lunch theorems for optimization},
  author  = {Wolpert, D.H. and Macready, W.G.},
  year    = 1997,
  journal = {IEEE Transactions on Evolutionary Computation},
  volume  = 1,
  number  = 1,
  pages   = {67--82},
  doi     = {10.1109/4235.585893}
}
% no free lunch theorem  : https://machinelearningmastery.com/no-free-lunch-theorem-for-machine-learning/
@book{luke2012essentials,
  title     = {Essentials of Metaheuristics (Second Edition)},
  author    = {Luke, S.},
  year      = 2012,
  publisher = {Lulu.com},
  isbn      = 9781300549628,
  url       = {https://books.google.co.za/books?id=5FDdsgEACAAJ}
}
@incollection{Wolpert2002,
  title     = {The Supervised Learning No-Free-Lunch Theorems},
  author    = {David H. Wolpert},
  year      = 2002,
  booktitle = {Soft Computing and Industry},
  publisher = {Springer London},
  pages     = {25--42},
  doi       = {10.1007/978-1-4471-0123-9_3},
  url       = {https://doi.org/10.1007/978-1-4471-0123-9_3}
}
% imputation of missing frames from a video
@article{huang2020rife,
  title   = {RIFE: Real-Time Intermediate Flow Estimation for Video Frame Interpolation},
  author  = {Huang, Zhewei and Zhang, Tianyuan and Heng, Wen and Shi, Boxin and Zhou, Shuchang},
  year    = 2020,
  journal = {arXiv preprint arXiv:2011.06294}
}
@report{Wolpert1997,
  title    = {No Free Lunch Theorems for Optimization},
  author   = {David H Wolpert and William G Macready},
  year     = 1997,
  journal  = {IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION},
  volume   = 1,
  pages    = 67,
  abstract = {A framework is developed to explore the connection between effective optimization algorithms and the problems they are solving. A number of "no free lunch" (NFL) theorems are presented which establish that for any algorithm, any elevated performance over one class of problems is offset by performance over another class. These theorems result in a geometric interpretation of what it means for an algorithm to be well suited to an optimization problem. Applications of the NFL theorems to information-theoretic aspects of optimization and benchmark measures of performance are also presented. Other issues addressed include time-varying optimization problems and a priori "head-to-head" minimax distinctions between optimization algorithms, distinctions that result despite the NFL theorems' enforcing of a type of uniformity over all algorithms.},
  issue    = 1,
  keywords = {Index Terms-Evolutionary algorithms,information theory,optimization}
}
@book{Domingos15,
  title     = {The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World},
  author    = {Domingos, Pedro},
  year      = 2015,
  publisher = {Basic Books},
  address   = {New York},
  isbn      = {978-0-465-06570-7},
  abstract  = {Society is changing, one learning algorithm at a time, from search engines to online dating, personalized medicine to predicting the stock market. But learning algorithms are not just about Big Data - these algorithms take raw data and make it useful by creating more algorithms. This is something new under the sun: a technology that builds itself. In this book, Domingos reveals how machine learning is remaking business, politics, science and war. And he takes us on an awe-inspiring quest to find 'The Master Algorithm' - a universal learner capable of deriving all knowledge from data.},
  added-at  = {2018-04-15T13:17:55.000+0200},
  biburl    = {https://www.bibsonomy.org/bibtex/2b48e9f824f83e98a132511b244ed8ad0/flint63},
  groups    = {public},
  interhash = {3d8bc19852ad9cab7580e2e00322a9c2},
  intrahash = {b48e9f824f83e98a132511b244ed8ad0},
  keywords  = {01801 105 book shelf numerical ai science economy data information knowledge processing learn algorithm zzz.big},
  timestamp = {2018-04-16T11:32:18.000+0200},
  username  = {flint63}
}
@book{hastie2009elements,
  title     = {The Elements of Statistical Learning: Data Mining, Inference, and Prediction},
  author    = {Hastie, T. and Tibshirani, R. and Friedman, J.H.},
  year      = 2009,
  publisher = {Springer},
  series    = {Springer series in statistics},
  isbn      = 9780387848846,
  url       = {https://books.google.co.za/books?id=eBSgoAEACAAJ},
  lccn      = 2008941148
}
% regularization can improve generalization
@inproceedings{NIPS1991_8eefcfdf,
  title     = {A Simple Weight Decay Can Improve Generalization},
  author    = {Krogh, Anders and Hertz, John},
  year      = 1992,
  booktitle = {Advances in Neural Information Processing Systems},
  publisher = {Morgan-Kaufmann},
  volume    = 4,
  pages     = {},
  url       = {https://proceedings.neurips.cc/paper/1991/file/8eefcfdf5990e441f0fb6f3fad709e21-Paper.pdf},
  editor    = {J. Moody and S. Hanson and R. P. Lippmann}
}
% elastic net penality
@article{ZouHastie2005,
  title    = {Regularization and variable selection via the elastic net},
  author   = {Zou, Hui and Hastie, Trevor},
  year     = 2005,
  journal  = {Journal of the Royal Statistical Society Series B},
  volume   = 67,
  number   = 2,
  pages    = {301--320},
  url      = {https://EconPapers.repec.org/RePEc:bla:jorssb:v:67:y:2005:i:2:p:301-320},
  abstract = {Summary. We propose the elastic net, a new regularization and variable selection method. Real world data and a simulation study show that the elastic net often outperforms the lasso, while enjoying a similar sparsity of representation. In addition, the elastic net encourages a grouping effect, where strongly correlated predictors tend to be in or out of the model together. The elastic net is particularly useful when the number of predictors (p) is much bigger than the number of observations (n). By contrast, the lasso is not a very satisfactory variable selection method in the p\gg{}n case. An algorithm called LARS-EN is proposed for computing elastic net regularization paths efficiently, much like algorithm LARS does for the lasso.}
}
% Image Interpretation
@article{Farabet2013,
  abstract = {Scene labeling consists of labeling each pixel in an image with the category of the object it belongs to. We propose a method that uses a multiscale convolutional network trained from raw pixels to extract dense feature vectors that encode regions of multiple sizes centered on each pixel. The method alleviates the need for engineered features, and produces a powerful representation that captures texture, shape, and contextual information. We report results using multiple postprocessing methods to produce the final labeling. Among those, we propose a technique to automatically retrieve, from a pool of segmentation components, an optimal set of components that best explain the scene; these components are arbitrary, for example, they can be taken from a segmentation tree or from any family of oversegmentations. The system yields record accuracies on the SIFT Flow dataset (33 classes) and the Barcelona dataset (170 classes) and near-record accuracy on Stanford background dataset (eight classes), while being an order of magnitude faster than competing approaches, producing a (320× 240) image labeling in less than a second, including feature extraction. © 1979-2012 IEEE.},
  author   = {Clement Farabet and Camille Couprie and Laurent Najman and Yann Lecun},
  doi      = {10.1109/TPAMI.2012.231},
  issn     = {01628828},
  issue    = {8},
  journal  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  keywords = {Convolutional networks,deep learning,image classification,image segmentation,scene parsing},
  pages    = {1915-1929},
  pmid     = {23787344},
  title    = {Learning hierarchical features for scene labeling},
  volume   = {35},
  year     = {2013}
}
@article{Girshick2013,
  abstract  = {Object detection performance, as measured on the canonical PASCAL VOC
               dataset, has plateaued in the last few years. The best-performing methods are
               complex ensemble systems that typically combine multiple low-level image
               features with high-level context. In this paper, we propose a simple and
               scalable detection algorithm that improves mean average precision (mAP) by more
               than 30% relative to the previous best result on VOC 2012---achieving a mAP of
               53.3%. Our approach combines two key insights: (1) one can apply high-capacity
               convolutional neural networks (CNNs) to bottom-up region proposals in order to
               localize and segment objects and (2) when labeled training data is scarce,
               supervised pre-training for an auxiliary task, followed by domain-specific
               fine-tuning, yields a significant performance boost. Since we combine region
               proposals with CNNs, we call our method R-CNN: Regions with CNN features. We
               also compare R-CNN to OverFeat, a recently proposed sliding-window detector
               based on a similar CNN architecture. We find that R-CNN outperforms OverFeat by
               a large margin on the 200-class ILSVRC2013 detection dataset. Source code for
               the complete system is available at http://www.cs.berkeley.edu/~rbg/rcnn.},
  author    = {Ross Girshick and Jeff Donahue and Trevor Darrell and Jitendra Malik},
  doi       = {10.48550/arxiv.1311.2524},
  isbn      = {9781479951178},
  issn      = {10636919},
  journal   = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
  month     = {11},
  pages     = {580-587},
  publisher = {IEEE Computer Society},
  title     = {Rich feature hierarchies for accurate object detection and semantic segmentation},
  url       = {https://arxiv.org/abs/1311.2524v5},
  year      = {2013}
}
@article{Chen2014,
  abstract = {Deep Convolutional Neural Networks (DCNNs) have recently shown state of the art performance in high level vision tasks, such as image classification and object detection. This work brings together methods from DCNNs and probabilistic graphical models for addressing the task of pixel-level classification (also called "semantic image segmentation"). We show that responses at the final layer of DCNNs are not sufficiently localized for accurate object segmentation. This is due to the very invariance properties that make DCNNs good for high level tasks. We overcome this poor localization property of deep networks by combining the responses at the final DCNN layer with a fully connected Conditional Random Field (CRF). Qualitatively, our "DeepLab" system is able to localize segment boundaries at a level of accuracy which is beyond previous methods. Quantitatively, our method sets the new state-of-art at the PASCAL VOC-2012 semantic image segmentation task, reaching 71.6% IOU accuracy in the test set. We show how these results can be obtained efficiently: Careful network re-purposing and a novel application of the 'hole' algorithm from the wavelet community allow dense computation of neural net responses at 8 frames per second on a modern GPU.},
  author   = {Liang-Chieh Chen and George Papandreou and Iasonas Kokkinos and Kevin Murphy and Alan L. Yuille},
  doi      = {10.48550/arxiv.1412.7062},
  month    = {12},
  pages    = {1-12},
  title    = {Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs},
  url      = {https://arxiv.org/abs/1412.7062v4},
  year     = {2014}
}
@article{He2014,
  abstract  = {Existing deep convolutional neural networks (CNNs) require a fixed-size (e.g., 224x224) input image. This requirement is "artificial" and may reduce the recognition accuracy for the images or sub-images of an arbitrary size/scale. In this work, we equip the networks with another pooling strategy, "spatial pyramid pooling", to eliminate the above requirement. The new network structure, called SPP-net, can generate a fixed-length representation regardless of image size/scale. Pyramid pooling is also robust to object deformations. With these advantages, SPP-net should in general improve all CNN-based image classification methods. On the ImageNet 2012 dataset, we demonstrate that SPP-net boosts the accuracy of a variety of CNN architectures despite their different designs. On the Pascal VOC 2007 and Caltech101 datasets, SPP-net achieves state-of-the-art classification results using a single full-image representation and no fine-tuning. The power of SPP-net is also significant in object detection. Using SPP-net, we compute the feature maps from the entire image only once, and then pool features in arbitrary regions (sub-images) to generate fixed-length representations for training the detectors. This method avoids repeatedly computing the convolutional features. In processing test images, our method is 24-102x faster than the R-CNN method, while achieving better or comparable accuracy on Pascal VOC 2007. In ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2014, our methods rank #2 in object detection and #3 in image classification among all 38 teams. This manuscript also introduces the improvement made for this competition.},
  author    = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
  doi       = {10.1007/978-3-319-10578-9_23},
  issue     = {PART 3},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  keywords  = {Image Classification,Index Terms-Convolutional Neural Networks,Object Detection !,Spatial Pyramid Pooling},
  month     = {6},
  pages     = {346-361},
  publisher = {Springer Verlag},
  title     = {Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition},
  volume    = {8691 LNCS},
  url       = {http://arxiv.org/abs/1406.4729 http://dx.doi.org/10.1007/978-3-319-10578-9_23},
  year      = {2014}
}
@article{Shelhamer2014,
  abstract  = {Convolutional networks are powerful visual models that yield hierarchies of
               features. We show that convolutional networks by themselves, trained
               end-to-end, pixels-to-pixels, exceed the state-of-the-art in semantic
               segmentation. Our key insight is to build "fully convolutional" networks that
               take input of arbitrary size and produce correspondingly-sized output with
               efficient inference and learning. We define and detail the space of fully
               convolutional networks, explain their application to spatially dense prediction
               tasks, and draw connections to prior models. We adapt contemporary
               classification networks (AlexNet, the VGG net, and GoogLeNet) into fully
               convolutional networks and transfer their learned representations by
               fine-tuning to the segmentation task. We then define a novel architecture that
               combines semantic information from a deep, coarse layer with appearance
               information from a shallow, fine layer to produce accurate and detailed
               segmentations. Our fully convolutional network achieves state-of-the-art
               segmentation of PASCAL VOC (20% relative improvement to 62.2% mean IU on 2012),
               NYUDv2, and SIFT Flow, while inference takes one third of a second for a
               typical image.},
  author    = {Evan Shelhamer and Jonathan Long and Trevor Darrell},
  doi       = {10.48550/arxiv.1411.4038},
  issn      = {01628828},
  issue     = {4},
  journal   = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  keywords  = {Convolutional Networks,Deep Learning,Semantic Segmentation,Transfer Learning},
  month     = {11},
  pages     = {640-651},
  pmid      = {27244717},
  publisher = {IEEE Computer Society},
  title     = {Fully Convolutional Networks for Semantic Segmentation},
  volume    = {39},
  url       = {https://arxiv.org/abs/1411.4038v2},
  year      = {2014}
}
@report{Girshick2015,
  abstract = {This paper proposes a Fast Region-based Convolutional Network method (Fast R-CNN) for object detection. Fast R-CNN builds on previous work to efficiently classify object proposals using deep convolutional networks. Compared to previous work, Fast R-CNN employs several innovations to improve training and testing speed while also increasing detection accuracy. Fast R-CNN trains the very deep VGG16 network 9× faster than R-CNN, is 213× faster at test-time, and achieves a higher mAP on PASCAL VOC 2012. Compared to SPPnet, Fast R-CNN trains VGG16 3× faster, tests 10× faster, and is more accurate. Fast R-CNN is implemented in Python and C++ (using Caffe) and is available under the open-source MIT License at https: //github.com/rbgirshick/fast-rcnn.},
  author   = {Ross Girshick},
  title    = {Fast R-CNN},
  url      = {https://github.com/rbgirshick/},
  year     = {2015}
}
@article{Ren2015,
  abstract  = {State-of-the-art object detection networks depend on region proposal
               algorithms to hypothesize object locations. Advances like SPPnet and Fast R-CNN
               have reduced the running time of these detection networks, exposing region
               proposal computation as a bottleneck. In this work, we introduce a Region
               Proposal Network (RPN) that shares full-image convolutional features with the
               detection network, thus enabling nearly cost-free region proposals. An RPN is a
               fully convolutional network that simultaneously predicts object bounds and
               objectness scores at each position. The RPN is trained end-to-end to generate
               high-quality region proposals, which are used by Fast R-CNN for detection. We
               further merge RPN and Fast R-CNN into a single network by sharing their
               convolutional features---using the recently popular terminology of neural
               networks with 'attention' mechanisms, the RPN component tells the unified
               network where to look. For the very deep VGG-16 model, our detection system has
               a frame rate of 5fps (including all steps) on a GPU, while achieving
               state-of-the-art object detection accuracy on PASCAL VOC 2007, 2012, and MS
               COCO datasets with only 300 proposals per image. In ILSVRC and COCO 2015
               competitions, Faster R-CNN and RPN are the foundations of the 1st-place winning
               entries in several tracks. Code has been made publicly available.},
  author    = {Shaoqing Ren and Kaiming He and Ross Girshick and Jian Sun},
  doi       = {10.48550/arxiv.1506.01497},
  issn      = {01628828},
  issue     = {6},
  journal   = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  keywords  = {Object detection,convolutional neural network,region proposal},
  month     = {6},
  pages     = {1137-1149},
  pmid      = {27295650},
  publisher = {IEEE Computer Society},
  title     = {Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks},
  volume    = {39},
  url       = {https://arxiv.org/abs/1506.01497v3},
  year      = {2015}
}
@article{Redmon2015,
  abstract  = {We present YOLO, a new approach to object detection. Prior work on object
               detection repurposes classifiers to perform detection. Instead, we frame object
               detection as a regression problem to spatially separated bounding boxes and
               associated class probabilities. A single neural network predicts bounding boxes
               and class probabilities directly from full images in one evaluation. Since the
               whole detection pipeline is a single network, it can be optimized end-to-end
               directly on detection performance. Our unified architecture is extremely fast. Our base YOLO model processes
               images in real-time at 45 frames per second. A smaller version of the network,
               Fast YOLO, processes an astounding 155 frames per second while still achieving
               double the mAP of other real-time detectors. Compared to state-of-the-art
               detection systems, YOLO makes more localization errors but is far less likely
               to predict false detections where nothing exists. Finally, YOLO learns very
               general representations of objects. It outperforms all other detection methods,
               including DPM and R-CNN, by a wide margin when generalizing from natural images
               to artwork on both the Picasso Dataset and the People-Art Dataset.},
  author    = {Joseph Redmon and Santosh Divvala and Ross Girshick and Ali Farhadi},
  doi       = {10.48550/arxiv.1506.02640},
  isbn      = {9781467388504},
  issn      = {10636919},
  journal   = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
  month     = {6},
  pages     = {779-788},
  publisher = {IEEE Computer Society},
  title     = {You Only Look Once: Unified, Real-Time Object Detection},
  volume    = {2016-December},
  url       = {https://arxiv.org/abs/1506.02640v5},
  year      = {2015}
}


% cross validation
@inbook{Refaeilzadeh2009,
  title     = {Cross-Validation},
  author    = {Refaeilzadeh, Payam and Tang, Lei and Liu, Huan},
  year      = 2009,
  booktitle = {Encyclopedia of Database Systems},
  publisher = {Springer US},
  address   = {Boston, MA},
  pages     = {532--538},
  doi       = {10.1007/978-0-387-39940-9_565},
  isbn      = {978-0-387-39940-9},
  url       = {https://doi.org/10.1007/978-0-387-39940-9_565},
  editor    = {LIU, LING and {\"O}ZSU, M. TAMER}
}
%    the embryo of an electronic computer that [the Navy] expects will be able
%    to walk, talk, see, write, reproduce itself and be conscious of its
%    existence.
@article{Olazaran1996,
  title     = {A Sociological Study of the Official History of the Perceptrons Controversy},
  author    = {Mikel Olazaran},
  year      = 1996,
  month     = aug,
  journal   = {Social Studies of Science},
  publisher = {{SAGE} Publications},
  volume    = 26,
  number    = 3,
  pages     = {611--659},
  doi       = {10.1177/030631296026003005},
  url       = {https://doi.org/10.1177/030631296026003005}
}
%https://towardsdatascience.com/regularization-in-machine-learning-76441ddcf99a
%https://towardsdatascience.com/l1-and-l2-regularization-methods-ce25e7fc831c
@article{McCulloch1943,
  title    = {A logical calculus of the ideas immanent in nervous activity},
  author   = {McCulloch, Warren S. and Pitts, Walter},
  year     = 1943,
  month    = {Dec},
  day      = {01},
  journal  = {The bulletin of mathematical biophysics},
  volume   = 5,
  number   = 4,
  pages    = {115--133},
  doi      = {10.1007/BF02478259},
  issn     = {1522-9602},
  url      = {https://doi.org/10.1007/BF02478259},
  abstract = {Because of the ``all-or-none'' character of nervous activity, neural events and the relations among them can be treated by means of propositional logic. It is found that the behavior of every net can be described in these terms, with the addition of more complicated logical means for nets containing circles; and that for any logical expression satisfying certain conditions, one can find a net behaving in the fashion it describes. It is shown that many particular choices among possible neurophysiological assumptions are equivalent, in the sense that for every net behaving under one assumption, there exists another net which behaves under the other and gives the same results, although perhaps not in the same time. Various applications of the calculus are discussed.}
}
@inproceedings{10.1007/978-3-642-70911-1_15,
  title     = {Donald Hebb: The Organization of Behavior},
  author    = {Shaw, G. L.},
  year      = 1986,
  booktitle = {Brain Theory},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {231--233},
  isbn      = {978-3-642-70911-1},
  editor    = {Palm, G{\"u}nther and Aertsen, Ad},
  abstract  = {I consider this a great privilege to be able to briefly remark on D.O. Hebb's marvellous book ``Organization of Behavior: A Neuropsychological Theory'' which he wrote in 1949. Hebb's ideas have had a profound influence on brain theory, in particular his famous ``A Neurophysiological Postulate'' governing the correlated pre-post synaptic changes which are the basis for the engram or memory trace. Although, there are many different forms of Hebb's postulate, I believe that essentially all ``viable'' mammalian cortical models embody some version of his idea: ``Let us assume then that the persistence or repetition of a reverberatory activity (or ``trace'') tends to induce lasting cellular changes that add to its stability. The assumption can be precisely stated as follows:When an axon of cell A is near enough to excite cell B and repeatedly or persistently takes part in firing it, some growth process or metabolic change takes place in one or both cells such that A `s efficiency, as one of the cells firing B, is increased''.}
}
@article{doi:10.1126/science.7912852,
  title    = {Rearrangements of Synaptic Connections in Visual Cortex Revealed by Laser Photostimulation},
  author   = {Matthew B. Dalva and Lawrence C. Katz},
  year     = 1994,
  journal  = {Science},
  volume   = 265,
  number   = 5169,
  pages    = {255--258},
  doi      = {10.1126/science.7912852},
  url      = {https://www.science.org/doi/abs/10.1126/science.7912852},
  eprint   = {\url{https://www.science.org/doi/pdf/10.1126/science.7912852}},
  abstract = {Assessing patterns of synaptic connections in the developing mammalian neocortex has relied primarily on anatomical studies. In a physiological approach described here, the patterns of synaptic connections in slices of developing ferret visual cortex were determined with scanning laser photostimulation. Functional synaptic inputs to pyramidal cells in cortical layers 2 and 3 originating from sites close to the neuronal cell body appeared at least 2 weeks before eye opening, prior to the formation of long-range horizontal connections. Extensive long-range horizontal connections appeared in the next 10 days of development. The number of local connections peaked at the time of eye opening; the number of these connections subsequently declined to the level found in the adult while the specificity of long-distance connections increased. Thus, the relative influence of local connections on the activity of layer 2 and layer 3 neurons declines as the cortex matures while the influence of longer range connections increases substantially.}
}
% NN OPTIMIZATION: Learning to Optimize
@article{Li2017,
  title    = {Learning to Optimize Neural Nets},
  author   = {Ke Li and Jitendra Malik},
  year     = 2017,
  month    = 3,
  url      = {http://arxiv.org/abs/1703.00441},
  abstract = {Learning to Optimize is a recently proposed framework for learning optimization algorithms using reinforcement learning. In this paper, we explore learning an optimization algorithm for training shallow neural nets. Such high-dimensional stochastic optimization problems present interesting challenges for existing reinforcement learning algorithms. We develop an extension that is suited to learning optimization algorithms in this setting and demonstrate that the learned optimization algorithm consistently outperforms other known optimization algorithms even on unseen tasks and is robust to changes in stochasticity of gradients and the neural net architecture. More specifically, we show that an optimization algorithm trained with the proposed method on the problem of training a neural net on MNIST generalizes to the problems of training neural nets on the Toronto Faces Dataset, CIFAR-10 and CIFAR-100.}
}
% NN OPTIMIZATION: Adam
@misc{kingma2015adam,
  title         = {Adam: A Method for Stochastic Optimization},
  author        = {Diederik P. Kingma and Jimmy Ba},
  year          = 2017,
  eprint        = {1412.6980},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}
% NN OPTIMIZATION: Overview
@misc{ruder2017overview,
  title         = {An overview of gradient descent optimization algorithms},
  author        = {Sebastian Ruder},
  year          = 2017,
  eprint        = {1609.04747},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}
# momentum
@article{QIAN1999145,
  title    = {On the momentum term in gradient descent learning algorithms},
  author   = {Ning Qian},
  year     = 1999,
  journal  = {Neural Networks},
  volume   = 12,
  number   = 1,
  pages    = {145--151},
  doi      = {10.1016/S0893-6080(98)00116-6},
  issn     = {0893-6080},
  url      = {https://www.sciencedirect.com/science/article/pii/S0893608098001166},
  keywords = {Momentum, Gradient descent learning algorithm, Damped harmonic oscillator, Critical damping, Learning rate, Speed of convergence},
  abstract = {A momentum term is usually included in the simulations of connectionist learning algorithms. Although it is well known that such a term greatly improves the speed of learning, there have been few rigorous studies of its mechanisms. In this paper, I show that in the limit of continuous time, the momentum parameter is analogous to the mass of Newtonian particles that move through a viscous medium in a conservative force field. The behavior of the system near a local minimum is equivalent to a set of coupled and damped harmonic oscillators. The momentum term improves the speed of convergence by bringing some eigen components of the system closer to critical damping. Similar results can be obtained for the discrete time case used in computer simulations. In particular, I derive the bounds for convergence on learning-rate and momentum parameters, and demonstrate that the momentum term can increase the range of learning rate over which the system converges. The optimal condition for convergence is also analyzed.}
}
# NAG
@inproceedings{Nesterov1983AMF,
  title  = {A method for unconstrained convex minimization problem with the rate of convergence o(1/k\ensuremath{^2})},
  author = {Yurii Nesterov},
  year   = 1983
}
# adagrad
@article{JMLR:v12:duchi11a,
  title   = {Adaptive Subgradient Methods for Online Learning and Stochastic Optimization},
  author  = {John Duchi and Elad Hazan and Yoram Singer},
  year    = 2011,
  journal = {Journal of Machine Learning Research},
  volume  = 12,
  number  = 61,
  pages   = {2121--2159},
  url     = {http://jmlr.org/papers/v12/duchi11a.html}
}
# adadelta
@misc{zeiler2012adadelta,
  title         = {ADADELTA: An Adaptive Learning Rate Method},
  author        = {Matthew D. Zeiler},
  year          = 2012,
  eprint        = {1212.5701},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}
@inproceedings{NIPS2014_5cce8ded,
  title     = {Delay-Tolerant Algorithms for Asynchronous Distributed Online Learning},
  author    = {McMahan, Brendan and Streeter, Matthew},
  year      = 2014,
  booktitle = {Advances in Neural Information Processing Systems},
  publisher = {Curran Associates, Inc.},
  volume    = 27,
  pages     = {},
  url       = {https://proceedings.neurips.cc/paper/2014/file/5cce8dede893813f879b873962fb669f-Paper.pdf},
  editor    = {Z. Ghahramani and M. Welling and C. Cortes and N. Lawrence and K. Q. Weinberger}
}

@inproceedings{Kothari2020,
  title     = {The final frontier: Deep learning in space},
  author    = {Vivek Kothari and Edgar Liberis and Nicholas D. Lane},
  year      = 2020,
  month     = 3,
  journal   = {HotMobile 2020 - Proceedings of the 21st International Workshop on Mobile Computing Systems and Applications},
  publisher = {Association for Computing Machinery, Inc},
  pages     = {45--49},
  doi       = {10.1145/3376897.3377864},
  isbn      = 9781450371162,
  abstract  = {Machine learning, particularly deep learning, is being increasing utilised in space applications, mirroring the groundbreaking success in many earthbound problems. Deploying a space device, e.g. a satellite, is becoming more accessible to small actors due to the development of modular satellites and commercial space launches, which fuels further growth of this area. Deep learning's ability to deliver sophisticated computational intelligence makes it an attractive option to facilitate various tasks on space devices and reduce operational costs. In thiswork,we identify deep learning in space as one of development directions for mobile and embedded machine learning. We collate various applications of machine learning to space data, such as satellite imaging, and describe how on-device deep learning can meaningfully improve the operation of a spacecraft, such as by reducing communication costs or facilitating navigation.We detail and contextualise compute platform of satellites and draw parallels with embedded systems and current research in deep learning for resource-constrained environments.},
  keywords  = {Autonomy,Deep Learning,Hardware in Space}
}
@misc{esa_ai,
  title   = {Artificial Intelligence in space},
  journal = {ESA},
  url     = {https://www.esa.int/Enabling_Support/Preparing_for_the_Future/Discovery_and_Preparation/Artificial_intelligence_in_space}
}
@article{Montavon2018,
  title     = {Methods for interpreting and understanding deep neural networks},
  author    = {Gr\'{e}goire Montavon and Wojciech Samek and Klaus Robert M\"{u}ller},
  year      = 2018,
  month     = 2,
  journal   = {Digital Signal Processing: A Review Journal},
  publisher = {Elsevier Inc.},
  volume    = 73,
  pages     = {1--15},
  doi       = {10.1016/j.dsp.2017.10.011},
  issn      = 10512004,
  abstract  = {This paper provides an entry point to the problem of interpreting a deep neural network model and explaining its predictions. It is based on a tutorial given at ICASSP 2017. As a tutorial paper, the set of methods covered here is not exhaustive, but sufficiently representative to discuss a number of questions in interpretability, technical challenges, and possible applications. The second part of the tutorial focuses on the recently proposed layer-wise relevance propagation (LRP) technique, for which we provide theory, recommendations, and tricks, to make most efficient use of it on real data.},
  keywords  = {Activation maximization,Deep neural networks,Layer-wise relevance propagation,Sensitivity analysis,Taylor decomposition}
}
@article{Sheu2020,
  title     = {Illuminating the Black Box: Interpreting Deep Neural Network Models for Psychiatric Research},
  author    = {Yi Han Sheu},
  year      = 2020,
  month     = 10,
  journal   = {Frontiers in Psychiatry},
  publisher = {Frontiers Media S.A.},
  volume    = 11,
  doi       = {10.3389/fpsyt.2020.551299},
  issn      = 16640640,
  abstract  = {Psychiatric research is often confronted with complex abstractions and dynamics that are not readily accessible or well-defined to our perception and measurements, making data-driven methods an appealing approach. Deep neural networks (DNNs) are capable of automatically learning abstractions in the data that can be entirely novel and have demonstrated superior performance over classical machine learning models across a range of tasks and, therefore, serve as a promising tool for making new discoveries in psychiatry. A key concern for the wider application of DNNs is their reputation as a ``black box'' approach--i.e., they are said to lack transparency or interpretability of how input data are transformed to model outputs. In fact, several existing and emerging tools are providing improvements in interpretability. However, most reviews of interpretability for DNNs focus on theoretical and/or engineering perspectives. This article reviews approaches to DNN interpretability issues that may be relevant to their application in psychiatric research and practice. It describes a framework for understanding these methods, reviews the conceptual basis of specific methods and their potential limitations, and discusses prospects for their implementation and future directions.},
  keywords  = {deep learning,deep neural networks,explainable AI,machine learning,model interpretability,psychiatry}
}
@article{goh2021multimodal,
  title   = {Multimodal Neurons in Artificial Neural Networks},
  author  = {Goh, Gabriel and \textdagger{}, Nick Cammarata and \textdagger{}, Chelsea Voss and Carter, Shan and Petrov, Michael and Schubert, Ludwig and Radford, Alec and Olah, Chris},
  year    = 2021,
  journal = {Distill},
  doi     = {10.23915/distill.00030},
  note    = {\url{https://distill.pub/2021/multimodal-neurons}}
}

@misc{molnar_2022,
  title   = {Interpretable machine learning},
  url     = {https://christophm.github.io/interpretable-ml-book/neural-networks.html},
  journal = {Chapter 10 Neural Network Interpretation},
  author  = {Molnar, Christoph},
  year    = {2022},
  month   = {Jan}
}


@article{IzzoGeodesyNet2021,
  title    = {Geodesy of irregular small bodies via neural density fields: geodesyNets},
  author   = {Dario Izzo and Pablo G\'{o}mez},
  year     = 2021,
  month    = 5,
  url      = {http://arxiv.org/abs/2105.13031},
  abstract = {We present a novel approach based on artificial neural networks, so-called geodesyNets, and present compelling evidence of their ability to serve as accurate geodetic models of highly irregular bodies using minimal prior information on the body. The approach does not rely on the body shape information but, if available, can harness it. GeodesyNets learn a three-dimensional, differentiable, function representing the body density, which we call neural density field. The body shape, as well as other geodetic properties, can easily be recovered. We investigate six different shapes including the bodies 101955 Bennu, 67P Churyumov-Gerasimenko, 433 Eros and 25143 Itokawa for which shape models developed during close proximity surveys are available. Both heterogeneous and homogeneous mass distributions are considered. The gravitational acceleration computed from the trained geodesyNets models, as well as the inferred body shape, show great accuracy in all cases with a relative error on the predicted acceleration smaller than 1\% even close to the asteroid surface. When the body shape information is available, geodesyNets can seamlessly exploit it and be trained to represent a high-fidelity neural density field able to give insights into the internal structure of the body. This work introduces a new unexplored approach to geodesy, adding a powerful tool to consolidated ones based on spherical harmonics, mascon models and polyhedral gravity.}
}
@article{IzzoBennu2021,
  title    = {Study of the asteroid Bennu using geodesyANNs and Osiris-Rex data},
  author   = {Moritz von Looz and Pablo Gomez and Dario Izzo},
  year     = 2021,
  month    = 9,
  url      = {http://arxiv.org/abs/2109.14427},
  abstract = {Asteroids and other small bodies in the solar system tend to have irregular shapes, owing to their low gravity. This irregularity does not only apply to the topology, but also to the underlying geology, potentially containing regions of different densities and materials. The topology can be derived from optical observations, while the mass density distribution of an object is only observable, to some extent, in its gravitational field. In a companion paper, we presented geodesyNets, a neural network approach to infer the mass density distribution of an object from measurements of its gravitational field. In the present work, we apply this approach to the asteroid Bennu using real data from the Osiris Rex mission. The mission measured the trajectories of not only the Osiris Rex spacecraft itself, but also of numerous pebble-sized rock particles which temporarily orbited Bennu. From these trajectory data, we obtain a representation of Bennu's mass density and validate it by propagating, in the resulting gravity field, multiple pebbles not used in the training process. The performance is comparable to that of a polyhedral gravity model of uniform density, but does not require a shape model. As little additional information is needed, we see this as a step towards autonomous on-board inversion of gravitational fields.}
}
@inproceedings{belinkov-etal-2020-interpretability,
  title     = {Interpretability and Analysis in Neural {NLP}},
  author    = {Belinkov, Yonatan  and Gehrmann, Sebastian  and Pavlick, Ellie},
  year      = 2020,
  month     = jul,
  booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts},
  publisher = {Association for Computational Linguistics},
  address   = {Online},
  pages     = {1--5},
  doi       = {10.18653/v1/2020.acl-tutorials.1},
  url       = {https://aclanthology.org/2020.acl-tutorials.1},
  abstract  = {While deep learning has transformed the natural language processing (NLP) field and impacted the larger computational linguistics community, the rise of neural networks is stained by their opaque nature: It is challenging to interpret the inner workings of neural network models, and explicate their behavior. Therefore, in the last few years, an increasingly large body of work has been devoted to the analysis and interpretation of neural network models in NLP. This body of work is so far lacking a common framework and methodology. Moreover, approaching the analysis of modern neural networks can be difficult for newcomers to the field. This tutorial aims to fill this gap and introduce the nascent field of interpretability and analysis of neural networks in NLP. The tutorial will cover the main lines of analysis work, such as structural analyses using probing classifiers, behavioral studies and test suites, and interactive visualizations. We will highlight not only the most commonly applied analysis methods, but also the specific limitations and shortcomings of current approaches, in order to inform participants where to focus future efforts.}
}
@article{DBLP:journals/corr/abs-2108-04840,
  title      = {Post-hoc Interpretability for Neural {NLP:} {A} Survey},
  author     = {Andreas Madsen and Siva Reddy and Sarath Chandar},
  year       = 2021,
  journal    = {CoRR},
  volume     = {abs/2108.04840},
  url        = {https://arxiv.org/abs/2108.04840},
  eprinttype = {arXiv},
  eprint     = {2108.04840},
  timestamp  = {Wed, 18 Aug 2021 19:45:42 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2108-04840.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}
@article{DBLP:journals/corr/abs-1802-00121,
  title      = {Interpreting CNNs via Decision Trees},
  author     = {Quanshi Zhang and Yu Yang and Ying Nian Wu and Song{-}Chun Zhu},
  year       = 2018,
  journal    = {CoRR},
  volume     = {abs/1802.00121},
  url        = {http://arxiv.org/abs/1802.00121},
  eprinttype = {arXiv},
  eprint     = {1802.00121},
  timestamp  = {Tue, 06 Jul 2021 11:50:29 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1802-00121.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}
@misc{planetary_data,
  title   = {IRAS Minor Planet Survey},
  author  = {Tedesco, E.F., P.V. Noah, M. Noah, and S.D. Price.},
  year    = 2004,
  journal = {NASA Planetary Data System},
  volume  = {abs/1802.00121},
  url     = {http://www.psi.edu/pds/resource/imps.html}
}
@misc{parfeni2020detection,
  title         = {Detection of asteroid trails in Hubble Space Telescope images using Deep Learning},
  author        = {Andrei A. Parfeni and Laurentiu I. Caramete and Andreea M. Dobre and Nguyen Tran Bach},
  year          = 2020,
  eprint        = {2010.15425},
  archiveprefix = {arXiv},
  primaryclass  = {astro-ph.IM}
}
@article{Chyba_Rabeendran_2021,
  title     = {A Two-stage Deep Learning Detection Classifier for the {ATLAS} Asteroid Survey},
  author    = {Amandin Chyba Rabeendran and Larry Denneau},
  year      = 2021,
  month     = {feb},
  journal   = {Publications of the Astronomical Society of the Pacific},
  publisher = {{IOP} Publishing},
  volume    = 133,
  number    = 1021,
  pages     = {034501},
  doi       = {10.1088/1538-3873/abc900},
  url       = {https://doi.org/10.1088/1538-3873/abc900},
  abstract  = {In this paper we present a two-step neural network model to separate detections of solar system objects from optical and electronic artifacts in data obtained with the ``Asteroid Terrestrial-impact Last Alert System'' (ATLAS), a near-Earth asteroid sky survey system. A convolutional neural network is used to classify small ``postage-stamp'' images of candidate detections of astronomical sources into eight classes, followed by a multi-layered perceptron that provides a probability that a temporal sequence of four candidate detections represents a real astronomical source. The goal of this work is to reduce the time delay between Near-Earth Object (NEO) detections and submission to the Minor Planet Center. Due to the rare and hazardous nature of NEOs, a low false negative rate is a priority for the model. We show that the model reaches 99.6\% accuracy on real asteroids in ATLAS data with a 0.4\% false negative rate. Deployment of this model on ATLAS has reduced the amount of NEO candidates that astronomers must screen by 90\%, thereby bringing ATLAS one step closer to full autonomy.}
}
@misc{bird2020model,
  title         = {Model Optimization for Deep Space Exploration via Simulators and Deep Learning},
  author        = {James Bird and Kellan Colburn and Linda Petzold and Philip Lubin},
  year          = 2020,
  eprint        = {2012.14092},
  archiveprefix = {arXiv},
  primaryclass  = {astro-ph.IM}
}
@article{https://doi.org/10.1029/JA083iA06p02637,
  title    = {Collision frequency of artificial satellites: The creation of a debris belt},
  author   = {Kessler, Donald J. and Cour-Palais, Burton G.},
  year     = 1978,
  journal  = {Journal of Geophysical Research: Space Physics},
  volume   = 83,
  number   = {A6},
  pages    = {2637--2646},
  doi      = {\url{https://doi.org/10.1029/JA083iA06p02637}},
  url      = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/JA083iA06p02637},
  eprint   = {\url{https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/JA083iA06p02637}},
  abstract = {As the number of artificial satellites in earth orbit increases, the probability of collisions between satellites also increases. Satellite collisions would produce orbiting fragments, each of which would increase the probability of further collisions, leading to the growth of a belt of debris around the earth. This process parallels certain theories concerning the growth of the asteroid belt. The debris flux in such an earth-orbiting belt could exceed the natural meteoroid flux, affecting future spacecraft designs. A mathematical model was used to predict the rate at which such a belt might form. Under certain conditions the belt could begin to form within this century and could be a significant problem during the next century. The possibility that numerous unobserved fragments already exist from spacecraft explosions would decrease this time interval. However, early implementation of specialized launch constraints and operational procedures could significantly delay the formation of the belt.}
}
@article{Ren2020,
  title     = {Pose Estimation of Uncooperative Unknown Space Objects from a Single Image},
  author    = {Ren, Xiaoyuan and Jiang, Libing and Wang, Zhuang},
  year      = 2020,
  month     = {Jul},
  day       = 18,
  journal   = {International Journal of Aerospace Engineering},
  publisher = {Hindawi},
  volume    = 2020,
  pages     = 9966311,
  doi       = {10.1155/2020/9966311},
  issn      = {1687-5966},
  url       = {https://doi.org/10.1155/2020/9966311},
  abstract  = {Estimating the 3D pose of the space object from a single image is an important but challenging work. Most of the existing methods estimate the 3D pose of known space objects and assume that the detailed geometry of a specific object is known. These methods are not available for unknown objects without the known geometry of the object. In contrast to previous works, this paper devotes to estimate the 3D pose of the unknown space object from a single image. Our method estimates not only the pose but also the shape of the unknown object from a single image. In this paper, a hierarchical shape model is proposed to represent the prior structure information of typical space objects. On this basis, the parameters of the pose and shape are estimated simultaneously for unknown space objects. Experimental results demonstrate the effectiveness of our method to estimate the 3D pose and infer the geometry of unknown typical space objects from a single image. Moreover, experimental results show the advantage of our approach over the methods relying on the known geometry of the object.}
}
@article{doi:10.1177/0954410021996129,
  title    = {Strategy for on-orbit space object classification using deep learning},
  author   = {Seongmin Lim and Jin-Hyung Kim and Hae-Dong Kim},
  year     = 2021,
  journal  = {Proceedings of the Institution of Mechanical Engineers, Part G: Journal of Aerospace Engineering},
  volume   = 235,
  number   = 15,
  pages    = {2326--2341},
  doi      = {10.1177/0954410021996129},
  url      = {https://doi.org/10.1177/0954410021996129},
  eprint   = {\url{https://doi.org/10.1177/0954410021996129}},
  abstract = {Since nanosatellites are spotlighted as a verification platform for space technology, new studies on on-orbit satellite servicing using nanosatellites are being conducted. This servicing is based on space robotics using vision-based sensors in the rendezvous state with a target satellite. The space environment, such as sunlight and Earth albedo, affects the mission. Simulation of the space environment on the ground is difficult, but the development of robust algorithms which reflect the effect is essential. In particular, missions such as active debris removal require a method for overcoming changes in any known information due to external factors such as collisions. This study proposes a new strategy on nanosatellite for on-orbit space object classification by applying deep learning to sensor-based orbit satellite service activity. When previously known information is changed, a method of online learning on orbit after obtaining additional data at a short relative distance can help determine the final service part. Using the images and point cloud data that simulate the space environment, we apply a convolutional neural network and PointNet to classify the objects. The learning environment is studied using a general desktop and a micro-graphics processing unit (GPU) board that can be mounted on a nanosatellite. For the training, we used self-produced data using 3D models of nanosatellites and asteroids with similar shapes, which are difficult to distinguish with existing algorithms. Consequently, the proposed strategy by the author shows feasibility of using nanosatellite's micro GPU for on-orbit space object classification, and it is verified that point cloud–based methods are more suitable by utilizing deep learning for nanosatellites. The proposed method with processor of nanosatellite is applicable to satellite service missions in orbit, such as capturing of robotic parts for extending life span or removing space debris.}
}
"Ted IR. IRAS-A-FPA-3-RDR-IMPS-V6.0. , ."
@inproceedings{8009786,
  title     = {Space target recognition based on deep learning},
  author    = {Zeng, Haoyue and Xia, Yong},
  year      = 2017,
  booktitle = {2017 20th International Conference on Information Fusion (Fusion)},
  volume    = {},
  number    = {},
  pages     = {1--5},
  doi       = {10.23919/ICIF.2017.8009786}
}
@inproceedings{Afshar2020,
  title     = {Simultaneous space object recognition and pose estimation by convolutional neural network},
  author    = {Afshar,R. and Chu,Z. and Lu,S.},
  year      = 2020,
  booktitle = {Proceedings of International Conference on Artificial Life and Robotics},
  volume    = 2020,
  pages     = {490--495},
  url       = {[www.scopus.com](http://www.scopus.com)},
  editor    = {},
  language  = {English}
}
@article{Takahashi2014,
  title    = {Small body surface gravity fields via spherical harmonic expansions},
  author   = {Takahashi, Yu and Scheeres, D. J.},
  year     = 2014,
  month    = {Jun},
  day      = {01},
  journal  = {Celestial Mechanics and Dynamical Astronomy},
  volume   = 119,
  number   = 2,
  pages    = {169--206},
  doi      = {10.1007/s10569-014-9552-9},
  issn     = {1572-9478},
  url      = {https://doi.org/10.1007/s10569-014-9552-9},
  abstract = {Conventional gravity field expressions are derived from Laplace's equation, the result being the spherical harmonic gravity field. This gravity field is said to be the exterior spherical harmonic gravity field, as its convergence region is outside the Brillouin (i.e., circumscribing) sphere of the body. In contrast, there exists its counterpart called the interior spherical harmonic gravity field for which the convergence region lies within the interior Brillouin sphere that is not the same as the exterior Brillouin sphere. Thus, the exterior spherical harmonic gravity field cannot model the gravitation within the exterior Brillouin sphere except in some special cases, and the interior spherical harmonic gravity field cannot model the gravitation outside the interior Brillouin sphere. In this paper, we will discuss two types of other spherical harmonic gravity fields that bridge the null space of the exterior/interior gravity field expressions by solving Poisson's equation. These two gravity fields are obtained by assuming the form of Helmholtz's equation to Poisson's equation. This method renders the gravitational potentials as functions of spherical Bessel functions and spherical harmonic coefficients. We refer to these gravity fields as the interior/exterior spherical Bessel gravity fields and study their characteristics. The interior spherical Bessel gravity field is investigated in detail for proximity operation purposes around small primitive bodies. Particularly, we apply the theory to asteroids Bennu (formerly 1999 RQ36) and Castalia to quantify its performance around both nearly spheroidal and contact-binary asteroids, respectively. Furthermore, comparisons between the exterior gravity field, interior gravity field, interior spherical Bessel gravity field, and polyhedral gravity field are made and recommendations are given in order to aid planning of proximity operations for future small body missions.}
}
@misc{carruba2022machine,
  title         = {Machine Learning applied to asteroid dynamics: an emerging research field},
  author        = {V. Carruba and S. Aljbaae and R. C. Domingos and M. Huaman and W. Barletta},
  year          = 2022,
  eprint        = {2110.06611},
  archiveprefix = {arXiv},
  primaryclass  = {astro-ph.EP}
}
@article{Izzo2021,
  title    = {Geodesy of irregular small bodies via neural density fields: geodesyNets},
  author   = {Dario Izzo and Pablo G\'{o}mez},
  year     = 2021,
  month    = 5,
  url      = {http://arxiv.org/abs/2105.13031},
  abstract = {We present a novel approach based on artificial neural networks, so-called geodesyNets, and present compelling evidence of their ability to serve as accurate geodetic models of highly irregular bodies using minimal prior information on the body. The approach does not rely on the body shape information but, if available, can harness it. GeodesyNets learn a three-dimensional, differentiable, function representing the body density, which we call neural density field. The body shape, as well as other geodetic properties, can easily be recovered. We investigate six different shapes including the bodies 101955 Bennu, 67P Churyumov-Gerasimenko, 433 Eros and 25143 Itokawa for which shape models developed during close proximity surveys are available. Both heterogeneous and homogeneous mass distributions are considered. The gravitational acceleration computed from the trained geodesyNets models, as well as the inferred body shape, show great accuracy in all cases with a relative error on the predicted acceleration smaller than 1\% even close to the asteroid surface. When the body shape information is available, geodesyNets can seamlessly exploit it and be trained to represent a high-fidelity neural density field able to give insights into the internal structure of the body. This work introduces a new unexplored approach to geodesy, adding a powerful tool to consolidated ones based on spherical harmonics, mascon models and polyhedral gravity.}
}
# estimation theory: landmark tracking
@article{Shuang2008,
  title    = {Landmark tracking based autonomous navigation schemes for landing spacecraft on asteroids},
  author   = {Li Shuang and Cui Pingyuan},
  year     = 2008,
  month    = 3,
  journal  = {Acta Astronautica},
  volume   = 62,
  pages    = {391--403},
  doi      = {10.1016/j.actaastro.2007.11.009},
  issn     = {00945765},
  abstract = {Autonomous optical navigation schemes for pinpoint landing of spacecraft on asteroids are considered. Due to the long communication delay and complicated dynamic environment close to asteroids, traditional spacecraft navigation and control using the deep space network (DSN) is not suitable for the precise landing of spacecraft on asteroids. Then it is necessary to develop new autonomous navigation algorithms for future asteroid sample and return missions. To meet this requirement, this paper presents two landmark tracking navigation algorithms based on nonlinear least squares (NLS) and extended Kalman filter (EKF). The validity of the proposed navigation schemes is confirmed by numerical simulation. \textcopyright{} 2007 Elsevier Ltd. All rights reserved.},
  issue    = {6-7},
  keywords = {Asteroid landing,Extended Kalman filter,Landmark tracking navigation,Nonlinear least squares}
}
# Elementary information theory
@book{ElementaryInformationTheory1979,
  title     = {Elementary information theory},
  author    = {Jones, D. S.},
  year      = 1979,
  publisher = {Clarendon Press ; Oxford University Press},
  address   = {Oxford; New York},
  language  = {English}
}
@book{Cover2006,
  title     = {Elements of Information Theory (Wiley Series in Telecommunications and Signal Processing)},
  author    = {Cover, Thomas M. and Thomas, Joy A.},
  year      = 2006,
  publisher = {Wiley-Interscience},
  address   = {USA},
  isbn      = {0471241954}
}
# new metric: D:JS
@generic{Endres2003,
  title     = {A new metric for probability distributions},
  author    = {Dominik M. Endres and Johannes E. Schindelin},
  year      = 2003,
  journal   = {IEEE Transactions on Information Theory},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  volume    = 49,
  pages     = {1858--1860},
  doi       = {10.1109/TIT.2003.813506},
  issn      = {00189448},
  abstract  = {We introduce a metric for probability distributions, which is bounded, information-theoretically motivated, and has a natural Bayesian interpretation. The square root of the well-known \ensuremath{\chi}2 distance is an asymptotic approximation to it. Moreover, it is a close relative of the capacitory discrimination and Jensen-Shannon divergence.},
  issue     = 7,
  keywords  = {Capacitory discrimination,Jensen-Shannon divergence,Metric,Triangle inequality,\ensuremath{\chi}2 distance}
}
@report{Fuglede2004,
  title  = {Jensen-Shannon Divergence and Hilbert space embedding},
  author = {Bent Fuglede and Flemming Tops\o{}e},
  year   = 2004,
  doi    = {10.1109/ISIT.2004.1365067},
  isbn   = {978-0-7803-8280-0}
}


@article{Tsuda2020,
  abstract  = {Hayabusa2 arrived at the C-type asteroid Ryugu in June 2018. During one and a half year of the Ryugu-proximity operation, we succeeded in two rovers landing, one lander landing, two spacecraft touchdown/sample collection, one kinetic impact operation and two tiny reflective balls and one rover orbiting. Among the two successful touchdowns, the second one succeeded in collecting subsurface material exposed by the kinetic impact operation. This paper describes the asteroid proximity operation activity of the Hayabusa2 mission, and gives an overview of the achievements done so far. Some important engineering and scientific activities, which have been done in synchronous with the spacecraft operations to tackle with unexpected Ryugu environment, are also described.},
  author    = {Yuichi Tsuda and Takanao Saiki and Fuyuto Terui and Satoru Nakazawa and Makoto Yoshikawa and Sei ichiro Watanabe},
  doi       = {10.1016/J.ACTAASTRO.2020.02.035},
  issn      = {0094-5765},
  journal   = {Acta Astronautica},
  keywords  = {Asteroid mission,Kinetic impact,Rover and lander,Sample return,Solar system exploration},
  month     = {6},
  pages     = {42-54},
  publisher = {Pergamon},
  title     = {Hayabusa2 mission status: Landing, roving and cratering on asteroid Ryugu},
  volume    = {171},
  year      = {2020}
}


@article{Schulman2017,
  abstract = {We propose a new family of policy gradient methods for reinforcement learning, which alternate between sampling data through interaction with the environment, and optimizing a "surrogate" objective function using stochastic gradient ascent. Whereas standard policy gradient methods perform one gradient update per data sample, we propose a novel objective function that enables multiple epochs of minibatch updates. The new methods, which we call proximal policy optimization (PPO), have some of the benefits of trust region policy optimization (TRPO), but they are much simpler to implement, more general, and have better sample complexity (empirically). Our experiments test PPO on a collection of benchmark tasks, including simulated robotic locomotion and Atari game playing, and we show that PPO outperforms other online policy gradient methods, and overall strikes a favorable balance between sample complexity, simplicity, and wall-time.},
  author   = {John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov},
  doi      = {10.48550/arxiv.1707.06347},
  month    = {7},
  title    = {Proximal Policy Optimization Algorithms},
  url      = {http://arxiv.org/abs/1707.06347},
  year     = {2017}
}
@article{Schulman2015,
  abstract = {We describe an iterative procedure for optimizing policies, with guaranteed monotonic improvement. By making several approximations to the theoretically-justified procedure, we develop a practical algorithm, called Trust Region Policy Optimization (TRPO). This algorithm is similar to natural policy gradient methods and is effective for optimizing large nonlinear policies such as neural networks. Our experiments demonstrate its robust performance on a wide variety of tasks: learning simulated robotic swimming, hopping, and walking gaits; and playing Atari games using images of the screen as input. Despite its approximations that deviate from the theory, TRPO tends to give monotonic improvement, with little tuning of hyperparameters.},
  author   = {John Schulman and Sergey Levine and Philipp Moritz and Michael I. Jordan and Pieter Abbeel},
  doi      = {10.48550/arxiv.1502.05477},
  month    = {2},
  title    = {Trust Region Policy Optimization},
  url      = {http://arxiv.org/abs/1502.05477},
  year     = {2015}
}

@article{Recht2019,
  abstract = { This article surveys reinforcement learning from the perspective of optimization and control, with a focus on continuous control applications. It reviews the general formulation, terminology, and typical experimental implementations of reinforcement learning as well as competing solution paradigms. In order to compare the relative merits of various techniques, it presents a case study of the linear quadratic regulator (LQR) with unknown dynamics, perhaps the simplest and best-studied problem in optimal control. It also describes how merging techniques from learning theory and control can provide nonasymptotic characterizations of LQR performance and shows that these characterizations tend to match experimental behavior. In turn, when revisiting more complex applications, many of the observed phenomena in LQR persist. In particular, theory and experiment demonstrate the role and importance of models and the cost of generality in reinforcement learning algorithms. The article concludes with a discussion of some of the challenges in designing learning systems that safely and reliably interact with complex and uncertain environments and how tools from reinforcement learning and control might be combined to approach these challenges. },
  author   = {Benjamin Recht},
  doi      = {10.1146/annurev-control-053018-023825},
  issue    = {1},
  journal  = {Annual Review of Control, Robotics, and Autonomous Systems},
  pages    = {253-279},
  title    = {A Tour of Reinforcement Learning: The View from Continuous Control},
  volume   = {2},
  url      = { 
              https://doi.org/10.1146/annurev-control-053018-023825
              
              },
  year     = {2019}
}
@article{Haarnoja2018,
  abstract = {Model-free deep reinforcement learning (RL) algorithms have been demonstrated
              on a range of challenging decision making and control tasks. However, these
              methods typically suffer from two major challenges: very high sample complexity
              and brittle convergence properties, which necessitate meticulous hyperparameter
              tuning. Both of these challenges severely limit the applicability of such
              methods to complex, real-world domains. In this paper, we propose soft
              actor-critic, an off-policy actor-critic deep RL algorithm based on the maximum
              entropy reinforcement learning framework. In this framework, the actor aims to
              maximize expected reward while also maximizing entropy. That is, to succeed at
              the task while acting as randomly as possible. Prior deep RL methods based on
              this framework have been formulated as Q-learning methods. By combining
              off-policy updates with a stable stochastic actor-critic formulation, our
              method achieves state-of-the-art performance on a range of continuous control
              benchmark tasks, outperforming prior on-policy and off-policy methods.
              Furthermore, we demonstrate that, in contrast to other off-policy algorithms,
              our approach is very stable, achieving very similar performance across
              different random seeds.},
  author   = {Tuomas Haarnoja and Aurick Zhou and Pieter Abbeel and Sergey Levine},
  doi      = {10.48550/arxiv.1801.01290},
  month    = {1},
  title    = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  url      = {https://arxiv.org/abs/1801.01290},
  year     = {2018}
}

@article{Fujimoto2018,
  abstract = {In value-based reinforcement learning methods such as deep Q-learning, function approximation errors are known to lead to overestimated value estimates and suboptimal policies. We show that this problem persists in an actor-critic setting and propose novel mechanisms to minimize its effects on both the actor and the critic. Our algorithm builds on Double Q-learning, by taking the minimum value between a pair of critics to limit overestimation. We draw the connection between target networks and overestimation bias, and suggest delaying policy updates to reduce per-update error and further improve performance. We evaluate our method on the suite of OpenAI gym tasks, outperforming the state of the art in every environment tested.},
  author   = {Scott Fujimoto and Herke van Hoof and David Meger},
  doi      = {10.48550/arxiv.1802.09477},
  month    = {2},
  title    = {Addressing Function Approximation Error in Actor-Critic Methods},
  url      = {http://arxiv.org/abs/1802.09477},
  year     = {2018}
}

@article{Hessel2017,
  abstract = {The deep reinforcement learning community has made several independent
              improvements to the DQN algorithm. However, it is unclear which of these
              extensions are complementary and can be fruitfully combined. This paper
              examines six extensions to the DQN algorithm and empirically studies their
              combination. Our experiments show that the combination provides
              state-of-the-art performance on the Atari 2600 benchmark, both in terms of data
              efficiency and final performance. We also provide results from a detailed
              ablation study that shows the contribution of each component to overall
              performance.},
  author   = {Matteo Hessel and Joseph Modayil and Hado van Hasselt and Tom Schaul and Georg Ostrovski and Will Dabney and Dan Horgan and Bilal Piot and Mohammad Azar and David Silver},
  doi      = {10.48550/arxiv.1710.02298},
  month    = {10},
  title    = {Rainbow: Combining Improvements in Deep Reinforcement Learning},
  url      = {https://arxiv.org/abs/1710.02298},
  year     = {2017}
}

@article{Schulman2015,
  abstract = {We describe an iterative procedure for optimizing policies, with guaranteed monotonic improvement. By making several approximations to the theoretically-justified procedure, we develop a practical algorithm, called Trust Region Policy Optimization (TRPO). This algorithm is similar to natural policy gradient methods and is effective for optimizing large nonlinear policies such as neural networks. Our experiments demonstrate its robust performance on a wide variety of tasks: learning simulated robotic swimming, hopping, and walking gaits; and playing Atari games using images of the screen as input. Despite its approximations that deviate from the theory, TRPO tends to give monotonic improvement, with little tuning of hyperparameters.},
  author   = {John Schulman and Sergey Levine and Philipp Moritz and Michael I. Jordan and Pieter Abbeel},
  doi      = {10.48550/arxiv.1502.05477},
  month    = {2},
  title    = {Trust Region Policy Optimization},
  url      = {http://arxiv.org/abs/1502.05477},
  year     = {2015}
}

@article{Rummery1994,
  author = {G. A. Rummery and G. A. Rummery and M. Niranjan},
  title  = {On-Line Q-Learning Using Connectionist Systems},
  url    = {http://130.203.136.95/viewdoc/summary?doi=10.1.1.17.2539},
  year   = {1994}
}
@article{Schulman2017,
  abstract = {We propose a new family of policy gradient methods for reinforcement learning, which alternate between sampling data through interaction with the environment, and optimizing a "surrogate" objective function using stochastic gradient ascent. Whereas standard policy gradient methods perform one gradient update per data sample, we propose a novel objective function that enables multiple epochs of minibatch updates. The new methods, which we call proximal policy optimization (PPO), have some of the benefits of trust region policy optimization (TRPO), but they are much simpler to implement, more general, and have better sample complexity (empirically). Our experiments test PPO on a collection of benchmark tasks, including simulated robotic locomotion and Atari game playing, and we show that PPO outperforms other online policy gradient methods, and overall strikes a favorable balance between sample complexity, simplicity, and wall-time.},
  author   = {John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov},
  doi      = {10.48550/arxiv.1707.06347},
  month    = {7},
  title    = {Proximal Policy Optimization Algorithms},
  url      = {http://arxiv.org/abs/1707.06347},
  year     = {2017}
}

@article{Mnih2016,
  abstract = {We propose a conceptually simple and lightweight framework for deep
              reinforcement learning that uses asynchronous gradient descent for optimization
              of deep neural network controllers. We present asynchronous variants of four
              standard reinforcement learning algorithms and show that parallel
              actor-learners have a stabilizing effect on training allowing all four methods
              to successfully train neural network controllers. The best performing method,
              an asynchronous variant of actor-critic, surpasses the current state-of-the-art
              on the Atari domain while training for half the time on a single multi-core CPU
              instead of a GPU. Furthermore, we show that asynchronous actor-critic succeeds
              on a wide variety of continuous motor control problems as well as on a new task
              of navigating random 3D mazes using a visual input.},
  author   = {Volodymyr Mnih and Adrià Puigdomènech Badia and Mehdi Mirza and Alex Graves and Timothy P. Lillicrap and Tim Harley and David Silver and Koray Kavukcuoglu},
  doi      = {10.48550/arxiv.1602.01783},
  month    = {2},
  title    = {Asynchronous Methods for Deep Reinforcement Learning},
  url      = {https://arxiv.org/abs/1602.01783},
  year     = {2016}
}

@book{Wakker2015,
author = {Wakker, Karel},
year = {2015},
month = {01},
pages = {},
title = {Fundamentals of Astrodynamics},
isbn = {978-94-6186-419-2}
}

@article{Mnih2013,
  abstract = {We present the first deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. We apply our method to seven Atari 2600 games from the Arcade Learning Environment, with no adjustment of the architecture or learning algorithm. We find that it outperforms all previous approaches on six of the games and surpasses a human expert on three of them.},
  author   = {Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Alex Graves and Ioannis Antonoglou and Daan Wierstra and Martin Riedmiller},
  doi      = {10.48550/arxiv.1312.5602},
  month    = {12},
  title    = {Playing Atari with Deep Reinforcement Learning},
  url      = {http://arxiv.org/abs/1312.5602},
  year     = {2013}
}

@article{Cicek2021,
   abstract = {The experience replay mechanism allows agents to use the experiences multiple times. In prior works, the sampling probability of the transitions was adjusted according to their importance. Reassigning sampling probabilities for every transition in the replay buffer after each iteration is highly inefficient. Therefore, experience replay prioritization algorithms recalculate the significance of a transition when the corresponding transition is sampled to gain computational efficiency. However, the importance level of the transitions changes dynamically as the policy and the value function of the agent are updated. In addition, experience replay stores the transitions are generated by the previous policies of the agent that may significantly deviate from the most recent policy of the agent. Higher deviation from the most recent policy of the agent leads to more off-policy updates, which is detrimental for the agent. In this paper, we develop a novel algorithm, Batch Prioritizing Experience Replay via KL Divergence (KLPER), which prioritizes batch of transitions rather than directly prioritizing each transition. Moreover, to reduce the off-policyness of the updates, our algorithm selects one batch among a certain number of batches and forces the agent to learn through the batch that is most likely generated by the most recent policy of the agent. We combine our algorithm with Deep Deterministic Policy Gradient and Twin Delayed Deep Deterministic Policy Gradient and evaluate it on various continuous control tasks. KLPER provides promising improvements for deep deterministic continuous control algorithms in terms of sample efficiency, final performance, and stability of the policy during the training.},
   author = {Dogan C. Cicek and Enes Duran and Baturay Saglam and Furkan B. Mutlu and Suleyman S. Kozat},
   month = {11},
   title = {Off-Policy Correction for Deep Deterministic Policy Gradient Algorithms via Batch Prioritized Experience Replay},
   url = {http://arxiv.org/abs/2111.01865},
   year = {2021},
}


@article{Jang2016,
   abstract = {Categorical variables are a natural choice for representing discrete
structure in the world. However, stochastic neural networks rarely use
categorical latent variables due to the inability to backpropagate through
samples. In this work, we present an efficient gradient estimator that replaces
the non-differentiable sample from a categorical distribution with a
differentiable sample from a novel Gumbel-Softmax distribution. This
distribution has the essential property that it can be smoothly annealed into a
categorical distribution. We show that our Gumbel-Softmax estimator outperforms
state-of-the-art gradient estimators on structured output prediction and
unsupervised generative modeling tasks with categorical latent variables, and
enables large speedups on semi-supervised classification.},
   author = {Eric Jang and Shixiang Gu and Ben Poole},
   doi = {10.48550/arxiv.1611.01144},
   month = {11},
   title = {Categorical Reparameterization with Gumbel-Softmax},
   url = {https://arxiv.org/abs/1611.01144},
   year = {2016},
}


@article{Watkins1992,
  author   = {Watkins, Christopher J. C. H.
              and Dayan, Peter},
  title    = {Q-learning},
  journal  = {Machine Learning},
  year     = {1992},
  month    = {May},
  day      = {01},
  volume   = {8},
  number   = {3},
  pages    = {279-292},
  abstract = {Q-learning (Watkins, 1989) is a simple way for agents to learn how to act optimally in controlled Markovian domains. It amounts to an incremental method for dynamic programming which imposes limited computational demands. It works by successively improving its evaluations of the quality of particular actions at particular states.},
  issn     = {1573-0565},
  doi      = {10.1007/BF00992698},
  url      = {https://doi.org/10.1007/BF00992698}
}


@article{Kurniawati2021,
  abstract = {Planning under uncertainty is critical to robotics. The Partially Observable
              Markov Decision Process (POMDP) is a mathematical framework for such planning
              problems. It is powerful due to its careful quantification of the
              non-deterministic effects of actions and partial observability of the states.
              But precisely because of this, POMDP is notorious for its high computational
              complexity and deemed impractical for robotics. However, since early 2000,
              POMDPs solving capabilities have advanced tremendously, thanks to
              sampling-based approximate solvers. Although these solvers do not generate the
              optimal solution, they can compute good POMDP solutions that significantly
              improve the robustness of robotics systems within reasonable computational
              resources, thereby making POMDPs practical for many realistic robotics
              problems. This paper presents a review of POMDPs, emphasizing computational
              issues that have hindered its practicality in robotics and ideas in
              sampling-based solvers that have alleviated such difficulties, together with
              lessons learned from applying POMDPs to physical robots.},
  author   = {Hanna Kurniawati},
  doi      = {10.48550/arxiv.2107.07599},
  month    = {7},
  title    = {Partially Observable Markov Decision Processes (POMDPs) and Robotics},
  url      = {https://arxiv.org/abs/2107.07599v1},
  year     = {2021}
}


@article{Astrom1965,
  author    = {{Åström, Karl Johan}},
  issn      = {{0022-247X}},
  language  = {{eng}},
  pages     = {{174--205}},
  publisher = {{Elsevier}},
  series    = {{Journal of Mathematical Analysis and Applications}},
  title     = {{Optimal Control of Markov Processes with Incomplete State Information I}},
  url       = {{https://lup.lub.lu.se/search/files/5323668/8867085.pdf}},
  doi       = {{10.1016/0022-247X(65)90154-X}},
  volume    = {{10}},
  year      = {{1965}}
}

@report{Shin2014,
  title  = {201 Frequency and Channel Assignments},
  author = {Dong K. Shin},
  year   = 2014,
  url    = {http://deepspace.jpl.nasa.gov/dsndocs/810-005/}
}
@report{Berner2020,
  title  = {201 Frequency and Channel Assignments, Rev. D},
  author = {Jeff Berner},
  year   = 2020,
  url    = {https://deepspace.jpl.nasa.gov/dsndocs/810-005/201/201D.pdf}
}

@article{Bellman1954,
  author    = {Richard Bellman},
  doi       = {bams/1183519147},
  issue     = {6},
  journal   = {Bulletin of the American Mathematical Society},
  pages     = {503 – 515},
  publisher = {American Mathematical Society},
  title     = {The theory of dynamic programming},
  volume    = {60},
  url       = {https://doi.org/},
  year      = {1954}
}

@book{Bellman1957a,
  abstract  = {An introduction to the mathematical theory of multistage decision processes, this text takes a "functional equation" approach to the discovery of optimum policies. Written by a leading developer of such policies, it presents a series of methods, uniqueness and existence theorems, and examples for solving the relevant equations. The text examines existence and uniqueness theorems, the optimal inventory equation, bottleneck problems in multistage production processes, a new formalism in the calculus of variation, strategies behind multistage games, and Markovian decision processes. Each chapter concludes with a problem set that Eric V. Denardo of Yale University, in his informative new introduction, calls "a rich lode of applications and research topics." 1957 edition. 37 figures.},
  author    = {Richard Bellman},
  isbn      = {9780486428093},
  keywords  = {book dynamic programming},
  publisher = {Dover Publications},
  title     = {Dynamic Programming},
  year      = {1957}
}
@article{Bellman1957b,
  author    = {Richard Bellman},
  issn      = {00959057, 19435274},
  issue     = {5},
  journal   = {Journal of Mathematics and Mechanics},
  pages     = {679-684},
  publisher = {Indiana University Mathematics Department},
  title     = {A Markovian Decision Process},
  volume    = {6},
  url       = {http://www.jstor.org/stable/24900506},
  year      = {1957}
}

@article{Dirkx2019,
  title     = {Laser and radio tracking for planetary science missions--a comparison},
  author    = {Dominic Dirkx and Ivan Prochazka and Sven Bauer and Pieter Visser and Ron Noomen and Leonid I. Gurvits and Bert Vermeersen},
  year      = 2019,
  month     = 11,
  journal   = {Journal of Geodesy},
  publisher = {Springer},
  volume    = 93,
  pages     = {2405--2420},
  doi       = {10.1007/s00190-018-1171-x},
  issn      = 14321394,
  abstract  = {At present, tracking data for planetary missions largely consists of radio observables: range-rate (Doppler), range and angular position (VLBI/\ensuremath{\Delta} DOR). Future planetary missions may use Interplanetary Laser Ranging (ILR) as a tracking observable. Two-way ILR will provide range data that are about 2 orders of magnitude more accurate than radio-based range data. ILR does not produce Doppler data, however. In this article, we compare the relative strength of radio Doppler and laser range data for the retrieval of parameters of interest in planetary missions, to clarify and quantify the science case of ILR, with a focus on geodetic observables. We first provide an overview of the near-term attainable quality of ILR, in terms of both the realization of the observable and the models used to process the measurements. Subsequently, we analyse the sensitivity of radio Doppler and laser range measurements in representative mission scenarios for parameters of interest. We use both an analytical approximation and numerical analyses of the relative sensitivity of ILR and radio Doppler observables for more general cases. We show that mm-precise range normal points are feasible for ILR, but mm-level accuracy and stability in the full analysis chain are unlikely to be attained, due to a combination of instrumental and model errors. We find that ILR has the potential for superior performance in observing signatures in the data with a characteristic period of greater than 0.33–1.65 hours (assuming 2–10 mm uncertainty for range and 10~\ensuremath{\mu} m/s at 60~s for Doppler). This indicates that Doppler tracking will typically remain the method of choice for gravity field determination and spacecraft orbit determination in planetary missions. ILR data will be able to supplement the orbiter tracking data used for the estimation of parameters with a once-per-orbit signal. Laser ranging data, however, are shown to have a significant advantage for the retrieval of rotational and tidal characteristics from landers. Similarly, laser ranging data will be superior for the construction of planetary ephemerides and the improvement of solar system tests of gravitation, both for orbiter and for lander missions.},
  issue     = 11,
  keywords  = {Interplanetary laser ranging,Planetary missions,Radio tracking}
}
#ESTRACK
@inproceedings{Doat2018,
  title     = {Esa tracking network – a european asset},
  author    = {First Y. Doat and M. Lanucara and P. M. Besso and T. Beck and G. Lorenzo and M. Butkovic},
  year      = 2018,
  journal   = {15th International Conference on Space Operations, 2018},
  publisher = {American Institute of Aeronautics and Astronautics Inc, AIAA},
  doi       = {10.2514/6.2018-2306},
  isbn      = 9781624105623,
  abstract  = {The ESA Tracking Stations Network (ESTRACK) supports the Agency's and 3rd party spacecraft, during both critical and routine mission phases. In order to ensure the required continuous and reliable communication capability, a set of ground stations are placed at the Australian, American and European longitudes. In addition, an ESA terminal is hosted at Malindi, Kenya. As from 1968 this ground stations network has been augmented as mandated by mission requirements, whilst maintaining a general-purpose character to the maximum extent possible. The latter ensures integrity of the network, common interfaces to control centers, efficient spare holding capabilities, and thus its cost efficient operations and maintenance. After having developed and operated a European network supporting low and near Earth spacecraft (e.g. Kiruna, Redu, Kourou), in the last years ESA focus has been put on the sustaining and development of a LEOP infrastructure (Kourou, Malindi and New-Norcia) and deep-space infrastructure (located in Australia, Spain and Argentina). At the same time, ESA has developed a partnership with cooperative agreements and commercial suppliers complementing the ESA capabilities for the support of critical and routine operations in the earh-Earth domain. This paper focuses on the strategic evolution of ESTRACK, ensuring that such strategic asset for Europe will be able to support the ESA future missions roadmap.}
}
@report{Pham2020,
  title       = {Deep Space Network Services Catalog},
  author      = {Timothy Pham},
  year        = 2020,
  month       = 9,
  url         = {https://epdm.jpl.nasa.gov},
  abstract    = {Users must ensure that they are using the current version in EPDM: https://epdm.jpl.nasa.gov},
  institution = {Jet Propulsion Labratory}
}
#DSN
@report{Dsn2015,
  title  = {Deep Space Network Services Catalog},
  author = {Alaudin M Bhanji Dsn},
  year   = 2015,
  url    = {https://pdms.jpl.nasa.gov}
}
@article{Bertotti1993,
  title    = {{Doppler tracking of spacecraft with multi-frequency links}},
  author   = {{Bertotti}, B. and {Comoretto}, G. and {Iess}, L.},
  year     = 1993,
  month    = {mar},
  journal  = {Astronomy and Astrophysics},
  volume   = 269,
  number   = {1-2},
  pages    = {608--616},
  keywords = {Interplanetary Medium, Interplanetary Spacecraft, Solar Wind, Space Communication, Spacecraft Tracking, Data Links, Magnetohydrodynamic Turbulence, Space Communications, Spacecraft Communications, Command and Tracking},
  adsnote  = {Provided by the SAO/NASA Astrophysics Data System}
}
@article{Bauer2017,
  title     = {Analysis of one-way laser ranging data to LRO, time transfer and clock characterization},
  author    = {S. Bauer and H. Hussmann and J. Oberst and D. Dirkx and D. Mao and G. A. Neumann and E. Mazarico and M. H. Torrence and J. F. McGarry and D. E. Smith and M. T. Zuber},
  year      = 2017,
  month     = 2,
  journal   = {Icarus},
  publisher = {Academic Press Inc.},
  volume    = 283,
  pages     = {38--54},
  doi       = {10.1016/j.icarus.2016.09.026},
  issn      = 10902643,
  abstract  = {We processed and analyzed one-way laser ranging data from International Laser Ranging Service ground stations to NASA's Lunar Reconnaissance Orbiter (LRO), obtained from June 13, 2009 until September 30, 2014. We pair and analyze the one-way range observables from station laser fire and spacecraft laser arrival times by using nominal LRO orbit models based on the GRAIL gravity field. We apply corrections for instrument range walk, as well as for atmospheric and relativistic effects. In total we derived a tracking data volume of \approx{} 3000 hours featuring 64 million Full Rate and 1.5 million Normal Point observations. From a statistical analysis of the dataset we evaluate the experiment and the ground station performance. We observe a laser ranging measurement precision of 12.3 cm in case of the Full Rate data which surpasses the LOLA timestamp precision of 15 cm. The averaging to Normal Point data further reduces the measurement precision to 5.6 cm. We characterized the LRO clock with fits throughout the mission time and estimated the rate to 6.9\hspace{0.167em}\texttimes{}\hspace{0.167em}10-8, the aging to 1.6\hspace{0.167em}\texttimes{}\hspace{0.167em}10-12/day and the change of aging to 2.3\hspace{0.167em}\texttimes{}\hspace{0.167em}10-14 /day2over all mission phases. The fits also provide referencing of onboard time to the TDB time scale at a precision of 166 ns over two and 256 ns over all mission phases, representing ground to space time transfer. Furthermore we measure ground station clock differences from the fits as well as from simultaneous passes which we use for ground to ground time transfer from common view observations. We observed relative offsets ranging from 33 to 560 ns and relative rates ranging from 2\hspace{0.167em}\texttimes{}\hspace{0.167em}10-13 to 6\hspace{0.167em}\texttimes{}\hspace{0.167em}10-12 between the ground station clocks during selected mission phases. We study the results from the different methods and discuss their applicability for time transfer.},
  keywords  = {Laser ranging,Lunar Reconnaissance Orbiter,One-way,time transfer}
}
@article{Bauer2016,
  title     = {Demonstration of orbit determination for the Lunar Reconnaissance Orbiter using one-way laser ranging data},
  author    = {S. Bauer and H. Hussmann and J. Oberst and D. Dirkx and D. Mao and G. A. Neumann and E. Mazarico and M. H. Torrence and J. F. McGarry and D. E. Smith and M. T. Zuber},
  year      = 2016,
  month     = 9,
  journal   = {Planetary and Space Science},
  publisher = {Elsevier Ltd},
  volume    = 129,
  pages     = {32--46},
  doi       = {10.1016/j.pss.2016.06.005},
  issn      = {00320633},
  abstract  = {We used one-way laser ranging data from International Laser Ranging Service (ILRS) ground stations to NASA's Lunar Reconnaissance Orbiter (LRO) for a demonstration of orbit determination. In the one-way setup, the state of LRO and the parameters of the spacecraft and all involved ground station clocks must be estimated simultaneously. This setup introduces many correlated parameters that are resolved by using a priori constraints. Moreover the observation data coverage and errors accumulating from the dynamical and the clock modeling limit the maximum arc length. The objective of this paper is to investigate the effect of the arc length, the dynamical and modeling accuracy and the observation data coverage on the accuracy of the results. We analyzed multiple arcs using lengths of 2 and 7 days during a one-week period in Science Mission phase 02 (SM02, November 2010) and compared the trajectories, the post-fit measurement residuals and the estimated clock parameters. We further incorporated simultaneous passes from multiple stations within the observation data to investigate the expected improvement in positioning. The estimated trajectories were compared to the nominal LRO trajectory and the clock parameters (offset, rate and aging) to the results found in the literature. Arcs estimated with one-way ranging data had differences of 5–30 m compared to the nominal LRO trajectory. While the estimated LRO clock rates agreed closely with the a priori constraints, the aging parameters absorbed clock modeling errors with increasing clock arc length. Because of high correlations between the different ground station clocks and due to limited clock modeling accuracy, their differences only agreed at the order of magnitude with the literature. We found that the incorporation of simultaneous passes requires improved modeling in particular to enable the expected improvement in positioning. We found that gaps in the observation data coverage over 12 h (\approx{}6 successive LRO orbits) prevented the successful estimation of arcs with lengths shorter or longer than 2 or 7 days with our given modeling.},
  keywords  = {LRO,One-way laser ranging,Orbit determination}
}
# s-band
@article{Peltzer1966,
  title  = {Apollo Unified S-Band System NASA TM-X55492},
  author = {K. E. Peltzer},
  year   = 1966,
  month  = 4,
  url    = {https://history.nasa.gov/alsj/TM-X55492.pdf}
}
@article{Aitken1936,
  title     = {IV.--On Least Squares and Linear Combination of Observations},
  author    = {Aitken, A. C.},
  year      = 1936,
  journal   = {Proceedings of the Royal Society of Edinburgh},
  publisher = {Royal Society of Edinburgh Scotland Foundation},
  volume    = 55,
  pages     = {42–48},
  doi       = {10.1017/S0370164600014346},
  key       = {value},
  key       = {value}
}
# Iterative Methods for Optimization
@book{Kelley1999,
  title       = {Iterative Methods for Optimization (Frontiers in Applied Mathematics, Series Number 18)},
  author      = {C. T. Kelley},
  year        = 1987,
  month       = 1,
  isbn        = {978-0898714333},
  url         = {http://www.ec-securehost.com/SIAM/FR18.html.},
  city        = {Raleigh, North Carolina},
  institution = {North Carolina State University},
  edition     = {1st}
}
@inbook{Catherine2005,
  title  = {Radiometric Tracking Techniques for Deep Space Navigation},
  author = {Thornton, Catherine and Border, James},
  year   = 2005,
  month  = {01},
  doi    = {10.1002/0471728454.fmatter},
  isbn   = 9780471728450
}
@article{Berner2002,
  title   = {Operations Comparison of Deep Space Ranging Types: Sequential Tone vs. Pseudo-Noise},
  author  = {Jeff B. Berner and Scott H. Bryant},
  year    = 2002,
  month   = 4,
  journal = {Institute of Electrical and Electronics Engineers},
  doi     = {10.1109/AERO.2002.1035264}
}
@inbook{Soffel1989,
  title     = {Relativity in Astrometry, Celestial Mechanics and Geodesy},
  author    = {Soffel, Michael H.},
  year      = 1989,
  booktitle = {Relativity in Astrometry, Celestial Mechanics and Geodesy},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {1--31},
  doi       = {10.1007/978-3-642-73406-9_1},
  isbn      = {978-3-642-73406-9},
  url       = {https://doi.org/10.1007/978-3-642-73406-9_1},
  abstract  = {``Astrometry is the part of Astronomy that is devoted to the measurement of the positions, motions, distances, dimensions, and geometry of celestial bodies. Until the advent of Astrophysics a century ago, Astronomy consisted only of what is now called Astrometry and its theoretical counterpart --- Celestial Mechanics. Practically all that was known about the Universe at the turn of the present century was obtained uniquely by astrometric techniques.}
}
%@COMMENT { BibTex package created from National Library of Australia Catalogue https://catalogue.nla.gov.au  }
@book{nla.cat-vn866184,
  title         = {Nouvelles methodes pour la determination des orbites des cometes [microform] / par A.M. Legendre},
  author        = {Legendre, A. M.},
  year          = 1805,
  publisher     = {F. Didot Paris},
  pages         = {viii, 80 p., [1] leaf of plates :},
  type          = {Book, Microform},
  language      = {French},
  subjects      = {Comets -- Orbits.},
  life-dates    = {1970 - 1805},
  catalogue-url = {https://nla.gov.au/nla.cat-vn866184}
}
# kalman filter seed
@article{Kalman1960,
  title    = {A new approach to linear filtering and prediction problems},
  author   = {Rudolph Emil Kalman and Others},
  year     = 1960,
  journal  = {Journal of basic Engineering},
  volume   = 82,
  pages    = {35--45},
  issue    = 1,
  keywords = {filtering kalman}
}
# kalman filter results (seedling)
@article{Kalman1961,
  title     = {New Results in Linear Filtering and Prediction Theory},
  author    = {R E Kalman and R S Bucy},
  year      = 1961,
  journal   = {Journal of Basic Engineering},
  publisher = {ASME International},
  volume    = 83,
  pages     = 95,
  doi       = {10.1115/1.3658902},
  url       = {http://dx.doi.org/10.1115/1.3658902},
  issue     = 1,
  keywords  = {filtering kalman}
}
# EKF?
@inproceedings{Julier1997,
  title   = {New extension of the Kalman filter to nonlinear systems},
  author  = {Simon J Julier and Jeffrey K Uhlmann},
  year    = 1997,
  journal = {Defense, Security, and Sensing}
}
# ukf
@inproceedings{Wan2000,
  title   = {The unscented Kalman filter for nonlinear estimation},
  author  = {E A Wan and R Van Der Merwe},
  year    = 2000,
  journal = {Proceedings of the IEEE 2000 Adaptive Systems for Signal Processing, Communications, and Control Symposium (Cat. No.00EX373)},
  pages   = {153--158},
  doi     = {10.1109/ASSPCC.2000.882463}
}
# ukf
@book{Wan2001,
  title     = {The Unscented Kalman Filter},
  author    = {Eric A Wan and Rudolph van der Merwe},
  year      = 2001,
  journal   = {Kalman Filtering and Neural Networks},
  publisher = {John Wiley \& Sons, Ltd},
  pages     = {221--280},
  doi       = {\url{https://doi.org/10.1002/0471221546.ch7}},
  isbn      = 9780471221548,
  url       = {https://onlinelibrary.wiley.com/doi/abs/10.1002/0471221546.ch7},
  abstract  = {Summary This chapter discusses the underlying assumptions and flaws in the EKF, and presents an alternative filter with performance superior to that of the EKF: the unscented Kalman filter (UKF). Three application areas of nonlinear estimation in which the EKF has been applied are covered as follows: state estimation, parameter estimation, and dual estimation. An overview of the framework for these areas is briefly reviewed.},
  keywords  = {EKF,UKF parameter estimation,UPF experiments,dual estimation,optimal recursive estimation,particle filter,unscented Kalman filter}
}
@article{Cheng2011,
  title  = {Optimized selection of sigma points in the unscented Kalman filter},
  author = {Yiping Cheng and Ze Liu},
  year   = 2011,
  month  = 6,
  doi    = {10.1109/ICECENG.2011.6057978}
}
@report{Plett2005,
  title    = {Dual and Joint EKF for Simultaneous SOC and SOH Estimation},
  author   = {Gregory L Plett},
  year     = 2005,
  abstract = {A battery management system for HEV/BEV application must perform a number of estimation tasks in real time. In previous papers, we have presented methods for cell SOC estimation that use extended Kalman filters (EKF) as their basis. In this paper, we show how EKF may also be used to estimate power fade, capacity fade, and can keep the SOC estimate accurate throughout the lifetime of the cell, even though its dynamics change as it ages. Results are presented to demonstrate the efficacy of the new methods.},
  keywords = {Algorithmic,HEV,calculation,lithium polymer,state of charge}
}
# small bodies
@article{Davidsson2021,
  title   = {What do small bodies tell us about the formation of the Solar System and the conditions in the early solar nebula?},
  author  = {Bj\"{o}rn Davidsson and Julie Brisset and R Terik Daly and Tilmann Denk and Anton Ermakov and Lori Feaga and Maria Gritsevich and Tim Holt and Zhengwei Hu and Margaret Landis and Alice Lucchetti and Joe Masiero and Maurizio Pajola and Gal Sarid},
  year    = 2021,
  month   = 3,
  journal = {Bulletin of the AAS},
  volume  = 53,
  note    = {\url{https://baas.aas.org/pub/2021n4i058}},
  issue   = 4
}
@article{Klahr2015,
  title     = {Linking the Origin of Asteroids to Planetesimal Formation in the Solar Nebula},
  author    = {Hubert Klahr and Andreas Schreiber},
  year      = 2015,
  journal   = {Proceedings of the International Astronomical Union},
  publisher = {Cambridge University Press},
  volume    = 10,
  pages     = {1--8},
  doi       = {10.1017/S1743921315010406},
  issue     = {S318}
}
@article{Hein2020,
  title     = {A techno-economic analysis of asteroid mining},
  author    = {Andreas M. Hein and Robert Matheson and Dan Fries},
  year      = 2020,
  month     = 3,
  journal   = {Acta Astronautica},
  publisher = {Pergamon},
  volume    = 168,
  pages     = {104--115},
  doi       = {10.1016/J.ACTAASTRO.2019.05.009},
  issn      = {0094-5765},
  abstract  = {Asteroid mining has been proposed as an approach to complement Earth-based supplies of rare earth metals and to supply resources in space, such as water. However, existing studies on the economic viability of asteroid mining do not provide much guidance on which technological improvements would be needed for increasing its economic viability. This paper develops a techno-economic analysis of asteroid mining with the objective of providing basic recommendations for future technology development and performance improvements. Both, providing water in space as well as returning platinum to Earth are considered. Starting from first principles of techno-economic analysis, gradually additional economic and technological factors are added to the analysis model. Applied to mining missions involving spacecraft reuse, learning curve effect, and multiple spacecraft, their economic viability is assessed. A sensitivity analysis with respect to throughput rate, spacecraft mass, and resource price is performed. Furthermore, a sample asteroid mining architecture for volatiles based on small CubeSat-class spacecraft is presented. It is concluded that key technological drivers for asteroid mining missions are throughput rate, number of spacecraft per mission, and the rate in which successive missions are conducted. Furthermore, for returning platinum to Earth, market reaction strongly influences its economic viability and it seems to be economically viable only under unlikely conditions.},
  keywords  = {Asteroid mining,Platinum,Space economics,Techno-economic analysis}
}
% small sats
@article{Wells2006,
  title    = {SIMONE: Interplanetary microsatellites for NEO rendezvous missions},
  author   = {Nigel Wells and Roger Walker and Simon Green and Andrew Ball},
  year     = 2006,
  month    = 10,
  journal  = {Acta Astronautica},
  volume   = 59,
  pages    = {700--709},
  doi      = {10.1016/j.actaastro.2005.07.036},
  issn     = {00945765},
  abstract = {The paper summarises a novel mission concept called SIMONE (smallsat intercept missions to objects near Earth), whereby a fleet of microsatellites may be deployed to individually rendezvous with a number of near Earth objects (NEOs), at very low cost. The mission enables, for the first time, the diverse properties of a range of spectral and physical type NEOs to be determined. Such data are invaluable to the scientific study, impact damage prediction, and impact countermeasure planning of NEOs. The five identical 120 kg spacecraft are designed for low-cost piggyback launch on Ariane-5 into GTO, from where each uses a gridded-ion engine to escape the Earth and ultimately to rendezvous with a different NEO target. The primary challenge with such a mission is the ability to accommodate the necessary electric propulsion, power, payload and other on-board systems within the constraints of a microsatellite. The paper describes the way in which the latest technological advancements have been selected and applied to the mission design. The SIMONE design is feasible and clearly demonstrates that the concept of an "interplanetary microsatellite" is now realisable. \textcopyright{} 2005.},
  issue    = {8-11}
}
@inproceedings{Laurin2008,
  title     = {NEOSSat: a Canadian small space telescope for near Earth asteroid detection},
  author    = {Denis Laurin and Alan Hildebrand and Rob Cardinal and William Harvey and Siamak Tafazoli},
  year      = 2008,
  month     = 7,
  journal   = {Space Telescopes and Instrumentation 2008: Optical, Infrared, and Millimeter},
  publisher = {SPIE},
  volume    = 7010,
  pages     = 701013,
  doi       = {10.1117/12.789736},
  isbn      = 9780819472205,
  issn      = {0277786X}
}
@inproceedings{Scott2013,
  title   = {Toward Microsatellite Based Space Situational Awareness},
  author  = {L Scott and B Wallace and M Sale and S Thorsteinson},
  year    = 2013,
  month   = 9,
  journal = {Advanced Maui Optical and Space Surveillance Technologies Conference},
  pages   = {E40},
  editor  = {S Ryan}
}
@inproceedings{Yu2014,
  title   = {CubeSat: A candidate for the asteroid exploration in the future},
  author  = {Xiaozhou Yu and Jun Zhou},
  year    = 2014,
  journal = {2014 International Conference on Manipulation, Manufacturing and Measurement on the Nanoscale (3M-NANO)},
  pages   = {261--265},
  doi     = {10.1109/3M-NANO.2014.7057349}
}
@book{Lewis2015,
  title     = {Asteroid mining 101 : wealth for the new space economy},
  author    = {Lewis, John S. and Gump, David},
  year      = 2015,
  publisher = {Deep Space Industries, Inc.},
  address   = {[Moffett Field, California]},
  language  = {English}
}
# telescope apertures
@book{North2014,
  title     = {Observing Variable Stars, Novae and Supernovae},
  author    = {G North and N James},
  year      = 2014,
  publisher = {Cambridge University Press},
  isbn      = 9781107636125,
  url       = {https://books.google.co.za/books?id=IzoDBAAAQBAJ}
}
@article{chiu_2019,
  title     = {`It snuck up on us': Scientists stunned by `city-killer' asteroid that just missed Earth},
  author    = {Chiu, Allyson},
  year      = 2019,
  month     = 7,
  journal   = {The Washington Post},
  publisher = {Nash Holdings},
  url       = {https://www.washingtonpost.com/nation/2019/07/26/it-snuck-up-us-city-killer-asteroid-just-missed-earth-scientists-almost-didnt-detect-it-time/}
}
@online{IAU2019OK,
  title        = {MPEC 2019-O56 : 2019 OK},
  year         = 2019,
  month        = 7,
  day          = 24,
  journal      = {International Astronomical Union: The Minor Planet Electronic Circulars},
  note         = {Accessed: 2022-06-09},
  howpublished = {\url{https://minorplanetcenter.net/mpec/K19/K19O56.html}}
}
@online{NASA2019,
  title        = {2019 OK},
  year         = 2020,
  month        = 7,
  day          = 20,
  journal      = {NASA Science: Solar System Exploration},
  publisher    = {NASA},
  note         = {Accessed: 2022-06-09},
  howpublished = {\url{https://solarsystem.nasa.gov/asteroids-comets-and-meteors/asteroids/2019-ok/in-depth/}}
}
@report{Cellino1999,
  title    = {The Velocity–Size Relationship for Members of Asteroid Families and Implications for the Physics of Catastrophic Collisions},
  author   = {A Cellino and P Michel and P Tanga and V Zappa\`{\i} and P Paolicchi and A Dell'oro},
  year     = 1999,
  journal  = {Icarus},
  volume   = 141,
  pages    = {79--95},
  url      = {http://www.idealibrary.comon},
  abstract = {An extensive analysis of the size-ejection velocity relationship for members of several of the most important asteroid families identified in the Main Belt is presented. We have found a well defined behavior , with smaller fragments having on the average higher ejection velocities. The results provide useful constraints to current models of catastrophic breakup processes and lead also to a new estimate of the transition limit in largest remnant/parent body mass ratio, distinguishing cratering, and shattering regimes. Moreover, we have now available a practical method for estimating fragment ejection velocities in interasteroid collisional events. This can be easily implemented in numerical models of the collisional evolution of the asteroid belt. In particular, it should be possible to undertake a more quantitative assessment of the efficiency of collisional events in the Main Belt as the sources of near Earth asteroids of different sizes.}
}
@article{Rumpf2017,
  title     = {Asteroid impact effects and their immediate hazards for human populations},
  author    = {Clemens M Rumpf and Hugh G Lewis and Peter M Atkinson},
  year      = 2017,
  month     = 4,
  journal   = {Geophysical Research Letters},
  publisher = {American Geophysical Union (AGU)},
  volume    = 44,
  pages     = {3433--3440},
  doi       = {10.1002/2017gl073191},
  url       = {https://doi.org/10.1002\%2F2017gl073191},
  issue     = 8
}
@online{Mcgill2007,
  title        = {2019 OK},
  year         = 2007,
  journal      = {McGill University School of Computer Science},
  publisher    = {McGill University},
  note         = {Accessed: 2022-06-09},
  howpublished = {\url{https://www.cs.mcgill.ca/~rwest/wikispeedia/wpcd/wp/2/2004_Indian_Ocean_earthquake.htm}}
}
@online{TsarBomba2007,
  title        = {Big Ivan, The Tsar Bomba (``King of Bombs'')},
  year         = 2007,
  journal      = {The Nuclear Weapon Archive},
  note         = {Accessed: 2022-06-09},
  howpublished = {\url{http://www.nuclearweaponarchive.org/Russia/TsarBomba.html}}
}
@article{Khan2020,
  title     = {On Tsar Bomba the most powerful nuclear weapon ever tested},
  author    = {F A Khan},
  year      = 2020,
  month     = 10,
  journal   = {Physics Education},
  publisher = {IOP Publishing},
  volume    = 56,
  pages     = 13002,
  doi       = {10.1088/1361-6552/abbcbc},
  url       = {Https://doi.org/10.1088/1361-6552/abbcbc},
  abstract  = {Some useful quantities like mass consumed, mass involved in fusion, mass fissioned, energy density, temperature and pressure have been calculated for the most powerful nuclear weapon, Tsar Bomba. Besides, its calculated efficiency is compared with seven other nuclear devices.},
  issue     = 1
}
@article{Nirupama2006,
  title     = {Energetics of the Tsunami of 26 December 2004 in the Indian Ocean: A Brief Review},
  author    = {N Nirupama and T S Murty and I Nistor and A D Rao},
  year      = 2006,
  journal   = {Marine Geodesy},
  publisher = {Taylor \& Francis},
  volume    = 29,
  pages     = {39--47},
  doi       = {10.1080/01490410600582346},
  url       = {https://doi.org/10.1080/01490410600582346},
  issue     = 1
}
@article{malik1985,
  title        = {Yields of the Hiroshima and Nagasaki nuclear explosions},
  author       = {Malik, John},
  year         = 1985,
  month        = 9,
  doi          = {10.2172/1489669},
  url          = {https://www.osti.gov/biblio/1489669},
  abstractnote = {A. deterministic estimate of the nuclear radiation fields from the Hiroshima and Nagasaki nuclear weapon explosions requires the yields of these explosions. The yield of the Nagasaki explosion is rather well established by both fireball and radiochemical data from other tests as 21 kt. There are no equivalent data for the Hiroshima explosion. Equating thermal radiation and blast effects observed at the two cities subsequent to the explosions gives a yield of about 15 kt. The pressure-vs-time data, obtained by dropped, parachute-retarded canisters and reevaluated using 2-D hydrodynamic calculations, give a yield between 16 and 17 kt. Scaling the gamma-ray dose data and calculations gives a yield of about 15 kt. Sulfur neutron activation data give a yield of about 15 kt. The current best estimates for the yield of these explosions are the following: Hiroshima 15 kt Nagasaki 21 kt The outside limits of uncertainties in these values are believed to be 20 percent for Hiroshima and 10 percent for Nagasaki.},
  place        = {United States}
}
http://www.nuclearweaponarchive.org/Russia/TsarBomba.html
@article{Wainscoat2022,
  title     = {Regions of slow apparent motion of close approaching asteroids: The case of 2019 OK},
  author    = {Richard Wainscoat and Robert Weryk and Steven Chesley and Peter Vere\v{s} and Marco Micheli},
  year      = 2022,
  month     = 2,
  journal   = {Icarus},
  publisher = {Academic Press},
  volume    = 373,
  pages     = 114735,
  doi       = {10.1016/J.ICARUS.2021.114735},
  issn      = {0019-1035},
  abstract  = {Close approaching (or impacting) asteroids can have slow apparent motion in some directions in the sky as they approach Earth. For some objects that approach Earth from east of opposition, the induced topocentric motion coming from Earth's rotation cancels the natural eastward motion in the sky, making the object appear to be almost stationary, This makes discovery difficult. Near-Earth asteroid 2019 OK passed within about 70000 km of Earth on 2019 July 25.06. It evaded discovery inbound, and despite its \ensuremath{\sim{}}100 m size and approaching from the nighttime side of Earth, was first seen only about 24 h before closest approach. The reasons why various surveys did not detect it are analyzed. It is compared to a range of synthetic impactors and the appearance of impactors coming from various directions in the nighttime sky is discussed. 2019 OK appeared to be almost stationary, and as a result was not detected as a moving object. Some impacting objects approaching from east of opposition will likely have similar slow motion to 2019 OK. Detection of slow moving nearby objects is a new, unrecognized challenge for Near-Earth Object surveys.},
  keywords  = {Asteroids,Earth impact,Near-Earth Object}
}
@article{Marks2022,
  title   = {The Worst Case: Planetary Defense against a Doomsday Impactor},
  author  = {Joel Marks},
  year    = 2022,
  month   = 6,
  journal = {Space Policy},
  pages   = 101493,
  doi     = {10.1016/j.spacepol.2022.101493},
  issn    = {02659646},
  url     = {https://linkinghub.elsevier.com/retrieve/pii/S0265964622000194}
}
# asteroid avoidance
@inbook{Harris2015,
  title   = {Asteroid Impacts and Modern Civilization: Can We Prevent a Catastrophe?},
  author  = {Harris, A.W. and Boslough, M. and Chapman, C.R. and Drube, Line and Michel, Patrick},
  year    = 2015,
  month   = {01},
  journal = {Asteroids IV},
  pages   = {835--854},
  doi     = {10.2458/azu_uapress_9780816532131-ch042}
}

@article{Creswell2017,
  abstract = {Generative adversarial networks (GANs) provide a way to learn deep representations without extensively annotated training data. They achieve this through deriving backpropagation signals through a competitive process involving a pair of networks. The representations that can be learned by GANs may be used in a variety of applications, including image synthesis, semantic image editing, style transfer, image super-resolution and classification. The aim of this review paper is to provide an overview of GANs for the signal processing community, drawing on familiar analogies and concepts where possible. In addition to identifying different methods for training and constructing GANs, we also point to remaining challenges in their theory and application.},
  author   = {Antonia Creswell and Tom White and Vincent Dumoulin and Kai Arulkumaran and Biswa Sengupta and Anil A Bharath},
  doi      = {10.1109/MSP.2017.2765202},
  month    = {10},
  title    = {Generative Adversarial Networks: An Overview},
  url      = {http://arxiv.org/abs/1710.07035 http://dx.doi.org/10.1109/MSP.2017.2765202},
  year     = {2017}
}

@inbook{Clark2018,
  abstract  = {There are hundreds of thousands of known asteroids, yet only 14 have been visited by spacecraft thus far, and 9 of those were targets of opportunity. The remaining five asteroids (Braille, Eros, Itokawa, Vesta, and Ceres) were visited by four missions dedicated to asteroid research (Deep Space 1, NEAR-Shoemaker, Hayabusa, and Dawn, respectively). In fact, of these five asteroids, Vesta and Ceres are perhaps better defined as protoplanets because of their sizes and the emerging evidence for their physical and chemical evolution. Two more near-Earth asteroids will be visited in 2018, followed by even more visits in 2023 and 2030. This asteroid mission chronology is listed in Table 1.1. This chapter will tell the story of these asteroid missions and visit each of them in turn to briefly review some of the exciting science results. The story begins with asteroid 951 Gaspra and continues down the list in Table 1.1, according to the target asteroid name presented in chronological order.},
  author    = {Beth E. Clark and Maria A. Barucci and Xiao Duan Zou and Marcello Fulchignoni and Andrew Rivkin and Carol Raymond and Makoto Yoshikawa and Linda T. Elkins-Tanton and Hal Levison},
  doi       = {10.1016/B978-0-12-813325-5.00001-X},
  isbn      = {9780128133255},
  journal   = {Primitive Meteorites and Asteroids: Physical, Chemical, and Spectroscopic Observations Paving the Way to Exploration},
  keywords  = {Asteroid,Chemical evolution,Meteorite,Mission,Physical properties,Spacecraft},
  month     = {1},
  pages     = {1-57},
  publisher = {Elsevier},
  title     = {A brief history of spacecraft missions to asteroids and protoplanets},
  year      = {2018}
}

 @misc{vidhya_2022,
  title   = {20 questions to test your skills on CNN (Convolutional Neural Networks)},
  url     = {https://www.analyticsvidhya.com/blog/2021/05/20-questions-to-test-your-skills-on-cnn-convolutional-neural-networks/},
  journal = {Analytics Vidhya},
  year    = {2022},
  month   = {Jun}
} 

@report{Silver2014,
  abstract = {In this paper we consider deterministic policy gradient algorithms for reinforcement learning with continuous actions. The deterministic policy gradient has a particularly appealing form: it is the expected gradient of the action-value function. This simple form means that the deter-ministic policy gradient can be estimated much more efficiently than the usual stochastic policy gradient. To ensure adequate exploration, we introduce an off-policy actor-critic algorithm that learns a deterministic target policy from an exploratory behaviour policy. We demonstrate that deterministic policy gradient algorithms can significantly outperform their stochastic counterparts in high-dimensional action spaces.},
  author   = {David Silver and Nicolas Heess and Thomas Degris and Daan Wierstra and Martin Riedmiller},
  title    = {Deterministic Policy Gradient Algorithms},
  year     = {2014}
}

@article{Lillicrap2015,
  abstract = {We adapt the ideas underlying the success of Deep Q-Learning to the
              continuous action domain. We present an actor-critic, model-free algorithm
              based on the deterministic policy gradient that can operate over continuous
              action spaces. Using the same learning algorithm, network architecture and
              hyper-parameters, our algorithm robustly solves more than 20 simulated physics
              tasks, including classic problems such as cartpole swing-up, dexterous
              manipulation, legged locomotion and car driving. Our algorithm is able to find
              policies whose performance is competitive with those found by a planning
              algorithm with full access to the dynamics of the domain and its derivatives.
              We further demonstrate that for many of the tasks the algorithm can learn
              policies end-to-end: directly from raw pixel inputs.},
  author   = {Timothy P. Lillicrap and Jonathan J. Hunt and Alexander Pritzel and Nicolas Heess and Tom Erez and Yuval Tassa and David Silver and Daan Wierstra},
  doi      = {10.48550/arxiv.1509.02971},
  month    = {9},
  title    = {Continuous control with deep reinforcement learning},
  url      = {https://arxiv.org/abs/1509.02971},
  year     = {2015}
}


@report{Sutton2000,
  abstract = {Function approximation is essential to reinforcement learning, but the standard approach of approximating a value function and determining a policy from it has so far proven theoretically intractable. In this paper we explore an alternative approach in which the policy is explicitly represented by its own function approximator, independent of the value function, and is updated according to the gradient of expected reward with respect to the policy parameters. Williams's REINFORCE method and actor-critic methods are examples of this approach. Our main new result is to show that the gradient can be written in a form suitable for estimation from experience aided by an approximate action-value or advantage function. Using this result, we prove for the first time that a version of policy iteration with arbitrary differentiable function approximation is convergent to a locally optimal policy. Large applications of reinforcement learning (RL) require the use of generalizing function approximators such neural networks, decision-trees, or instance-based methods. The dominant approach for the last decade has been the value-function approach, in which all function approximation effort goes into estimating a value function, with the action-selection policy represented implicitly as the "greedy" policy with respect to the estimated values (e.g., as the policy that selects in each state the action with highest estimated value). The value-function approach has worked well in many applications , but has several limitations. First, it is oriented toward finding deterministic policies, whereas the optimal policy is often stochastic, selecting different actions with specific probabilities (e.g., see Singh, Jaakkola, and Jordan, 1994). Second, an arbitrarily small change in the estimated value of an action can cause it to be, or not be, selected. Such discontinuous changes have been identified as a key obstacle to establishing convergence assurances for algorithms following the value-function approach (Bertsekas and Tsitsiklis, 1996). For example, Q-Iearning, Sarsa, and dynamic programming methods have all been shown unable to converge to any policy for simple MDPs and simple function approximators (Gordon, 1995, 1996; Baird, 1995; Tsit-siklis and van Roy, 1996; Bertsekas and Tsitsiklis, 1996). This can occur even if the best approximation is found at each step before changing the policy, and whether the notion of "best" is in the mean-squared-error sense or the slightly different senses of residual-gradient, temporal-difference, and dynamic-programming methods. In this paper we explore an alternative approach to function approximation in RL.},
  author   = {Richard S Sutton and David Mcallester and Satinder Singh and Yishay Mansour},
  title    = {Policy Gradient Methods for Reinforcement Learning with Function Approximation}
}

@book{Sutton1998,
  added-at = {2019-07-13T10:11:53.000+0200},
  author   = {Sutton, Richard S. and Barto, Andrew G.},
  biburl   = {https://www.bibsonomy.org/bibtex/2f46601cf8b13d39d1378af0d79438b12/lanteunis},
  edition  = {Second}
}

@article{Hovell2020,
  abstract = {This paper introduces a novel technique, named deep guidance, that leverages deep reinforcement learning, a branch of artificial intelligence, that enables guidance strategies to be learned rather than designed. The deep guidance technique consists of a learned guidance strategy that feeds velocity commands to a conventional controller to track. Control theory is combined with deep reinforcement learning in order to lower the learning burden and facilitate the transfer of the trained system from simulation to reality. In this paper, a proof-of-concept spacecraft pose tracking and docking scenario is considered, in simulation and experiment, to test the feasibility of the proposed approach. Results show that such a system can be trained entirely in simulation and transferred to reality with comparable performance.},
  author   = {Kirk Hovell and Steve Ulrich},
  doi      = {10.2514/6.2020-1600},
  issue    = {January},
  title    = {On Deep Reinforcement Learning for Spacecraft Guidance},
  year     = {2020}
}

@article{Kolosa2019,
  abstract = {This dissertation explores a novel method of solving low-thrust spacecraft targeting prob- lems using reinforcement learning. A reinforcement learning algorithm based on Deep Determin- istic Policy Gradients was developed to solve low-thrust trajectory optimization problems. The algorithm consists of two neural networks, an actor network and a critic network. The actor ap- proximates a thrust magnitude given the current spacecraft state expressed as a set of orbital el- ements. The critic network evaluates the action taken by the actor based on the state and action taken. Three different types of trajectory problems were solved, a generalized orbit change maneu- ver, a semimajor axis change maneuver, and an inclination change maneuver. When training the algorithm in a simulated space environment, it was able to solve both the generalized orbit change and semimajor axis change maneuvers with no prior knowledge of the environment’s dynamics. The robustness of the algorithm was tested on an inclination change maneuver with a randomized set of initial states. After training, the algorithm was able to successfully generalize and solve new inclination changes that it has not seen before. This method has potential future applications in developing more complex low-thrust ma- neuvers or real-time autonomous spaceflight control.},
  author   = {Daniel S Kolosa},
  journal  = {Western Michigan University},
  title    = {A Reinforcement Learning Approach to Spacecraft Trajectory Optimization},
  year     = {2019}
}


@article{Schmidt2019,
  abstract = {State-of-the-art solutions in the areas of "Language Modelling & Generating
              Text", "Speech Recognition", "Generating Image Descriptions" or "Video Tagging"
              have been using Recurrent Neural Networks as the foundation for their
              approaches. Understanding the underlying concepts is therefore of tremendous
              importance if we want to keep up with recent or upcoming publications in those
              areas. In this work we give a short overview over some of the most important
              concepts in the realm of Recurrent Neural Networks which enables readers to
              easily understand the fundamentals such as but not limited to "Backpropagation
              through Time" or "Long Short-Term Memory Units" as well as some of the more
              recent advances like the "Attention Mechanism" or "Pointer Networks". We also
              give recommendations for further reading regarding more complex topics where it
              is necessary.},
  author   = {Robin M. Schmidt},
  doi      = {10.48550/arxiv.1912.05911},
  month    = {11},
  title    = {Recurrent Neural Networks (RNNs): A gentle Introduction and Overview},
  url      = {https://arxiv.org/abs/1912.05911},
  year     = {2019}
}

 @misc{Colah2015,
  title   = {Understanding LSTM networks},
  url     = {https://colah.github.io/posts/2015-08-Understanding-LSTMs/},
  journal = {Understanding LSTM Networks -- colah's blog}
} 

@article{Goodfellow2016,
  abstract = {This report summarizes the tutorial presented by the author at NIPS 2016 on generative adversarial networks (GANs). The tutorial describes: (1) Why generative modeling is a topic worth studying, (2) how generative models work, and how GANs compare to other generative models, (3) the details of how GANs work, (4) research frontiers in GANs, and (5) state-of-the-art image models that combine GANs with other methods. Finally, the tutorial contains three exercises for readers to complete, and the solutions to these exercises.},
  author   = {Ian Goodfellow},
  month    = {12},
  title    = {NIPS 2016 Tutorial: Generative Adversarial Networks},
  url      = {http://arxiv.org/abs/1701.00160},
  year     = {2016}
}


@article{Goodfellow2014,
  abstract = {We propose a new framework for estimating generative models via an
              adversarial process, in which we simultaneously train two models: a generative
              model G that captures the data distribution, and a discriminative model D that
              estimates the probability that a sample came from the training data rather than
              G. The training procedure for G is to maximize the probability of D making a
              mistake. This framework corresponds to a minimax two-player game. In the space
              of arbitrary functions G and D, a unique solution exists, with G recovering the
              training data distribution and D equal to 1/2 everywhere. In the case where G
              and D are defined by multilayer perceptrons, the entire system can be trained
              with backpropagation. There is no need for any Markov chains or unrolled
              approximate inference networks during either training or generation of samples.
              Experiments demonstrate the potential of the framework through qualitative and
              quantitative evaluation of the generated samples.},
  author   = {Ian J. Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio},
  doi      = {10.48550/arxiv.1406.2661},
  month    = {6},
  title    = {Generative Adversarial Networks},
  url      = {https://arxiv.org/abs/1406.2661},
  year     = {2014}
}

@article{Alqahtani2021,
  abstract  = {Generative adversarial networks (GANs) present a way to learn deep representations without extensively annotated training data. These networks achieve learning through deriving back propagation signals through a competitive process involving a pair of networks. The representations that can be learned by GANs may be used in several applications. GANs have made significant advancements and tremendous performance in numerous applications. The essential applications include semantic image editing, style transfer, image synthesis, image super-resolution and classification. This paper aims to present an overview of GANs, its different variants, and potential application in various domains. The paper attempts to identify GANs’ advantages, disadvantages and significant challenges to the successful implementation of GAN in different application areas. The main intention of this paper is to explore and present a comprehensive review of the crucial applications of GANs covering a variety of areas, study of the techniques and architectures used and further the contribution of that respective application in the real world. Finally, the paper ends with the conclusion and future aspects.},
  author    = {Hamed Alqahtani and Manolya Kavakli-Thorne and Gulshan Kumar},
  doi       = {10.1007/s11831-019-09388-y},
  issn      = {18861784},
  issue     = {2},
  journal   = {Archives of Computational Methods in Engineering},
  keywords  = {Generative adversarial networks,Neural networks,Supervised learning,Unsupervised learning},
  month     = {3},
  pages     = {525-552},
  publisher = {Springer Science and Business Media B.V.},
  title     = {Applications of Generative Adversarial Networks (GANs): An Updated Review},
  volume    = {28},
  year      = {2021}
}


@article{Creswell2017,
  abstract = {Generative adversarial networks (GANs) provide a way to learn deep representations without extensively annotated training data. They achieve this through deriving backpropagation signals through a competitive process involving a pair of networks. The representations that can be learned by GANs may be used in a variety of applications, including image synthesis, semantic image editing, style transfer, image super-resolution and classification. The aim of this review paper is to provide an overview of GANs for the signal processing community, drawing on familiar analogies and concepts where possible. In addition to identifying different methods for training and constructing GANs, we also point to remaining challenges in their theory and application.},
  author   = {Antonia Creswell and Tom White and Vincent Dumoulin and Kai Arulkumaran and Biswa Sengupta and Anil A Bharath},
  doi      = {10.1109/MSP.2017.2765202},
  month    = {10},
  title    = {Generative Adversarial Networks: An Overview},
  url      = {http://arxiv.org/abs/1710.07035 http://dx.doi.org/10.1109/MSP.2017.2765202},
  year     = {2017}
}


@article{Sitzmann2020,
  abstract = {Implicitly defined, continuous, differentiable signal representations
              parameterized by neural networks have emerged as a powerful paradigm, offering
              many possible benefits over conventional representations. However, current
              network architectures for such implicit neural representations are incapable of
              modeling signals with fine detail, and fail to represent a signal's spatial and
              temporal derivatives, despite the fact that these are essential to many
              physical signals defined implicitly as the solution to partial differential
              equations. We propose to leverage periodic activation functions for implicit
              neural representations and demonstrate that these networks, dubbed sinusoidal
              representation networks or Sirens, are ideally suited for representing complex
              natural signals and their derivatives. We analyze Siren activation statistics
              to propose a principled initialization scheme and demonstrate the
              representation of images, wavefields, video, sound, and their derivatives.
              Further, we show how Sirens can be leveraged to solve challenging boundary
              value problems, such as particular Eikonal equations (yielding signed distance
              functions), the Poisson equation, and the Helmholtz and wave equations. Lastly,
              we combine Sirens with hypernetworks to learn priors over the space of Siren
              functions.},
  author   = {Vincent Sitzmann and Julien N. P. Martel and Alexander W. Bergman and David B. Lindell and Gordon Wetzstein},
  doi      = {10.48550/arxiv.2006.09661},
  month    = {6},
  title    = {Implicit Neural Representations with Periodic Activation Functions},
  url      = {https://arxiv.org/abs/2006.09661},
  year     = {2020}
}


@inproceedings{sitzmann2019siren,
  author    = {Sitzmann, Vincent
               and Martel, Julien N.P.
               and Bergman, Alexander W.
               and Lindell, David B.
               and Wetzstein, Gordon},
  title     = {Implicit Neural Representations
               with Periodic Activation Functions},
  booktitle = {Proc. NeurIPS},
  year      = {2020}
}


@article{Ramachandran2017,
  abstract = {The choice of activation functions in deep networks has a significant effect on the training dynamics and task performance. Currently, the most successful and widely-used activation function is the Rectified Linear Unit (ReLU). Although various hand-designed alternatives to ReLU have been proposed, none have managed to replace it due to inconsistent gains. In this work, we propose to leverage automatic search techniques to discover new activation functions. Using a combination of exhaustive and reinforcement learning-based search, we discover multiple novel activation functions. We verify the effectiveness of the searches by conducting an empirical evaluation with the best discovered activation function. Our experiments show that the best discovered activation function, $f(x) = x \cdot \text\{sigmoid\}(\beta x)$, which we name Swish, tends to work better than ReLU on deeper models across a number of challenging datasets. For example, simply replacing ReLUs with Swish units improves top-1 classification accuracy on ImageNet by 0.9\% for Mobile NASNet-A and 0.6\% for Inception-ResNet-v2. The simplicity of Swish and its similarity to ReLU make it easy for practitioners to replace ReLUs with Swish units in any neural network.},
  author   = {Prajit Ramachandran and Barret Zoph and Quoc V. Le},
  doi      = {10.48550/arxiv.1710.05941},
  month    = {10},
  title    = {Searching for Activation Functions},
  url      = {http://arxiv.org/abs/1710.05941},
  year     = {2017}
}


@inproceedings{pmlr-v15-glorot11a,
  title     = {Deep Sparse Rectifier Neural Networks},
  author    = {Glorot, Xavier and Bordes, Antoine and Bengio, Yoshua},
  booktitle = {Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
  pages     = {315--323},
  year      = {2011},
  editor    = {Gordon, Geoffrey and Dunson, David and Dudík, Miroslav},
  volume    = {15},
  series    = {Proceedings of Machine Learning Research},
  address   = {Fort Lauderdale, FL, USA},
  month     = {11--13 Apr},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v15/glorot11a/glorot11a.pdf},
  url       = {https://proceedings.mlr.press/v15/glorot11a.html},
  abstract  = {While logistic sigmoid neurons are more biologically plausible than hyperbolic tangent neurons, the latter work better for training multi-layer neural networks. This paper shows that rectifying neurons are an even better model of biological neurons and yield equal or better performance than hyperbolic tangent networks in spite of the hard non-linearity and non-differentiability at zero, creating sparse representations with true zeros which seem remarkably suitable for naturally sparse data. Even though they can take advantage of semi-supervised setups with extra-unlabeled data, deep rectifier networks can reach their best performance without requiring any unsupervised pre-training on purely supervised tasks with large labeled datasets. Hence, these results can be seen as a new milestone in the attempts at understanding the difficulty in training deep but purely supervised neural networks, and closing the performance gap between neural networks learnt with and without unsupervised pre-training.}
}

@report{Maas2013,
  abstract = {Deep neural network acoustic models produce substantial gains in large vocabulary continuous speech recognition systems. Emerging work with rectified linear (ReL) hidden units demonstrates additional gains in final system performance relative to more commonly used sigmoidal nonlinearities. In this work, we explore the use of deep rectifier networks as acoustic models for the 300 hour Switchboard conversational speech recognition task. Using simple training procedures without pretraining, networks with rectifier nonlinearities produce 2% absolute reductions in word error rates over their sigmoidal counterparts. We analyze hidden layer representations to quantify differences in how ReL units encode inputs as compared to sigmoidal units. Finally, we evaluate a variant of the ReL unit with a gradient more amenable to optimization in an attempt to further improve deep rectifier networks.},
  author   = {Andrew L Maas and Awni Y Hannun and Andrew Y Ng},
  title    = {Rectifier Nonlinearities Improve Neural Network Acoustic Models},
  year     = {2013}
}


@article{Hara2015,
  abstract  = {Deep Learning is attracting much attention in object recognition and speech processing. A benefit of using the deep learning is that it provides automatic pre-training. Several proposed methods that include auto-encoder are being successfully used in various applications. Moreover, deep learning uses a multilayer network that consists of many layers, a huge number of units, and huge amount of data. Thus, executing deep learning requires heavy computation, so deep learning is usually utilized with parallel computation with many cores or many machines. Deep learning employs the gradient algorithm, however this traps the learning into the saddle point or local minima. To avoid this difficulty, a rectified linear unit (ReLU) is proposed to speed up the learning convergence. However, the reasons the convergence is speeded up are not well understood. In this paper, we analyze the ReLU by a using simpler network called the soft-committee machine and clarify the reason for the speedup. We also train the network in an on-line manner. The soft-committee machine provides a good test bed to analyze deep learning. The results provide some reasons for the speedup of the convergence of the deep learning.},
  author    = {Kazuyuki Hara and Daisuke Saito and Hayaru Shouno},
  doi       = {10.1109/IJCNN.2015.7280578},
  isbn      = {9781479919604},
  journal   = {Proceedings of the International Joint Conference on Neural Networks},
  keywords  = {Computers},
  month     = {9},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  title     = {Analysis of function of rectified linear unit used in deep learning},
  volume    = {2015-September},
  year      = {2015}
}


@report{Fahlman1988,
  abstract = {Most connectionist or "neural network" learning systems use some form of the back-propagation algorithm. However, back-propagation learning is too slow for many applications, and it scales up poorly as tasks become larger and more complex. The factors governing learning speed are poorly understood. I have begun a systematic, empirical study of learning speed in backprop-like algorithms, measured against a variety of benchmark problems. The goal is twofold: to develop faster learning algorithms and to contribute to the development of a methodology that will be of value in future studies of this kind. This paper is a progress report describing the results obtained during the first six months of this study. To date I have looked only at a limited set of benchmark problems, but the results on these are encouraging: I have developed a new learning algorithm that is faster than standard backprop by an order of magnitude or more and that appears to scale up very well as the problem size increases.},
  author   = {Scott E Fahlman},
  title    = {An Empirical Study of Learning Speed in Back-Propagation Networks},
  year     = {1988}
}


@article{Hart2018,
  abstract  = {In January 2017, Psyche and a second mission concept were selected by NASA for flight as part of the 14th Discovery mission competition. Assigned for an initial launch date in 2023, the Psyche team was given direction shortly after selection to research the possibility for earlier opportunities. Ultimately, the team was able to identify a launch opportunity in 2022 with a reduced flight time to its destination. This was accomplished in large part to crosscutting trades centered on the electrical power subsystem. These trades were facilitated through the Psyche mission's planned use of Solar Electric Propulsion (SEP), which enables substantial flexibility with respect to trajectory design. In combination with low-thrust trajectory analysis tools, the team was able to robustly converge to solutions with a higher fidelity and accuracy of results. These trades also took advantage of the 1300 series product line produced by Space Systems Loral (SSL), which enabled power growth while maintaining strong system-level heritage through its modular design that has been utilized on a large number of geostationary (GEO) communications satellites. This paper presents an overview of the Psyche mission concept, and the unique architecture that enables the use of commercially developed electric propulsion and space power systems from Space Systems Loral to provide flexibility in mission design. This paper then discusses the trades that allowed the Psyche team to meet a 2022 launch date.},
  author    = {William Hart and G. Mark Brown and Steven M. Collins and Maria De Soria-Santacruz Pich and Paul Fieseler and Dan Goebel and Danielle Marsh and David Y. Oh and Steve Snyder and Noah Warner and Gregory Whiffen and Linda T. Elkins-Tanton and James F. Bell and David J. Lawrence and Peter Lord and Zachary Pirkl},
  doi       = {10.1109/AERO.2018.8396444},
  isbn      = {9781538620144},
  issn      = {1095323X},
  journal   = {IEEE Aerospace Conference Proceedings},
  month     = {6},
  pages     = {1-20},
  publisher = {IEEE Computer Society},
  title     = {Overview of the spacecraft design for the Psyche mission concept},
  volume    = {2018-March},
  year      = {2018}
}


% DART 2022
@inproceedings{Cheng2012,
  abstract = {The Double Asteroid Redirection Test (DART) study has been undertaken by the Johns Hopkins Applied Physics Laboratory with support from members of NASA centers including the Goddard Space Flight Center, the Johnson Space Center, and the Jet Propulsion Laboratory, as one of two elements of a joint mission named Asteroid Impact & Deflection Assessment (AIDA), which is a first demonstration of asteroid deflection and a characterization of the kinetic impact effects. AIDA consists of two independent but mutually supporting missions, one of which is the asteroid kinetic impactor and the other is the characterization spacecraft. These two missions are, respectively, DART and the European Space Agency's Asteroid Impact Monitoring (AIM) mission. DART will be the first ever space mission to deflect the trajectory of an asteroid and measure the deflection to within 10\%. This will be done using a binary asteroid target with accurate determinations of orbital period by ground-based observations. DART will return vital data to determine the momentum transfer efficiency of the kinetic impact [1,2].},
  title    = {Dart: Double asteroid redirection test},
  author   = {A F Cheng and P Michel and C Reed and A Galvez and I Carnelli and Paris Headquarters},
  year     = 2012,
  journal  = {European Planetary Science Congress},
  volume   = 7,
  pages    = {23--28}
}


% Deep space 1 Braille
@article{Buratti2004,
  abstract  = {Spectra of Asteroid 9969 Braille in the 1.25-2.6 μm region returned by the Deep Space 1 (DS1) Mission show a ∼10% absorption band centered at 2 μm, and a reflectance peak at 1.6 μm. Analysis of these features suggest that the composition of Braille is roughly equal parts pyroxene and olivine. Its spectrum between 0.4 and 2.5 μm suggests that it is most closely related to the Q taxonomic type of asteroid. The spectrum also closely matches that of the ordinary chondrites, the most common type of terrestrial meteorite. The geometric albedo of Braille is unusually high (pv = 0.34), which is also consistent with its placement within the rarer classes of stony asteroids, and which suggests it has a relatively fresh, unweathered surface, perhaps due to a recent collision. © 2003 Elsevier Inc. All rights reserved.},
  author    = {Bonnie J. Buratti and D. T. Britt and L. A. Soderblom and M. D. Hicks and D. C. Boice and R. H. Brown and R. Meier and R. M. Nelson and J. Oberst and T. C. Owen and A. S. Rivkin and B. R. Sandel and S. A. Stern and N. Thomas and R. V. Yelle},
  doi       = {10.1016/J.ICARUS.2003.06.002},
  issn      = {0019-1035},
  issue     = {1},
  journal   = {Icarus},
  keywords  = {9969 Braille,Asteroids,Deep Space 1,NEOs},
  month     = {1},
  pages     = {129-135},
  publisher = {Academic Press},
  title     = {9969 Braille: Deep Space 1 infrared spectroscopy, geometric albedo, and classification},
  volume    = {167},
  year      = {2004}
}


% DART 2022
@article{Rivkin2021,
  title     = {The Double Asteroid Redirection Test (DART): Planetary Defense Investigations and Requirements},
  author    = {Andrew S Rivkin and Nancy L Chabot and Angela M Stickle and Cristina A Thomas and Derek C Richardson and Olivier Barnouin and Eugene G Fahnestock and Carolyn M Ernst and Andrew F Cheng and Steven Chesley and Shantanu Naidu and Thomas S Statler and Brent Barbee and Harrison Agrusa and Nicholas Moskovitz and R Terik Daly and Petr Pravec and Petr Scheirich and Elisabetta Dotto and Vincenzo Della Corte and Patrick Michel and Michael K\"{u}ppers and Justin Atchison and Masatoshi Hirabayashi},
  year      = 2021,
  month     = 8,
  journal   = {The Planetary Science Journal},
  publisher = {American Astronomical Society},
  volume    = 2,
  pages     = 173,
  doi       = {10.3847/psj/ac063e},
  url       = {https://doi.org/10.3847/psj/ac063e},
  abstract  = {The Double Asteroid Redirection Test (DART) is a Planetary Defense mission, designed to demonstrate the kinetic impactor technique on (65803) Didymos I Dimorphos, the secondary of the (65803) Didymos system. DART has four level 1 requirements to meet in order to declare mission success: (1) impact Dimorphos between 2022 September 25 and October 2, (2) cause at least a 73 s change in its binary orbit period via the impact, (3) measure the change in binary period to an uncertainty of 7.3 s or less, and (4) measure the momentum transfer efficiency (\ensuremath{\beta}) of the impact and characterize the resulting effects of the impact. The data necessary to achieve these requirements will be obtained and analyzed by the DART Investigation Team. We discuss the rationales for the data to be gathered, the analyses to be undertaken, and how mission success will be achieved.},
  issue     = 5
}
https://solarsystem.nasa.gov/asteroids-comets-and-meteors/asteroids/2019-ok/in-depth/
@article{Holsapple2012,
  abstract = {When an asteroid experiences an impact, its path is changed. How much it changes is important to know for both asteroid evolution studies and for attempts to prevent an asteroid from impacting the Earth. In an impact process the total momentum of the material is conserved. However, not all of the material is of interest, but only that remaining with the asteroid. The ratio of the change of momentum of the remaining asteroid to that of the impactor is called the momentum multiplication factor; and is commonly given the symbol β. It has been known for some time that β can be greater than unity, and in some cases far greater. That could be a significant factor in attempts to deflect an asteroid with an impact, and can also be important in the stirring of objects in the asteroid belt due to mutual impacts.The escaping crater ejecta are the source of the momentum multiplication. Housen and Holsapple (Housen, K.R., Holsapple, K.A. [2011a]. Icarus 211, 856-875) have given a recent summary of ejecta characteristics and scaling. Here we use those ejecta results to determine how β depends on the impactor properties, on the asteroid size and composition, and establish the paths and time of flight of all of the ejecta particles. The approach is to add the contribution of each element of ejected mass accounting for its initial velocity, its trajectory and whether it escapes the asteroid. The goal in this paper is to provide a theoretical framework of the fundamental results which can be used as a test of the veracity of experiments and detailed numerical calculations of impacts. A subsequent paper will present direct laboratory results and numerical simulations of momentum multiplication in various geological materials. © 2012 Elsevier Inc.},
  author   = {Keith A. Holsapple and Kevin R. Housen},
  doi      = {10.1016/j.icarus.2012.09.022},
  issn     = {00191035},
  issue    = {2},
  journal  = {Icarus},
  keywords = {Asteroids,Collisional physics,Cratering,Impact processes,Near-Earth objects},
  month    = {11},
  pages    = {875-887},
  title    = {Momentum transfer in asteroid impacts. I. Theory and scaling},
  volume   = {221},
  year     = {2012}
}
