Automatically generated by Mendeley Desktop 1.19.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Berners-lee2009,
author = {Berners-lee, Tim},
doi = {10.1016/b978-0-443-06885-0.50010-0},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Berners-lee{\_}2009{\_}How nerves work.pdf:pdf},
journal = {Auricular Acupuncture {\&} Addiction},
pages = {15--22},
title = {{How nerves work}},
year = {2009}
}
@incollection{Russel2010b,
author = {Russel, Stuart and Norvig, Peter},
booktitle = {Artificial Intelligence: a Modern Approach},
chapter = {21},
edition = {3rd},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Russel, Norvig{\_}2010{\_}Reinforcement Learning.pdf:pdf},
isbn = {9780136042594},
pages = {830--853},
publisher = {Upper Saddle River, NJ : Prentice Hall},
title = {{Reinforcement Learning}},
year = {2010}
}
@article{Schneider1994,
abstract = {If creativity is a reaction against the norm, then to understand and exploit creativity one must first understand and adequately represent this norm. In other words, to produce the extraordinary, as a human or as a machine, one must first understand the ordinary. Creativity is a large theme that manifests itself in many small ways in language, and in this paper we address one such manifestation of linguistic creativity, the comparison statement. Since linguistic comparisons run the gamut from the ordinary (mundane and commonplace) to the extraordinary (i.e., novel, striking and/or humorous), they provide an excellent vehicle for understanding the interplay between norms and creativity. Copyright {\textcopyright} 2008, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
author = {Schneider, E.D. and Kay, J.J.},
doi = {10.1016/0895-7177(94)90188-0},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Schneider, Kay{\_}1994{\_}Life as a manifestation of the second law of thermodynamics.pdf:pdf},
isbn = {9781577353591},
issn = {08957177},
journal = {Mathematical and Computer Modelling},
month = {mar},
number = {6-8},
pages = {25--48},
title = {{Life as a manifestation of the second law of thermodynamics}},
volume = {19},
year = {1994}
}
@article{Friston2011a,
abstract = {We have suggested that the mirror-neuron system might be usefully understood as implementing Bayes-optimal perception of actions emitted by oneself or others. To substantiate this claim, we present neuronal simulations that show the same representations can prescribe motor behavior and encode motor intentions during action-observation. These simulations are based on the free-energy formulation of active inference, which is formally related to predictive coding. In this scheme, (generalised) states of the world are represented as trajectories. When these states include motor trajectories they implicitly entail intentions (future motor states). Optimizing the representation of these intentions enables predictive coding in a prospective sense. Crucially, the same generative models used to make predictions can be deployed to predict the actions of self or others by simply changing the bias or precision (i.e. attention) afforded to proprioceptive signals. We illustrate these points using simulations of handwriting to illustrate neuronally plausible generation and recognition of itinerant (wandering) motor trajectories. We then use the same simulations to produce synthetic electrophysiological responses to violations of intentional expectations. Our results affirm that a Bayes-optimal approach provides a principled framework, which accommodates current thinking about the mirror-neuron system. Furthermore, it endorses the general formulation of action as active inference. {\textcopyright} 2011 Springer-Verlag.},
author = {Friston, Karl J. and Mattout, J{\'{e}}r{\'{e}}mie and Kilner, James M.},
doi = {10.1007/s00422-011-0424-z},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston, Mattout, Kilner{\_}2011{\_}Action understanding and active inference.pdf:pdf},
issn = {03401200},
journal = {Biological Cybernetics},
keywords = {Action-observation,Free-energy,Generative models,Inference,Mirror-neuron system,Perception,Precision,Predictive coding},
number = {1-2},
pages = {137--160},
title = {{Action understanding and active inference}},
volume = {104},
year = {2011}
}
@article{Shao2019,
archivePrefix = {arXiv},
arxivId = {arXiv:1912.10944v2},
author = {Shao, Kun and Tang, Zhentao and Zhu, Yuanheng and Li, Nannan and Zhao, Dongbin},
eprint = {arXiv:1912.10944v2},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Shao et al.{\_}2019{\_}A Survey of Deep Reinforcement Learning in Video Games.pdf:pdf},
journal = {ArXiv},
title = {{A Survey of Deep Reinforcement Learning in Video Games}},
year = {2019}
}
@article{Friston2015f,
abstract = {This paper considers communication in terms of inference about the behaviour of others (and our own behaviour). It is based on the premise that our sensations are largely generated by other agents like ourselves. This means, we are trying to infer how our sensations are caused by others, while they are trying to infer our behaviour: for example, in the dialogue between two speakers. We suggest that the infinite regress induced by modelling another agent - who is modelling you - can be finessed if you both possess the same model. In other words, the sensations caused by others and oneself are generated by the same process. This leads to a view of communication based upon a narrative that is shared by agents who are exchanging sensory signals. Crucially, this narrative transcends agency - and simply involves intermittently attending to and attenuating sensory input. Attending to sensations enables the shared narrative to predict the sensations generated by another (i.e. to listen), while attenuating sensory input enables one to articulate the narrative (i.e. to speak). This produces a reciprocal exchange of sensory signals that, formally, induces a generalised synchrony between internal (neuronal) brain states generating predictions in both agents. We develop the arguments behind this perspective, using an active (Bayesian) inference framework and offer some simulations (of birdsong) as proof of principle.},
author = {Friston, Karl and Frith, Christopher},
doi = {10.1016/j.concog.2014.12.003},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston, Frith{\_}2015{\_}A Duet for one(2).pdf:pdf},
issn = {10902376},
journal = {Consciousness and Cognition},
keywords = {Active inference,Attention,Bayesian,Communication,Generalised synchrony,Predictive coding,Sensory attenuation,Theory of mind},
pages = {390--405},
pmid = {25563935},
title = {{A Duet for one}},
volume = {36},
year = {2015}
}
@article{Friston2009b,
abstract = {This paper assumes that cortical circuits have evolved to enable inference about the causes of sensory input received by the brain. This provides a principled specification of what neural circuits have to achieve. Here, we attempt to address how the brain makes inferences by casting inference as an optimisation problem. We look at how the ensuing recognition dynamics could be supported by directed connections and message-passing among neuronal populations, given our knowledge of intrinsic and extrinsic neuronal connections. We assume that the brain models the world as a dynamic system, which imposes causal structure on the sensorium. Perception is equated with the optimisation or inversion of this internal model, to explain sensory input. Given a model of how sensory data are generated, we use a generic variational approach to model inversion to furnish equations that prescribe recognition; i.e., the dynamics of neuronal activity that represents the causes of sensory input. Here, we focus on a model whose hierarchical and dynamical structure enables simulated brains to recognise and predict sequences of sensory states. We first review these models and their inversion under a variational free-energy formulation. We then show that the brain has the necessary infrastructure to implement this inversion and present stimulations using synthetic birds that generate and recognise birdsongs. {\textcopyright} 2009 Elsevier Ltd. All rights reserved.},
annote = {This paper provides a mathematical model of hierarchical predictive coding and tests it on the generation and recognition of birdsongs.

Tags: [LPA][HEV][FCD][BDM][TMS][SUS]},
author = {Friston, Karl J. and Kiebel, Stefan J.},
doi = {10.1016/j.neunet.2009.07.023},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston, Kiebel{\_}2009{\_}Cortical circuits for perceptual inference.pdf:pdf},
issn = {08936080},
journal = {Neural Networks},
keywords = {Birdsong,Circuits,Dynamic,Free-energy,Generative models,Hierarchical,Nonlinear,Predictive coding,Variational},
number = {8},
pages = {1093--1104},
publisher = {Elsevier Ltd},
title = {{Cortical circuits for perceptual inference}},
url = {http://dx.doi.org/10.1016/j.neunet.2009.07.023},
volume = {22},
year = {2009}
}
@article{ODonoghue2020,
abstract = {Reinforcement learning (RL) combines a control problem with statistical estimation: The system dynamics are not known to the agent, but can be learned through experience. A recent line of research casts 'RL as inference' and suggests a particular framework to generalize the RL problem as probabilistic inference. Our paper surfaces a key shortcoming in that approach, and clarifies the sense in which RL can be coherently cast as an inference problem. In particular, an RL agent must consider the effects of its actions upon future rewards and observations: The exploration-exploitation tradeoff. In all but the most simple settings, the resulting inference is computationally intractable so that practical RL algorithms must resort to approximation. We demonstrate that the popular 'RL as inference' approximation can perform poorly in even very basic problems. However, we show that with a small modification the framework does yield algorithms that can provably perform well, and we show that the resulting algorithm is equivalent to the recently proposed K-learning, which we further connect with Thompson sampling.},
archivePrefix = {arXiv},
arxivId = {2001.00805},
author = {O'Donoghue, Brendan and Osband, Ian and Ionescu, Catalin},
eprint = {2001.00805},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/O'Donoghue, Osband, Ionescu{\_}2020{\_}Making Sense of Reinforcement Learning and Probabilistic Inference.pdf:pdf},
pages = {1--16},
title = {{Making Sense of Reinforcement Learning and Probabilistic Inference}},
year = {2020}
}
@article{Unknown,
author = {Adams, Rick A. and Shipp, Stewart and Friston, Karl J.},
doi = {10.1007/s00429-012-0475-5},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Adams, Shipp, Friston{\_}2013{\_}Predictions not commands active inference in the motor system.pdf:pdf},
issn = {1863-2653},
journal = {Brain Structure and Function},
month = {may},
number = {3},
pages = {611--643},
title = {{Predictions not commands: active inference in the motor system}},
url = {http://link.springer.com/10.1007/s00429-012-0475-5},
volume = {218},
year = {2013}
}
@incollection{Milnor1985,
abstract = {There is no agreement in the literature regarding the definition of$\backslash$nthe concept of attractor in dynamical systems theory. The purpose$\backslash$nof this paper is to propose another definition of this term, based$\backslash$non the concept of probable asymptotic behavior of orbits. Definitions$\backslash$nof attractor range from the concepts of Lyapunov stability and asymptotic$\backslash$nstability to the more specialized notion of Axiom A attractors. Different$\backslash$ndefinitions are due to {\{}$\backslash$it R. Williams{\}} [Publ. Math., Inst. Hautes$\backslash$nEtud. Sci. 43, 169--203 (1974; Zbl 0279.58013)], {\{}$\backslash$it D. Ruelle{\}}$\backslash$nand {\{}$\backslash$it F. Takens{\}} [Commun. Math. Phys. 23, 343--344 (1971; Zbl$\backslash$n0227.76084); see also ibid. 20, 167--192 (1971; Zbl 0223.76041)]$\backslash$nand {\{}$\backslash$it P. Collet{\}} and {\{}$\backslash$it J.-P. Eckmann{\}} [Iterated maps on the$\backslash$ninterval as dynamical systems. Progress in Physics, 1. Basel etc.:$\backslash$nBirkh{\"{a}}user (1980; Zbl 0458.58002)], among many others. After presenting$\backslash$nthe basic ingredients of all of these definitions, the author settles$\backslash$non the following definition: A closed subset A$\backslash$subset M is an attractor$\backslash$nif it satisfies (1) the realm of attraction $\rho$(A) consisting$\backslash$nof all points whose $\omega$-limit set lies in A, has positive$\backslash$nmeasure, and (2) there is no strictly smaller closed subset A'$\backslash$subset$\backslash$nA for which $\rho$(A') coincides with $\rho$(A) up to a set of$\backslash$nmeasure zero. The author applies this definition to a variety of$\backslash$nwell-known dynamical systems, including iterated maps of the interval$\backslash$nand strange attractors.},
address = {New York, NY},
author = {Milnor, John},
booktitle = {The Theory of Chaotic Attractors},
doi = {10.1007/978-0-387-21830-4_15},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Milnor{\_}1985{\_}On the Concept of Attractor.pdf:pdf},
pages = {243--264},
publisher = {Springer New York},
title = {{On the Concept of Attractor}},
volume = {195},
year = {1985}
}
@article{Hopfield1978,
abstract = {We hypothesize that the origin of the genetic code is associated with the structure of the tRNA that existed in primal cells. The sequences of modern tRNA contain correlations which can be understood as 'fossil' evidence of the secondary structure of primal tRNA. Kinetic proofreading through diffusion can amplify a low level of intrinsic selectivity of tRNA for its amino acid. Experimental tests of the theory are suggested.},
author = {Hopfield, John J.},
doi = {10.1073/pnas.75.9.4334},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Hopfield{\_}1978{\_}Origin of the genetic code a testable hypothesis based on tRNA structure, sequence, and kinetic proofreading.pdf:pdf},
issn = {00278424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
number = {9},
pages = {4334--4338},
title = {{Origin of the genetic code: a testable hypothesis based on tRNA structure, sequence, and kinetic proofreading}},
volume = {75},
year = {1978}
}
@article{Kappen2012,
abstract = {We reformulate a class of non-linear stochastic optimal control problems introduced by Todorov (in Advances in Neural Information Processing Systems, vol. 19, pp. 1369-1376, 2007) as a Kullback-Leibler (KL) minimization problem. As a result, the optimal control computation reduces to an inference computation and approximate inference methods can be applied to efficiently compute approximate optimal controls. We show how this KL control theory contains the path integral control method as a special case. We provide an example of a block stacking task and a multi-agent cooperative game where we demonstrate how approximate inference can be successfully applied to instances that are too complex for exact computation. We discuss the relation of the KL control approach to other inference approaches to control. {\textcopyright} The Author(s) 2012. This article is published with open access at Springerlink.com.},
archivePrefix = {arXiv},
arxivId = {0901.0633},
author = {Kappen, Hilbert J. and G{\'{o}}mez, Vicen{\c{c}} and Opper, Manfred},
doi = {10.1007/s10994-012-5278-7},
eprint = {0901.0633},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Kappen, G{\'{o}}mez, Opper{\_}2012{\_}Optimal control as a graphical model inference problem.pdf:pdf},
issn = {0885-6125},
journal = {Machine Learning},
keywords = {Approximate inference,Belief propagation,Cluster variation method,Graphical model,Kullback-leibler divergence,Optimal control,Uncontrolled dynamics},
month = {may},
number = {2},
pages = {159--182},
title = {{Optimal control as a graphical model inference problem}},
url = {http://link.springer.com/10.1007/s10994-012-5278-7},
volume = {87},
year = {2012}
}
@article{Harris2008,
abstract = {Classically, neurons communicate by anterograde conduction of action potentials. However, information can also pass backward along axons, a process that is essential during the development of the nervous system. Here we propose a role for such 'retroaxonal' signals in adult learning. We hypothesize that strengthening of a neuron's output synapses stabilizes recent changes in the same neuron's inputs. During learning, the input synapses of many neurons undergo transient changes, resulting in altered spiking activity. If this in turn promotes strengthening of output synapses, the recent synaptic changes will be stabilized; otherwise they will decay. A representation of sensory stimuli therefore evolves that is tailored to the demands of behavioral tasks. We describe a candidate molecular mechanism for this process involving the activation of CREB by retrograde neurotrophin signals. {\textcopyright} 2008 Elsevier Ltd. All rights reserved.},
author = {Harris, Kenneth D.},
doi = {10.1016/j.tins.2007.12.002},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Harris{\_}2008{\_}Stability of the fittest organizing learning through retroaxonal signals.pdf:pdf},
issn = {01662236},
journal = {Trends in Neurosciences},
number = {3},
pages = {130--136},
title = {{Stability of the fittest: organizing learning through retroaxonal signals}},
volume = {31},
year = {2008}
}
@incollection{Mumford1996,
author = {Mumford, David},
booktitle = {Perception as Bayesian Inference},
doi = {10.1017/CBO9780511984037.003},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Mumford{\_}1996{\_}Pattern theory A unifying perspective.pdf:pdf},
month = {sep},
pages = {188--224},
publisher = {Cambridge University Press},
title = {{Pattern theory: A unifying perspective}},
url = {https://www.cambridge.org/core/product/identifier/CBO9780511984037A010/type/book{\_}part},
year = {1996}
}
@article{Friston2009a,
abstract = {This paper considers prediction and perceptual categorization as an inference problem that is solved by the brain. We assume that the brain models the world as a hierarchy or cascade of dynamical systems that encode causal structure in the sensorium. Perception is equated with the optimization or inversion of these internal models, to explain sensory data. Given a model of how sensory data are generated, we can invoke a generic approach to model inversion, based on a free energy bound on the model's evidence. The ensuing free-energy formulation furnishes equations that prescribe the process of recognition, i.e. the dynamics of neuronal activity that represent the causes of sensory input. Here, we focus on a very general model, whose hierarchical and dynamical structure enables simulated brains to recognize and predict trajectories or sequences of sensory states. We first review hierarchical dynamical models and their inversion. We then show that the brain has the necessary infrastructure to implement this inversion and illustrate this point using synthetic birds that can recognize and categorize birdsongs. {\textcopyright} 2009 The Royal Society.},
annote = {From Duplicate 2 (Predictive coding under the free-energy principle - Friston, Karl; Kiebel, Stefan)

This paper links DEM and hierarchical models to predictive coding},
author = {Friston, Karl J. and Kiebel, Stefan J.},
doi = {10.1098/rstb.2008.0300},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston, Kiebel{\_}2009{\_}Predictive coding under the free-energy principle.pdf:pdf;:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston, Kiebel{\_}2009{\_}Predictive coding under the free-energy principle(2).pdf:pdf},
issn = {14712970},
journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
keywords = {Birdsong,Generative models,Hierarchical,Predictive coding},
number = {1521},
pages = {1211--1221},
pmid = {19528002},
title = {{Predictive coding under the free-energy principle}},
volume = {364},
year = {2009}
}
@book{Buzsaki2019,
author = {Buzsaki, G},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Buzsaki{\_}2019{\_}The Brain from Inside Out.pdf:pdf},
isbn = {9780190905385},
publisher = {OXFORD University Press},
title = {{The Brain from Inside Out}},
url = {https://books.google.nl/books?id={\_}87bvQEACAAJ},
year = {2019}
}
@article{Friston2009,
abstract = {This paper questions the need for reinforcement learning or control theory when optimising behaviour. We show that it is fairly simple to teach an agent complicated and adaptive behaviours using a free-energy formulation of perception. In this formulation, agents adjust their internal states and sampling of the environment to minimize their free-energy. Such agents learn causal structure in the environment and sample it in an adaptive and self-supervised fashion. This results in behavioural policies that reproduce those optimised by reinforcement learning and dynamic programming. Critically, we do not need to invoke the notion of reward, value or utility. We illustrate these points by solving a benchmark problem in dynamic programming; namely the mountain-car problem, using active perception or inference under the free-energy principle. The ensuing proof-of-concept may be important because the free-energy formulation furnishes a unified account of both action and perception and may speak to a reappraisal of the role of dopamine in the brain. {\textcopyright} 2009 Friston et al.},
author = {Friston, Karl J. and Daunizeau, Jean and Kiebel, Stefan J.},
doi = {10.1371/journal.pone.0006421},
editor = {Sporns, Olaf},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston, Daunizeau, Kiebel{\_}2009{\_}Reinforcement Learning or Active Inference.pdf:pdf},
issn = {1932-6203},
journal = {PLoS ONE},
month = {jul},
number = {7},
pages = {e6421},
pmid = {19641614},
title = {{Reinforcement Learning or Active Inference?}},
volume = {4},
year = {2009}
}
@article{Ghavamzadeh2015,
abstract = {Bayesian methods for machine learning have been widely investigated, yielding principled methods for incorporating prior information into inference algorithms. In this survey, we provide an in-depth review of the role of Bayesian methods for the reinforcement learning (RL) paradigm. The major incentives for incorporating Bayesian reasoning in RL are: 1) it provides an elegant approach to action-selection (exploration/ exploitation) as a function of the uncertainty in learning; and 2) it provides a machinery to incorporate prior knowledge into the algorithms. We first discuss models and methods for Bayesian inference in the simple single-step Bandit model. We then review the extensive recent literature on Bayesian methods for model-based RL, where prior information can be expressed on the parameters of the Markov model. We also present Bayesian methods for model-free RL, where priors are expressed over the value function or policy class. The objective of the paper is to provide a comprehensive survey on Bayesian RL algorithms and their theoretical and empirical properties.},
archivePrefix = {arXiv},
arxivId = {1609.04436},
author = {Ghavamzadeh, Mohammed and Mannor, Shie and Pineau, Joelle and Tamar, Aviv},
doi = {10.1561/2200000049},
eprint = {1609.04436},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Ghavamzadeh et al.{\_}2015{\_}Bayesian Reinforcement Learning A Survey.pdf:pdf},
isbn = {2200000049},
issn = {1935-8237},
journal = {Foundations and Trends{\textregistered} in Machine Learning},
number = {5-6},
pages = {359--483},
title = {{Bayesian Reinforcement Learning: A Survey}},
volume = {8},
year = {2015}
}
@article{Banavar2010,
abstract = {There are numerous situations in physics and other disciplines which can be described at different levels of detail in terms of probability distributions. Such descriptions arise either intrinsically as in quantum mechanics, or because of the vast amount of details necessary for a complete description as, for example, in Brownian motion and in many-body systems. We show that an application of the principle of maximum entropy for estimating the underlying probability distribution can depend on the variables used for describing the system. The choice of characterization of the system carries with it implicit assumptions about fundamental attributes such as whether the system is classical or quantum mechanical or equivalently whether the individuals are distinguishable or indistinguishable. We show that the correct procedure entails the maximization of the relative entropy subject to known constraints and, additionally, requires knowledge of the behavior of the system in the absence of these constraints. We present an application of the principle of maximum entropy to understanding species diversity in ecology and introduce a new statistical ensemble corresponding to the distribution of a variable population of individuals into a set of species not defined a priori. {\textcopyright} 2010 IOP Publishing Ltd.},
author = {Banavar, Jayanth R. and Maritan, Amos and Volkov, Igor},
doi = {10.1088/0953-8984/22/6/063101},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Banavar, Maritan, Volkov{\_}2010{\_}Applications of the principle of maximum entropy from physics to ecology.pdf:pdf},
issn = {0953-8984},
journal = {Journal of Physics: Condensed Matter},
month = {feb},
number = {6},
pages = {063101},
pmid = {21389359},
title = {{Applications of the principle of maximum entropy: from physics to ecology}},
volume = {22},
year = {2010}
}
@article{Friston2003a,
abstract = {This article is about how the brain data mines its sensory inputs. There are several architectural principles of functional brain anatomy that have emerged from careful anatomic and physiologic studies over the past century. These principles are considered in the light of representational learning to see if they could have been predicted a priori on the basis of purely theoretical considerations. We first review the organisation of hierarchical sensory cortices, paying special attention to the distinction between forward and backward connections. We then review various approaches to representational learning as special cases of generative models, starting with supervised learning and ending with learning based upon empirical Bayes. The latter predicts many features, such as a hierarchical cortical system, prevalent top-down backward influences and functional asymmetries between forward and backward connections that are seen in the real brain. The key points made in this article are: (i) hierarchical generative models enable the learning of empirical priors and eschew prior assumptions about the causes of sensory input that are inherent in non-hierarchical models. These assumptions are necessary for learning schemes based on information theory and efficient or sparse coding, but are not necessary in a hierarchical context. Critically, the anatomical infrastructure that may implement generative models in the brain is hierarchical. Furthermore, learning based on empirical Bayes can proceed in a biologically plausible way. (ii) The second point is that backward connections are essential if the processes generating inputs cannot be inverted, or the inversion cannot be parameterised. Because these processes involve many-to-one mappings, are non-linear and dynamic in nature, they are generally non-invertible. This enforces an explicit parameterisation of generative models (i.e. backward connections) to afford recognition and suggests that forward architectures, on their own, are not sufficient for perception. (iii) Finally, non-linearities in generative models, mediated by backward connections, require these connections to be modulatory, so that representations in higher cortical levels can interact to predict responses in lower levels. This is important in relation to functional asymmetries in forward and backward connections that have been demonstrated empirically. {\textcopyright} 2003 Elsevier Ltd. All rights reserved.},
author = {Friston, Karl J.},
doi = {10.1016/j.neunet.2003.06.005},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston{\_}2003{\_}Learning and inference in the brain.pdf:pdf;:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston{\_}2003{\_}Learning and inference in the brain(2).pdf:pdf},
issn = {08936080},
journal = {Neural Networks},
keywords = {Bayesian,Generative models,Inference,Information theory,Predictive coding},
month = {nov},
number = {9},
pages = {1325--1352},
pmid = {14622888},
title = {{Learning and inference in the brain}},
volume = {16},
year = {2003}
}
@article{Hopfield1996,
abstract = {Motifs of neural circuitry seem surprisingly conserved over different areas of neocortex or of paleocortex, while performing quite different sensory processing tasks. This apparent paradox may be resolved by the fact that seemingly different problems in sensory information processing are related by transformations (changes of variables) that convert one problem into another. The same basic algorithm that is appropriate to the recognition of a known odor quality, independent of the strength of the odor, can be used to recognize a vocalization (e.g., a spoken syllable), independent of whether it is spoken quickly or slowly. To convert one problem into the other, a new representation of time sequences is needed. The time that has elapsed since a recent event must be represented in neural activity. The electrophysiological hallmarks of cells that are involved in generating such a representation of time are discussed. The anatomical relationships between olfactory and auditory pathways suggest relevant experiments. The neurophysiological mechanism for the psychophysical logarithmic encoding of time duration would be of direct use for interconverting olfactory and auditory processing problems. Such reuse of old algorithms in new settings and representations is related to the way that evolution develops new biochemistry.},
author = {Hopfield, John J.},
doi = {10.1073/pnas.93.26.15440},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Hopfield{\_}1996{\_}Transforming neural computations and representing time.pdf:pdf},
issn = {00278424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {audition,olfaction,representation,sequences},
number = {26},
pages = {15440--15444},
title = {{Transforming neural computations and representing time}},
volume = {93},
year = {1996}
}
@misc{Abdolmaleki2018,
abstract = {We introduce a new algorithm for reinforcement learning called Maximum aposteriori Policy Optimisation $\backslash$(MPO$\backslash$) based on coordinate ascent on a relativeentropy objective. We show that several existing methods can directly be related to our derivation. We develop two off-policy algorithms and demonstrate that they are competitive with the state-of-the-art in deep reinforcement learning. In particular, for continuous control, our method outperforms existing methods with respect to sample efficiency, premature convergence and robustness to hyperparameter settings.},
archivePrefix = {arXiv},
arxivId = {1806.06920},
author = {Abdolmaleki, Abbas and Springenberg, Jost Tobias and Tassa, Yuval and Munos, Remi and Heess, Nicolas and Riedmiller, Martin},
booktitle = {arXiv},
eprint = {1806.06920},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Abdolmaleki et al.{\_}2018{\_}Maximum a posteriori policy optimisation.pdf:pdf},
publisher = {ArXiv},
title = {{Maximum a posteriori policy optimisation}},
year = {2018}
}
@article{Brown2012,
abstract = {In this paper, we review the nature of illusions using the free-energy formulation of Bayesian perception. We reiterate the notion that illusory percepts are, in fact, Bayes-optimal and represent the most likely explanation for ambiguous sensory input. This point is illustrated using perhaps the simplest of visual illusions; namely, the Cornsweet effect. By using plausible prior beliefs about the spatial gradients of illuminance and reflectance in visual scenes, we show that the Cornsweet effect emerges as a natural consequence of Bayesoptimal perception. Furthermore, we were able to simulate the appearance of secondary illusory percepts (Mach bands) as a function of stimulus contrast. The contrast-dependent emergence of the Cornsweet effect and subsequent appearance of Mach bands were simulated using a simple but plausible generative model. Because our generative model was inverted using a neurobiologically plausible scheme, we could use the inversion as a simulation of neuronal processing and implicit inference. Finally, we were able to verify the qualitative and quantitative predictions of this Bayes-optimal simulation psychophysically, using stimuli presented briefly to normal subjects at different contrast levels, in the context of a fixed alternative forced choice paradigm. {\textcopyright} 2012 Brown and Friston.},
author = {Brown, Harriet and Friston, Karl J.},
doi = {10.3389/fpsyg.2012.00043},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Brown, Friston{\_}2012{\_}Free-energy and illusions The Cornsweet effect.pdf:pdf},
issn = {16641078},
journal = {Frontiers in Psychology},
keywords = {Bayesian inference,Cornsweet effect,Free-energy,Illusions,Perception,Perceptual priors},
number = {FEB},
pages = {1--13},
title = {{Free-energy and illusions: The Cornsweet effect}},
volume = {3},
year = {2012}
}
@book{Fahrmeir2001,
address = {New York, NY},
author = {Fahrmeir, Ludwig and Tutz, Gerhard},
doi = {10.1007/978-1-4757-3454-6},
isbn = {978-1-4419-2900-6},
publisher = {Springer New York},
series = {Springer Series in Statistics},
title = {{Multivariate Statistical Modelling Based on Generalized Linear Models}},
url = {http://link.springer.com/10.1007/978-1-4757-3454-6},
year = {2001}
}
@inproceedings{Meera2020,
abstract = {The free energy principle from neuroscience provides a biologically plausible solution to the brain's inference mechanism. This paper reformulates this theory to design a brain-inspired state and input estimator for a linear time-invariant state space system with colored noise. This reformulation for linear systems bridges the gap between the neuroscientific theory and control theory, therefore opening up the possibility of evaluating it under the hood of standard control approaches. Through rigorous simulations under colored noises, the observer is shown to outperform Kalman Filter and Unknown Input Observer with minimal error in state and input estimation. It is tested against a wide range of scenarios and the proof of concept is demonstrated by applying it on a real system.},
author = {Meera, Ajith Anil and Wisse, Martijn},
booktitle = {2020 American Control Conference (ACC)},
doi = {10.23919/ACC45564.2020.9147581},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Meera, Wisse{\_}Unknown{\_}Free Energy Principle Based State and Input Observer Design for Linear Systems with Colored Noise.pdf:pdf},
month = {jul},
pages = {5052--5058},
publisher = {IEEE},
title = {{Free Energy Principle Based State and Input Observer Design for Linear Systems with Colored Noise}},
volume = {July}
}
@article{Carhart-Harris2019a,
abstract = {This paper formulates the action of psychedelics by integrating the free-energy principle and entropic brain hypothesis. We call this formulation relaxed beliefs under psychedelics (REBUS) and the anarchic brain, founded on the principle that—via their entropic effect on spontaneous cortical activity— psychedelics work to relax the precision of high-level priors or beliefs, thereby liberating bottom-up information flow, particularly via intrinsic sources such as the limbic system. We assemble evidence for this model and show how it can explain a broad range of phenomena associated with the psychedelic experience. With regard to their potential therapeutic use, we propose that psychedelics work to relax the precision weighting of pathologically overweighted priors underpinning various expressions of mental illness. We propose that this process entails an increased sensitization of high-level priors to bottom-up signaling (stemming from intrinsic sources), and that this heightened sensitivity enables the potential revision and deweighting of overweighted priors. We end by discussing further implications of the model, such as that psychedelics can bring about the revision of other heavily weighted high-level priors, not directly related to mental health, such as those underlying partisan and/or overly-confident political, religious, and/or philosophical perspectives. Significance Statement——Psychedelics are capturing interest, with efforts underwaytobringpsilocybintherapy to marketing authorisation and legal access within a decade, spearheaded by the findings of a series of phase 2 trials. In this climate, a compelling unified model of how psychedelics alter brain function to alter consciousness would have appeal. Towards this end, we have sought to integrate a leading model of global brain function, hierarchical predictive coding, withanoften-citedmodelofthe acute action of psychedelics, the entropic brain hypothesis. The resulting synthesis states that psychedelics work to relax high-level priors, sensitising them to liberated bottom-up information flow, which, with the right intention, care provision and context, can help guide and cultivate the revision of entrenched pathological priors.},
author = {Carhart-Harris, R. L. and Friston, Karl J.},
doi = {10.1124/pr.118.017160},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Carhart-Harris, Friston{\_}2019{\_}REBUS and the anarchic brain Toward a unified model of the brain action of psychedelics.pdf:pdf},
issn = {15210081},
journal = {Pharmacological Reviews},
number = {3},
pages = {316--344},
pmid = {31221820},
title = {{REBUS and the anarchic brain: Toward a unified model of the brain action of psychedelics}},
volume = {71},
year = {2019}
}
@book{Baker2014,
abstract = {The human brain is the most powerful plan-recognition system we know. Central to the brain's remarkable plan-recognition capacity is a theory of mind (ToM): our intuitive conception of other agents' mental states-chiefly, beliefs and desires-and how they cause behavior. We present a Bayesian framework for ToM-based plan recognition, expressing generative models of belief- and desire-dependent planning in terms of partially observable Markov decision processes (POMDPs), and reconstructing an agent's joint belief state and reward function using Bayesian inference, conditioned on observations of the agent's behavior in the context of its environment. We show that the framework predicts human judgments with surprising accuracy, and substantially better than alternative accounts. We propose that "reverse engineering" human ToM by quantitatively evaluating the performance of computational cognitive models against data from human behavioral experiments provides a promising avenue for building plan recognition systems. {\textcopyright} 2014 Elsevier Inc. All rights reserved.},
author = {Baker, Chris L. and Tenenbaum, Joshua B.},
booktitle = {Plan, Activity, and Intent Recognition: Theory and Practice},
doi = {10.1016/B978-0-12-398532-3.00007-5},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Baker, Tenenbaum{\_}2014{\_}Modeling Human Plan Recognition Using Bayesian Theory of Mind.pdf:pdf},
isbn = {9780123985323},
keywords = {Bayesian modeling,Belief-desire inference,Cognitive modeling,Commonsense psychology,Partially observable markov decision processes,Theory of mind},
pages = {177--204},
publisher = {Elsevier Inc.},
title = {{Modeling Human Plan Recognition Using Bayesian Theory of Mind}},
url = {http://dx.doi.org/10.1016/B978-0-12-398532-3.00007-5},
volume = {1},
year = {2014}
}
@article{Friston2016,
abstract = {This paper offers an active inference account of choice behaviour and learning. It focuses on the distinction between goal-directed and habitual behaviour and how they contextualise each other. We show that habits emerge naturally (and autodidactically) from sequential policy optimisation when agents are equipped with state-action policies. In active inference, behaviour has explorative (epistemic) and exploitative (pragmatic) aspects that are sensitive to ambiguity and risk respectively, where epistemic (ambiguity-resolving) behaviour enables pragmatic (reward-seeking) behaviour and the subsequent emergence of habits. Although goal-directed and habitual policies are usually associated with model-based and model-free schemes, we find the more important distinction is between belief-free and belief-based schemes. The underlying (variational) belief updating provides a comprehensive (if metaphorical) process theory for several phenomena, including the transfer of dopamine responses, reversal learning, habit formation and devaluation. Finally, we show that active inference reduces to a classical (Bellman) scheme, in the absence of ambiguity.},
author = {Friston, Karl J. and FitzGerald, Thomas and Rigoli, Francesco and Schwartenbeck, Philipp and O'Doherty, John P. and Pezzulo, Giovanni},
doi = {10.1016/j.neubiorev.2016.06.022},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston et al.{\_}2016{\_}Active inference and learning.pdf:pdf},
issn = {18737528},
journal = {Neuroscience and Biobehavioral Reviews},
keywords = {Active inference,Bayesian inference,Bayesian surprise,Epistemic value,Exploitation,Exploration,Free energy,Goal-directed,Habit learning,Information gain},
pages = {862--879},
pmid = {27375276},
publisher = {Elsevier Ltd},
title = {{Active inference and learning}},
url = {http://dx.doi.org/10.1016/j.neubiorev.2016.06.022},
volume = {68},
year = {2016}
}
@article{Lu2017,
abstract = {The expressive power of neural networks is important for understanding deep learning. Most existing works consider this problem from the view of the depth of a network. In this paper, we study how width affects the expressiveness of neural networks. Classical results state that depth-bounded (e.g. depth-2) networks with suitable activation functions are universal approximators. We show a universal approximation theorem for width-bounded ReLU networks: width-(n + 4) ReLU networks, where n is the input dimension, are universal approximators. Moreover, except for a measure zero set, all functions cannot be approximated by width-n ReLU networks, which exhibits a phase transition. Several recent works demonstrate the benefits of depth by proving the depth-efficiency of neural networks. That is, there are classes of deep networks which cannot be realized by any shallow network whose size is no more than an exponential bound. Here we pose the dual question on the width-efficiency of ReLU networks: Are there wide networks that cannot be realized by narrow networks whose size is not substantially larger? We show that there exist classes of wide networks which cannot be realized by any narrow network whose depth is no more than a polynomial bound. On the other hand, we demonstrate by extensive experiments that narrow networks whose size exceed the polynomial bound by a constant factor can approximate wide and shallow network with high accuracy. Our results provide more comprehensive evidence that depth may be more effective than width for the expressiveness of ReLU networks.},
author = {Lu, Zhou and Pu, Hongming and Wang, Feicheng and Hu, Zhiqiang and Wang, Liwei},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Lu et al.{\_}2017{\_}The expressive power of neural networks A view from the width.pdf:pdf},
journal = {arXiv},
number = {Nips},
pages = {1--9},
title = {{The expressive power of neural networks: A view from the width}},
year = {2017}
}
@article{Friston2005,
abstract = {This article concerns the nature of evoked brain responses and the principles underlying their generation. We start with the premise that the sensory brain has evolved to represent or infer the causes of changes in its sensory inputs. The problem of inference is well formulated in statistical terms. The statistical fundaments of inference may therefore afford important constraints on neuronal implementation. By formulating the original ideas of Helmholtz on perception, in terms of modern-day statistical theories, one arrives at a model of perceptual inference and learning that can explain a remarkable range of neurobiological facts. It turns out that the problems of inferring the causes of sensory input (perceptual inference) and learning the relationship between input and cause (perceptual learning) can be resolved using exactly the same principle. Specifically, both inference and learning rest on minimizing the brain's free energy, as defined in statistical physics. Furthermore, inference and learning can proceed in a biologically plausible fashion. Cortical responses can be seen as the brain's attempt to minimize the free energy induced by a stimulus and thereby encode the most likely cause of that stimulus. Similarly, learning emerges from changes in synaptic efficacy that minimize the free energy, averaged over all stimuli encountered. The underlying scheme rests on empirical Bayes and hierarchical models of how sensory input is caused. The use of hierarchical models enables the brain to construct prior expectations in a dynamic and context-sensitive fashion. This scheme provides a principled way to understand many aspects of cortical organization and responses. The aim of this article is to encompass many apparently unrelated anatomical, physiological and psychophysical attributes of the brain within a single theoretical perspective. In terms of cortical architectures, the theoretical treatment predicts that sensory cortex should be arranged hierarchically, that connections should be reciprocal and that forward and backward connections should show a functional asymmetry (forward connections are driving, whereas backward connections are both driving and modulatory). In terms of synaptic physiology, it predicts associative plasticity and, for dynamic models, spike-timing-dependent plasticity. In terms of electrophysiology, it accounts for classical and extra classical receptive field effects and long-latency or endogenous components of evoked cortical responses. It predicts the attenuation of responses encoding prediction error with perceptual learning and explains many phenomena such as repetition suppression, mismatch negativity (MMN) and the P300 in electroencephalography. In psychophysical terms, it accounts for the behavioural correlates of these physiological phenomena, for example, priming and global precedence. The final focus of this article is on perceptual learning as measured with the MMN and the implications for empirical studies of coupling among cortical areas using evoked sensory responses. {\textcopyright} 2005 The Royal Society.},
author = {Friston, Karl J.},
doi = {10.1098/rstb.2005.1622},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston{\_}2005{\_}A theory of cortical responses.pdf:pdf;:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston{\_}2005{\_}A theory of cortical responses(2).pdf:pdf},
issn = {09628436},
journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
keywords = {Bayesian,Cortical,Generative models,Hierarchical,Inference,Predictive coding},
number = {1456},
pages = {815--836},
pmid = {15937014},
title = {{A theory of cortical responses}},
volume = {360},
year = {2005}
}
@article{David2003,
abstract = {Although MEG/EEG signals are highly variable, systematic changes in distinct frequency bands are commonly encountered. These frequency-specific changes represent robust neural correlates of cognitive or perceptual processes (for example, alpha rhythms emerge on closing the eyes). However, their functional significance remains a matter of debate. Some of the mechanisms that generate these signals are known at the cellular level and rest on a balance of excitatory and inhibitory interactions within and between populations of neurons. The kinetics of the ensuing population dynamics determine the frequency of oscillations. In this work we extended the classical nonlinear lumped-parameter model of alpha rhythms, initially developed by Lopes da Silva and colleagues [Kybernetik 15 (1974) 27], to generate more complex dynamics. We show that the whole spectrum of MEG/EEG signals can be reproduced within the oscillatory regime of this model by simply changing the population kinetics. We used the model to examine the influence of coupling strength and propagation delay on the rhythms generated by coupled cortical areas. The main findings were that (1) coupling induces phase-locked activity, with a phase shift of 0 or $\pi$ when the coupling is bidirectional, and (2) both coupling and propagation delay are critical determinants of the MEG/EEG spectrum. In forthcoming articles, we will use this model to (1) estimate how neuronal interactions are expressed in MEG/EEG oscillations and establish the construct validity of various indices of nonlinear coupling, and (2) generate event-related transients to derive physiologically informed basis functions for statistical modelling of average evoked responses. {\textcopyright} 2003 Elsevier Inc. All rights reserved.},
author = {David, Olivier and Friston, Karl J.},
doi = {10.1016/j.neuroimage.2003.07.015},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/David, Friston{\_}2003{\_}A neural mass model for MEGEEG Coupling and neuronal dynamics.pdf:pdf},
issn = {10538119},
journal = {NeuroImage},
number = {3},
pages = {1743--1755},
pmid = {14642484},
title = {{A neural mass model for MEG/EEG: Coupling and neuronal dynamics}},
volume = {20},
year = {2003}
}
@article{Kean2007,
author = {Kean, Sam},
doi = {10.1038/scientificamerican0620-70},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Kean{\_}2007{\_}Tales of the dying brain.pdf:pdf},
isbn = {2001043090},
issn = {00095982},
journal = {Chronicle of Higher Education},
number = {2},
pages = {5},
publisher = {Nature Publishing Group},
title = {{Tales of the dying brain}},
volume = {322},
year = {2007}
}
@article{Millidge2020d,
abstract = {Backpropagation of error (backprop) is a powerful algorithm for training machine learning architectures through end-to-end differentiation. However, backprop is often criticised for lacking biological plausibility. Recently, it has been shown that backprop in multilayer-perceptrons (MLPs) can be approximated using predictive coding, a biologically-plausible process theory of cortical computation which relies only on local and Hebbian updates. The power of backprop, however, lies not in its instantiation in MLPs, but rather in the concept of automatic differentiation which allows for the optimisation of any differentiable program expressed as a computation graph. Here, we demonstrate that predictive coding converges asymptotically (and in practice rapidly) to exact backprop gradients on arbitrary computation graphs using only local learning rules. We apply this result to develop a straightforward strategy to translate core machine learning architectures into their predictive coding equivalents. We construct predictive coding CNNs, RNNs, and the more complex LSTMs, which include a non-layer-like branching internal graph structure and multiplicative interactions. Our models perform equivalently to backprop on challenging machine learning benchmarks, while utilising only local and (mostly) Hebbian plasticity. Our method raises the potential that standard machine learning algorithms could in principle be directly implemented in neural circuitry, and may also contribute to the development of completely distributed neuromorphic architectures. .},
archivePrefix = {arXiv},
arxivId = {2006.04182},
author = {Millidge, Beren and Tschantz, Alexander and Buckley, Christopher L.},
eprint = {2006.04182},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Millidge, Tschantz, Buckley{\_}2020{\_}Predictive coding approximates backprop along arbitrary computation graphs(2).pdf:pdf},
issn = {23318422},
journal = {arXiv},
pages = {1--25},
title = {{Predictive coding approximates backprop along arbitrary computation graphs}},
year = {2020}
}
@article{Friston2003,
abstract = {In this paper we present an approach to the identification of nonlinear input-state-output systems. By using a bilinear approximation to the dynamics of interactions among states, the parameters of the implicit causal model reduce to three sets. These comprise (1) parameters that mediate the influence of extrinsic inputs on the states, (2) parameters that mediate intrinsic coupling among the states, and (3) [bilinear] parameters that allow the inputs to modulate that coupling. Identification proceeds in a Bayesian framework given known, deterministic inputs and the observed responses of the system. We developed this approach for the analysis of effective connectivity using experimentally designed inputs and fMRI responses. In this context, the coupling parameters correspond to effective connectivity and the bilinear parameters reflect the changes in connectivity induced by inputs. The ensuing framework allows one to characterise fMRI experiments, conceptually, as an experimental manipulation of integration among brain regions (by contextual or trial-free inputs, like time or attentional set) that is revealed using evoked responses (to perturbations or trial-bound inputs, like stimuli). As with previous analyses of effective connectivity, the focus is on experimentally induced changes in coupling (cf., psychophysiologic interactions). However, unlike previous approaches in neuroimaging, the causal model ascribes responses to designed deterministic inputs, as opposed to treating inputs as unknown and stochastic. {\textcopyright} 2003 Elsevier Science (USA). All rights reserved.},
author = {Friston, Karl J. and Harrison, Lee M. and Penny, W. D.},
doi = {10.1016/S1053-8119(03)00202-7},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston, Harrison, Penny{\_}2003{\_}Dynamic causal modelling.pdf:pdf},
issn = {10538119},
journal = {NeuroImage},
keywords = {Bilinear model,Effective connectivity,Functional neuroimaging,Hemodynamic response function,Nonlinear system identification,fMRI},
number = {4},
pages = {1273--1302},
pmid = {12948688},
title = {{Dynamic causal modelling}},
volume = {19},
year = {2003}
}
@article{Eigen1977,
author = {Eigen, Manfred and Schuster, Peter},
doi = {10.1007/BF00450633},
issn = {0028-1042},
journal = {Naturwissenschaften},
month = {nov},
number = {11},
pages = {541--565},
title = {{The Hypercycle: A principle of natural self-organization}},
volume = {64},
year = {1977}
}
@article{Dharani2015a,
author = {Dharani, Krishnagopal},
doi = {10.1016/b978-0-12-800900-0.00007-5},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Dharani{\_}2015{\_}Molecular-Grid Model.pdf:pdf},
isbn = {9780128009000},
journal = {The Biology of Thought},
pages = {123--142},
title = {{Molecular-Grid Model}},
year = {2015}
}
@article{DeOliveira2007,
abstract = {An updated discussion on physical and mathematical aspects of the ergodic hypothesis in classical equilibrium statistical mechanics is presented. Then a practical attitude for the, justification of the microcanonical ensemble is indicated. It is also remarked that the difficulty in proving the ergodic hypothesis should be expected. Copyright by the Sociedade Brasileira de Fisica.},
author = {de Oliveira, C{\'{e}}sar R. and Werlang, Thiago},
doi = {10.1590/s1806-11172007000200003},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/de Oliveira, Werlang{\_}2007{\_}Ergodic hypothesis in classical statistical mechanics.pdf:pdf},
issn = {01024744},
journal = {Revista Brasileira de Ensino de Fisica},
keywords = {Ergodic hypothesis,Microcanonical ensemble,Statistical mechanics},
number = {2},
pages = {189--201},
title = {{Ergodic hypothesis in classical statistical mechanics}},
volume = {29},
year = {2007}
}
@article{Harris2003,
abstract = {Neurons can produce action potentials with high temporal precision. A fundamental issue is whether, and how, this capability is used in information processing. According to the 'cell assembly' hypothesis, transient synchrony of anatomically distributed groups of neurons underlies processing of both external sensory input and internal cognitive mechanisms. Accordingly, neuron populations should be arranged into groups whose synchrony exceeds that predicted by common modulation by sensory input. Here we find that the spike times of hippocampal pyramidal cells can be predicted more accurately by using the spike times of simultaneously recorded neurons in addition to the animals location in space. This improvement remained when the spatial prediction was refined with a spatially dependent theta phase modulation. The time window in which spike times are best predicted from simultaneous peer activity is 10-30 ms, suggesting that cell assemblies are synchronized at this timescale. Because this temporal window matches the membrane time constant of pyramidal neurons, the period of the hippocampal gamma oscillation and the time window for synaptic plasticity, we propose that cooperative activity at this timescale is optimal for information transmission and storage in cortical circuits.},
author = {Harris, Kenneth D. and Csicsvari, Jozsef and Hirase, Hajime and Dragoi, George and Buzs{\'{a}}ki, Gy{\"{o}}rgy},
doi = {10.1038/nature01834},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Harris et al.{\_}2003{\_}Organization of cell assemblies in the hippocampus.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
month = {jul},
number = {6948},
pages = {552--556},
pmid = {12891358},
title = {{Organization of cell assemblies in the hippocampus}},
url = {http://www.nature.com/articles/nature01834},
volume = {424},
year = {2003}
}
@article{Friston2008,
abstract = {This paper describes a general model that subsumes many parametric models for continuous data. The model comprises hidden layers of state-space or dynamic causal models, arranged so that the output of one provides input to another. The ensuing hierarchy furnishes a model for many types of data, of arbitrary complexity. Special cases range from the general linear model for static data to generalised convolution models, with system noise, for nonlinear time-series analysis. Crucially, all of these models can be inverted using exactly the same scheme, namely, dynamic expectation maximization. This means that a single model and optimisation scheme can be used to invert a wide range of models. We present the model and a brief review of its inversion to disclose the relationships among, apparently, diverse generative models of empirical data. We then show that this inversion can be formulated as a simple neural network and may provide a useful metaphor for inference and learning in the brain. {\textcopyright} 2008 Karl Friston.},
annote = {Discuses the idea of hierarchical dynamic models and their inversion (using DEM) in the brain},
author = {Friston, Karl J.},
doi = {10.1371/journal.pcbi.1000211},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston{\_}2008{\_}Hierarchical models in the brain.pdf:pdf},
issn = {1553734X},
journal = {PLoS Computational Biology},
number = {11},
pmid = {18989391},
title = {{Hierarchical models in the brain}},
volume = {4},
year = {2008}
}
@article{Friston2001,
abstract = {The brain can be regarded as an ensemble of connected dynamical systems and as such conforms to some simple principles relating the inputs and outputs of its constituent parts. The ensuing implications, for the way we think about, and measure, neuronal interactions, can be quite profound. These range from 1) implications for which aspects of neuronal activity are important to measure and how to characterize coupling among neuronal populations; 2) implication for understanding the emergence of dynamic receptive fields and functionally specialized brain architectures; and 3) teleological implications pertaining to the genesis of dynamic instability and complexity, which is necessary for adaptive self-organization. This review focuses on the first set of implications by looking at neuronal interactions, coupling, and implicit neuronal codes from a dynamical perspective. By considering the brain in this light, one can show that a sufficient description of neuronal activity must comprise activity at the current time and its recent history. This history constitutes a neuronal transient. Such transients represent an essential metric of neuronal interactions and, implicitly, a code employed in the functional integration of brain systems. The nature of transients, expressed conjointly in different neuronal populations, reflects the underlying coupling among brain systems. A complete description of this coupling, or effective connectivity, can be expressed in terms of generalized convolution kernels (Volterra kernels) that embody high-order or nonlinear interactions. This coupling may be synchronous, and possibly oscillatory, or asynchronous. A critical distinction between synchronous and asynchronous coupling is that the former is essentially linear and the latter is nonlinear. The nonlinear nature of asynchronous coupling enables the rich, context-sensitive interactions that characterize real brain dynamics, suggesting that it plays an important role in functional integration.},
author = {Friston, Karl J.},
doi = {10.1177/107385840100700510},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston{\_}2001{\_}Brain function, nonlinear coupling, and neuronal transients.pdf:pdf},
issn = {10738584},
journal = {Neuroscientist},
keywords = {Functional integration,Neuronal codes,Neuronal transients,Nonlinear dynamics,Volterra Series},
number = {5},
pages = {406--418},
title = {{Brain function, nonlinear coupling, and neuronal transients}},
volume = {7},
year = {2001}
}
@article{Hopfield1994b,
abstract = {The question How does it work? is the motivation of many physicists. Condensed matter physics, chemical physics and nuclear physics can all be thought of as descriptions of the relation between structure and properties. The components of a biological system have functional properties that are particularly relevant to the operation of the system. Thus it is especially important in biology to understand the relation between structure and function. Such understanding can be sought at the level of the molecule, the cell, the organ, the organism or the social group.Brains have long been regarded as biological computers. But how do these collections of neurons perform computations. {\textcopyright} 1994, American Institute of Physics. All rights reserved.},
author = {Hopfield, John J.},
doi = {10.1063/1.881412},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Hopfield{\_}1994{\_}Neurons, Dynamics and Computation.pdf:pdf},
issn = {19450699},
journal = {Physics Today},
number = {2},
pages = {40--46},
title = {{Neurons, Dynamics and Computation}},
volume = {47},
year = {1994}
}
@inproceedings{Cho2014,
abstract = {In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixed-length vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.},
address = {Stroudsburg, PA, USA},
archivePrefix = {arXiv},
arxivId = {1406.1078},
author = {Cho, Kyunghyun and van Merrienboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
booktitle = {Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
doi = {10.3115/v1/D14-1179},
eprint = {1406.1078},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Cho et al.{\_}2014{\_}Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation.pdf:pdf},
month = {jun},
pages = {1724--1734},
publisher = {Association for Computational Linguistics},
title = {{Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation}},
url = {http://arxiv.org/abs/1406.1078 http://aclweb.org/anthology/D14-1179},
year = {2014}
}
@article{Miller1956,
abstract = {In putting together his grandest venture to date, Donald Trump used the principles of corporate culture to make his version of the Taj Mahal a reality. Here's how you can apply the basics of company culture. {\textcopyright} 1990, SAGE Publications. All rights reserved.},
author = {Miller, George A.},
doi = {10.1037/h0043158},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Miller{\_}1956{\_}The magical number seven, plus or minus two some limits on our capacity for processing information.pdf:pdf},
issn = {1939-1471},
journal = {Psychological Review},
number = {2},
pages = {81--97},
title = {{The magical number seven, plus or minus two: some limits on our capacity for processing information.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/h0043158},
volume = {63},
year = {1956}
}
@article{Friston2018,
abstract = {In the 20th century we thought the brain extracted knowledge from sensations. The 21st century witnessed a ‘strange inversion', in which the brain became an organ of inference, actively constructing explanations for what's going on ‘out there', beyond its sensory epithelia. One paper played a key role in this paradigm shift.},
author = {Friston, Karl J.},
doi = {10.1038/s41593-018-0200-7},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston{\_}2018{\_}Does predictive coding have a future.pdf:pdf},
issn = {15461726},
journal = {Nature Neuroscience},
number = {8},
pages = {1019--1021},
title = {{Does predictive coding have a future?}},
volume = {21},
year = {2018}
}
@incollection{Hesp2019,
author = {Hesp, Casper and Ramstead, Maxwell J.D. and Constant, Axel and Badcock, Paul and Kirchhoff, Michael and Friston, Karl J.},
booktitle = {Evolution, Develompent and Complexity},
doi = {10.1007/978-3-030-00075-2_7},
pages = {195--227},
title = {{A Multi-scale View of the Emergent Complexity of Life: A Free-Energy Proposal}},
year = {2019}
}
@article{Smith2021,
author = {Smith, Ryan and Friston, Karl J and Whyte, Christopher J},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Smith, Friston, Whyte{\_}2021{\_}A Step-by-Step Tutorial on Active Inference and its Application to Empirical Data.pdf:pdf},
journal = {preprint},
pages = {1--104},
title = {{A Step-by-Step Tutorial on Active Inference and its Application to Empirical Data}},
year = {2021}
}
@article{Millidge2019,
abstract = {Active Inference is a theory of action arising from neuroscience which casts action and planning as a bayesian inference problem to be solved by minimizing a single quantity – the variational free energy. Active Inference promises a unifying account of action and perception coupled with a biologically plausible process theory. Despite these potential advantages, current implementations of Active Inference can only handle small, discrete policy and state-spaces and typically require the environmental dynamics to be known. In this paper we propose a novel deep Active Inference algorithm which approximates key densities using deep neural networks as flexible function approximators, which enables Active Inference to scale to significantly larger and more complex tasks. We demonstrate our approach on a suite of OpenAIGym benchmark tasks and obtain performance comparable with common reinforcement learning baselines. Moreover, our algorithm shows similarities with maximum entropy reinforcement learning and the policy gradients algorithm, which reveals interesting connections between the Active Inference framework and reinforcement learning.},
archivePrefix = {arXiv},
arxivId = {1907.03876},
author = {Millidge, Beren},
eprint = {1907.03876},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Millidge{\_}2019{\_}Deep Active Inference As Variational Policy Gradients.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {Active Inference,Actor-Critic,Neural Networks,OpenAI Gym,Policy Gradients,Predictive Processing,Reinforcement Learning},
title = {{Deep Active Inference As Variational Policy Gradients}},
year = {2019}
}
@article{Issa2018,
abstract = {Ventral visual stream neural responses are dynamic, even for static image presentations. However, dynamical neural models of visual cortex are lacking as most progress has been made modeling static, time-averaged responses. Here, we studied population neural dynamics during face detection across three cortical processing stages. Remarkably,{\~{}}30 milliseconds after the initially evoked response, we found that neurons in intermediate level areas decreased their responses to typical configurations of their preferred face parts relative to their response for atypical configurations even while neurons in higher areas achieved and maintained a preference for typical configurations. These hierarchical neural dynamics were inconsistent with standard feedforward circuits. Rather, recurrent models computing prediction errors between stages captured the observed temporal signatures. This model of neural dynamics, which simply augments the standard feedforward model of online vision, suggests that neural responses to static images may encode top-down prediction errors in addition to bottom-up feature estimates.},
author = {Issa, Elias B. and Cadieu, Charles F. and DiCarlo, James J.},
doi = {10.7554/eLife.42870},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Issa, Cadieu, DiCarlo{\_}2018{\_}Neural dynamics at successive stages of the ventral visual stream are consistent with hierarchical error sign.pdf:pdf},
issn = {2050-084X},
journal = {eLife},
month = {nov},
number = {1},
pages = {1--24},
pmid = {30484773},
title = {{Neural dynamics at successive stages of the ventral visual stream are consistent with hierarchical error signals}},
url = {https://elifesciences.org/articles/42870},
volume = {7},
year = {2018}
}
@article{Ranganath2016,
abstract = {Black box variational inference allows researchers to easily prototype and evaluate an array of models. Recent advances allow such algorithms to scale to high dimensions. However, a central question remains: How to specify an expressive variational distribution that maintains efficient computation? To address this, we develop hierarchical variational models (HVMS). HVMS augment a variational approximation with a prior on its parameters, which allows it to capture complex structure for both discrete and continuous latent variables. The algorithm we develop is black box, can be used for any HVM, and has the same computational efficiency as the original approximation. We study hvms on a variety of deep discrete latent variable models. HVMs generalize other expressive variational distributions and maintains higher fidelity to the posterior.},
archivePrefix = {arXiv},
arxivId = {1511.02386},
author = {Ranganath, Rajesh and Tran, Dustin and Blei, David M.},
eprint = {1511.02386},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Ranganath, Tran, Blei{\_}2016{\_}Hierarchical variational models.pdf:pdf},
isbn = {9781510829008},
journal = {33rd International Conference on Machine Learning, ICML 2016},
pages = {515--528},
title = {{Hierarchical variational models}},
volume = {1},
year = {2016}
}
@article{Friston2008a,
abstract = {This paper presents a variational treatment of dynamic models that furnishes time-dependent conditional densities on the path or trajectory of a system's states and the time-independent densities of its parameters. These are obtained by maximising a variational action with respect to conditional densities, under a fixed-form assumption about their form. The action or path-integral of free-energy represents a lower bound on the model's log-evidence or marginal likelihood required for model selection and averaging. This approach rests on formulating the optimisation dynamically, in generalised coordinates of motion. The resulting scheme can be used for online Bayesian inversion of nonlinear dynamic causal models and is shown to outperform existing approaches, such as Kalman and particle filtering. Furthermore, it provides for dual and triple inferences on a system's states, parameters and hyperparameters using exactly the same principles. We refer to this approach as dynamic expectation maximisation (DEM). {\textcopyright} 2008 Elsevier Inc. All rights reserved.},
author = {Friston, Karl J. and Trujillo-Barreto, Nelson and Daunizeau, Jean},
doi = {10.1016/j.neuroimage.2008.02.054},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston, Trujillo-Barreto, Daunizeau{\_}2008{\_}DEM A variational treatment of dynamic systems.pdf:pdf},
issn = {10538119},
journal = {NeuroImage},
keywords = {Action,Bayesian filtering,Dynamic expectation maximisation,Dynamical systems,Free energy,Nonlinear,Variational Bayes,Variational filtering},
number = {3},
pages = {849--885},
title = {{DEM: A variational treatment of dynamic systems}},
volume = {41},
year = {2008}
}
@article{Hochreiter1997,
abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
author = {Hochreiter, Sepp and Schmidhuber, J{\"{u}}rgen},
doi = {10.1162/neco.1997.9.8.1735},
issn = {0899-7667},
journal = {Neural Computation},
month = {nov},
number = {8},
pages = {1735--1780},
title = {{Long Short-Term Memory}},
url = {https://www.mitpressjournals.org/doi/abs/10.1162/neco.1997.9.8.1735},
volume = {9},
year = {1997}
}
@article{Lillicrap2016,
abstract = {The brain processes information through multiple layers of neurons. This deep architecture is representationally powerful, but complicates learning because it is difficult to identify the responsible neurons when a mistake is made. In machine learning, the backpropagation algorithm assigns blame by multiplying error signals with all the synaptic weights on each neuron's axon and further downstream. However, this involves a precise, symmetric backward connectivity pattern, which is thought to be impossible in the brain. Here we demonstrate that this strong architectural constraint is not required for effective error propagation. We present a surprisingly simple mechanism that assigns blame by multiplying errors by even random synaptic weights. This mechanism can transmit teaching signals across multiple layers of neurons and performs as effectively as backpropagation on a variety of tasks. Our results help reopen questions about how the brain could use error signals and dispel long-held assumptions about algorithmic constraints on learning.},
author = {Lillicrap, Timothy P. and Cownden, Daniel and Tweed, Douglas B. and Akerman, Colin J.},
doi = {10.1038/ncomms13276},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Lillicrap et al.{\_}2016{\_}Random synaptic feedback weights support error backpropagation for deep learning.pdf:pdf},
issn = {20411723},
journal = {Nature Communications},
pages = {1--10},
pmid = {27824044},
publisher = {Nature Publishing Group},
title = {{Random synaptic feedback weights support error backpropagation for deep learning}},
url = {http://dx.doi.org/10.1038/ncomms13276},
volume = {7},
year = {2016}
}
@article{Auksztulewicz2016,
abstract = {This paper presents a review of theoretical and empirical work on repetition suppression in the context of predictive coding. Predictive coding is a neurobiologically plausible scheme explaining how biological systems might perform perceptual inference and learning. From this perspective, repetition suppression is a manifestation of minimising prediction error through adaptive changes in predictions about the content and precision of sensory inputs. Simulations of artificial neural hierarchies provide a principled way of understanding how repetition suppression – at different time scales – can be explained in terms of inference and learning implemented under predictive coding. This formulation of repetition suppression is supported by results of numerous empirical studies of repetition suppression and its contextual determinants.},
author = {Auksztulewicz, Ryszard and Friston, Karl J.},
doi = {10.1016/j.cortex.2015.11.024},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Auksztulewicz, Friston{\_}2016{\_}Repetition suppression and its contextual determinants in predictive coding.pdf:pdf},
issn = {19738102},
journal = {Cortex},
keywords = {Mismatch negativity,Perceptual inference,Perceptual learning,Predictive coding,Repetition suppression},
pages = {125--140},
publisher = {Elsevier Ltd},
title = {{Repetition suppression and its contextual determinants in predictive coding}},
url = {http://dx.doi.org/10.1016/j.cortex.2015.11.024},
volume = {80},
year = {2016}
}
@article{Toussaint2006,
abstract = {Inference in Markov Decision Processes has recently received interest as a means to infer goals of an observed action, policy recognition, and also as a tool to compute policies. A particularly interesting aspect of the approach is that any existing inference technique in DBNs now becomes available for answering behavioral questions-including those on continuous, factorial, or hierarchical state representations. Here we present an Expectation Maximization algorithm for computing optimal policies. Unlike previous approaches we can show that this actually optimizes the discounted expected future return for arbitrary reward functions and without assuming an ad hoc finite total time. The algorithm is generic in that any inference technique can be utilized in the E-step. We demonstrate this for exact inference on a discrete maze and Gaussian belief state propagation in continuous stochastic optimal control problems.},
author = {Toussaint, Marc and Storkey, Amos},
doi = {10.1145/1143844.1143963},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Toussaint, Storkey{\_}2006{\_}Probabilistic inference for solving discrete and continuous state Markov Decision Processes.pdf:pdf},
isbn = {1595933832},
journal = {ACM International Conference Proceeding Series},
pages = {945--952},
title = {{Probabilistic inference for solving discrete and continuous state Markov Decision Processes}},
volume = {148},
year = {2006}
}
@book{Stratonovich1967,
address = {New York [etc.] SE  - XIV, 329 p. : ill. ; 24 cm.},
annote = {Available at the TU Delft library (closed stacks)

Cited by Hierarchical Models in the Brain when discussing the non applicability of Marcovian process assumptions for actual processes, which are infinitely smooth (pages 121-124, 165)},
author = {Stratonovich, R L and Silverman, Richard Allan.},
booktitle = {Mathematics and its applications ; vol. 3 TA  - TT  -},
edition = {Rev. Engli},
isbn = {0677007906 9780677007908},
language = {English},
publisher = {Gordon and Breach},
title = {{Topics in the theory of random noise / Vol. II, Peaks of random functions and the effect of noise on relays, nonlinear self-excited oscillations in the presence of noise. LK  - https://tudelft.on.worldcat.org/oclc/769252893}},
year = {1967}
}
@article{Millidge2020b,
abstract = {Active Inference is a theory arising from theoretical neuroscience which casts action and planning as Bayesian inference problems to be solved by minimizing a single quantity — the variational free energy. The theory promises a unifying account of action and perception coupled with a biologically plausible process theory. However, despite these potential advantages, current implementations of Active Inference can only handle small policy and state–spaces and typically require the environmental dynamics to be known. In this paper we propose a novel deep Active Inference algorithm that approximates key densities using deep neural networks as flexible function approximators, which enables our approach to scale to significantly larger and more complex tasks than any before attempted in the literature. We demonstrate our method on a suite of OpenAIGym benchmark tasks and obtain performance comparable with common reinforcement learning baselines. Moreover, our algorithm evokes similarities with maximum-entropy reinforcement learning and the policy gradients algorithm, which reveals interesting connections between the Active Inference framework and reinforcement learning.},
author = {Millidge, Beren},
doi = {10.1016/j.jmp.2020.102348},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Millidge{\_}2020{\_}Deep active inference as variational policy gradients.pdf:pdf},
issn = {10960880},
journal = {Journal of Mathematical Psychology},
keywords = {Active inference,Neural networks,Policy gradients,Predictive processing,Reinforcement learning},
pages = {102348},
publisher = {Elsevier Inc.},
title = {{Deep active inference as variational policy gradients}},
volume = {96},
year = {2020}
}
@article{Hopfield2004,
abstract = {Many stimuli have meaning only as patterns over time. Most auditory and many visual stimuli are of this nature and can be described as multidimensional, time-dependent vectors. A simple neuron can encode a single component of the vector in a firing rate. The addition of a small subthreshold oscillatory current perturbs the action-potential timing, encoding the signal also in a timing relationship, with little effect on the coexisting firing rate representation. When the subthreshold signal is common to a group of neurons, the timing-based information is significant to neurons receiving inputs from the group. This information encoding allows simple implementation of computations not readily done with rate coding. These ideas are examined by using speech to provide a realistic input signal to a biologically inspired model network of spiking neurons. The output neurons of the two-layer system are shown to specifically encode short linguistic elements of speech.},
author = {Hopfield, John J.},
doi = {10.1073/pnas.0401125101},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Hopfield{\_}2004{\_}Encoding for computation Recognizing brief dynamical patterns by exploiting effects of weak rhythms on action-potential ti.pdf:pdf},
issn = {00278424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
number = {16},
pages = {6255--6260},
title = {{Encoding for computation: Recognizing brief dynamical patterns by exploiting effects of weak rhythms on action-potential timing}},
volume = {101},
year = {2004}
}
@incollection{Tromp2016,
author = {Tromp, John and Farneb{\"{a}}ck, Gunnar},
doi = {10.1007/978-3-540-75538-8_8},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Tromp, Farneb{\"{a}}ck{\_}2007{\_}Combinatorics of Go.pdf:pdf},
pages = {84--99},
title = {{Combinatorics of Go}},
year = {2007}
}
@article{Hartley1958,
author = {Hartley, H. O.},
doi = {10.2307/2527783},
issn = {0006341X},
journal = {Biometrics},
month = {jun},
number = {2},
pages = {174},
title = {{Maximum Likelihood Estimation from Incomplete Data}},
url = {https://www.jstor.org/stable/2527783?origin=crossref},
volume = {14},
year = {1958}
}
@book{Gutkin2012,
abstract = {Drug addiction remains one of the most important public health problems in western societies and is a rising concern for developing nations. Over the past 3 decades, experimental research on the neurobiology and psychology of drug addiction has generated a torrent of exciting data, from the molecular up to the behavioral levels. As a result, a new and pressing challenge for addiction research is to formulate a synthetic theoretical framework that goes well beyond mere scientific eclectism to deepen our understanding of drug addiction and to foster our capacity to prevent and to cure drug addiction. Intrigued by the apparent irrational behavior of drug addicts, researchers from a wide range of scientific disciplines have formulated a plethora of theoretical schemes over the years to understand addiction. However, most of these theories and models are qualitative in nature and are formulated using terms that are often ill-defined. As a result, the empirical validity of these models has been difficult to test rigorously, which has served to generate more controversy than clarity. In this context, as in other scientific fields, mathematical and computational modeling should contribute to the development of more testable and rigorous models of addiction.},
author = {Gutkin, Boris and Ahmed, Serge H.},
booktitle = {Computational Neuroscience of Drug Addiction},
doi = {10.1007/978-1-4614-0751-5},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Gutkin, Ahmed{\_}2012{\_}Computational neuroscience of drug addiction.pdf:pdf},
isbn = {9781461407515},
pages = {1--341},
title = {{Computational neuroscience of drug addiction}},
year = {2012}
}
@article{Pathak2017,
archivePrefix = {arXiv},
arxivId = {arXiv:1705.05363v1},
author = {Pathak, Deepak and Agrawal, Pulkit and Efros, Alexei A and Darrell, Trevor},
eprint = {arXiv:1705.05363v1},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Pathak et al.{\_}2017{\_}Curiosity-driven Exploration by Self-supervised Prediction.pdf:pdf},
journal = {ArXiv},
title = {{Curiosity-driven Exploration by Self-supervised Prediction}},
year = {2017}
}
@article{Grossberg1987,
abstract = {Functional and mechanistic comparisons are made between several network$\backslash$nmodels of cognitive processing: competitive learning, interactive$\backslash$nactivation, adaptive resonance, and back propagation. The starting$\backslash$npoint of this comparison is the article of Rumelhart and Zipser (1985)$\backslash$non feature discovery through competitive learning. All the models$\backslash$nwhich Rumelhart and Zipser (1985) have described were shown in Grossberg$\backslash$n(1976b) to exhibit a type of learning which is temporally unstable.$\backslash$nCompetitive learning mechanisms can be stabilized in response to$\backslash$nan arbitrary input environment by being supplemented with mechanisms$\backslash$nfor learning top-down expectancies, or templates; for matching bottom-up$\backslash$ninput patterns with the top-down expectancies; and for releasing$\backslash$norienting reactions in a mismatch situation, thereby updating short-term$\backslash$nmemory and searching for another internal representation. Network$\backslash$narchitectures which embody all of these mechanisms were called adaptive$\backslash$nresonance models by Grossberg (1976c). Self-stabilizing learning$\backslash$nmodels are candidates for use in real-world applications where unpredictable$\backslash$nchanges can occur in complex input environments. Competitive learning$\backslash$npostulates are inconsistent with the postulates of the interactive$\backslash$nactivation model of McClelland and Rumelhart (1981), and suggest$\backslash$ndifferent levels of processing and interaction rules for the analysis$\backslash$nof word recognition. Adaptive resonance models use these alternative$\backslash$nlevels and interaction rules. The self-organizing learning of an$\backslash$nadaptive resonance model is compared and contrasted with the teacher-directed$\backslash$nlearning of a back propagation model. A number of criteria for evaluating$\backslash$nreal-time network models of cognitive processing are described and$\backslash$napplied.},
author = {Grossberg, Stephen},
doi = {10.1111/j.1551-6708.1987.tb00862.x},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Grossberg{\_}1987{\_}Competitive Learning From Interactive Activation to Adaptive Resonance.pdf:pdf},
journal = {Cognitive Science},
number = {1},
pages = {23--63},
title = {{Competitive Learning: From Interactive Activation to Adaptive Resonance}},
volume = {11},
year = {1987}
}
@article{Ghosh2020,
abstract = {We cast policy gradient methods as the repeated application of two operators: a policy improvement operator {\$}\backslashmathcal{\{}I{\}}{\$}, which maps any policy {\$}\backslashpi{\$} to a better one {\$}\backslashmathcal{\{}I{\}}\backslashpi{\$}, and a projection operator {\$}\backslashmathcal{\{}P{\}}{\$}, which finds the best approximation of {\$}\backslashmathcal{\{}I{\}}\backslashpi{\$} in the set of realizable policies. We use this framework to introduce operator-based versions of traditional policy gradient methods such as REINFORCE and PPO, which leads to a better understanding of their original counterparts. We also use the understanding we develop of the role of {\$}\backslashmathcal{\{}I{\}}{\$} and {\$}\backslashmathcal{\{}P{\}}{\$} to propose a new global lower bound of the expected return. This new perspective allows us to further bridge the gap between policy-based and value-based methods, showing how REINFORCE and the Bellman optimality operator, for example, can be seen as two sides of the same coin.},
archivePrefix = {arXiv},
arxivId = {2006.11266},
author = {Ghosh, Dibya and Machado, Marlos C. and Roux, Nicolas Le},
eprint = {2006.11266},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Ghosh, Machado, Roux{\_}2020{\_}An operator view of policy gradient methods.pdf:pdf},
number = {NeurIPS},
title = {{An operator view of policy gradient methods}},
url = {http://arxiv.org/abs/2006.11266},
year = {2020}
}
@article{Schmidt2019,
abstract = {Vanilla RNN with ReLU activation have a simple structure that is amenable to systematic dynamical systems analysis and interpretation, but they suffer from the exploding vs. vanishing gradients problem. Recent attempts to retain this simplicity while alleviating the gradient problem are based on proper initialization schemes or orthogonality/unitary constraints on the RNN's recurrence matrix, which, however, comes with limitations to its expressive power with regards to dynamical systems phenomena like chaos or multi-stability. Here, we instead suggest a regularization scheme that pushes part of the RNN's latent subspace toward a line attractor configuration that enables long short-term memory and arbitrarily slow time scales. We show that our approach excels on a number of benchmarks like the sequential MNIST or multiplication problems, and enables reconstruction of dynamical systems which harbor widely different time scales.},
archivePrefix = {arXiv},
arxivId = {1910.03471},
author = {Schmidt, Dominik and Koppe, Georgia and Beutelspacher, Max and Durstewitz, Daniel},
eprint = {1910.03471},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Schmidt et al.{\_}2019{\_}Inferring dynamical systems with long-range dependencies through line attractor regularization.pdf:pdf},
issn = {23318422},
journal = {arXiv},
pages = {1--19},
title = {{Inferring dynamical systems with long-range dependencies through line attractor regularization}},
year = {2019}
}
@article{Friston2015d,
abstract = {We offer a formal treatment of choice behavior based on the premise that agents minimize the expected free energy of future outcomes. Crucially, the negative free energy or quality of a policy can be decomposed into extrinsic and epistemic (or intrinsic) value. Minimizing expected free energy is therefore equivalent to maximizing extrinsic value or expected utility (dened in terms of prior preferences or goals), while maximizing information gain or intrinsic value (or reducing uncertainty about the causes of valuable outcomes). The resulting scheme resolves the exploration-exploitation dilemma: Epistemic value is maximized until there is no further information gain, after which exploitation is assured through maximization of extrinsic value. This is formally consistent with the Infomax principle, generalizing formulations of active vision based upon salience (Bayesian surprise) and optimal decisions based on expected utility and risk-sensitive (Kullback-Leibler) control. Furthermore, as with previous active inference formulations of discrete (Markovian) problems, ad hoc softmax parameters become the expected (Bayes-optimal) precision of beliefs about, or condence in, policies. This article focuses on the basic theory, illustrating the ideas with simulations. A key aspect of these simulations is the similarity between precision updates and dopaminergic discharges observed in conditioning paradigms. This article introduces a variational (free energy) formulation of explorative behavior and the (epistemic) value of knowing one's environment. This formulation tries to unite a number of perspectives on behavioral imperatives; namely, the exploration-exploitation dilemma and the distinction between the explicit (extrinsic) value of controlled outcomes and their epistemic (intrinsic) value in reducing uncertainty about environmental contingencies},
author = {Friston, Karl and Rigoli, Francesco and Ognibene, Dimitri and Mathys, Christoph and Fitzgerald, Thomas and Pezzulo, Giovanni},
doi = {10.1080/17588928.2015.1020053},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston et al.{\_}2015{\_}Active inference and epistemic value.pdf:pdf},
issn = {1758-8928},
journal = {Cognitive Neuroscience},
keywords = {Active inference,Agency,Bayesian inference,Bayesian surprise,Bounded rationality,Epistemic value,Exploitation,Exploration,Free energy,Information gain,Utility theory},
month = {oct},
number = {4},
pages = {187--214},
title = {{Active inference and epistemic value}},
volume = {6},
year = {2015}
}
@article{Jordan1999,
abstract = {This paper presents a tutorial introduction to the use of variational methods for inference and learning in graphical models (Bayesian networks and Markov random fields). We present a number of examples of graphical models, including the QMR-DT database, the sigmoid belief network, the Boltzman machine, and several variants of hidden Markov models, in which it is infeasible to run exact inference algorithms. We then introduce variational methods, which exploit laws of large numbers to transform the original graphical model into a simplified graphical model in which inference is efficient. Inference in the simplified model provides bounds on probabilities of interest in the original model. We describe a general framework for generating variational transformations based on convex duality. Finally we return to the examples and demonstrate how variational algorithms can be formulated in each case.},
author = {Jordan, Michael I. and Ghahramani, Zoubin and Jaakkola, Tommi S. and Saul, Lawrence K.},
doi = {10.1023/A:1007665907178},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Jordan et al.{\_}1999{\_}Introduction to variational methods for graphical models.pdf:pdf},
issn = {08856125},
journal = {Machine Learning},
keywords = {approximate infer-,bayesian networks,belief networks,boltzmann machines,ence,graphical models,hidden markov models,mean field methods,neural networks,probabilistic inference,variational methods},
number = {2},
pages = {183--233},
title = {{Introduction to variational methods for graphical models}},
volume = {37},
year = {1999}
}
@article{Karl2017,
abstract = {We introduce Deep Variational Bayes Filters (DVBF), a new method for unsupervised learning and identification of latent Markovian state space models. Leveraging recent advances in Stochastic Gradient Variational Bayes, DVBF can overcome intractable inference distributions via variational inference. Thus, it can handle highly nonlinear input data with temporal and spatial dependencies such as image sequences without domain knowledge. Our experiments show that enabling backpropagation through transitions enforces state space assumptions and significantly improves information content of the latent embedding. This also enables realistic long-term prediction.},
archivePrefix = {arXiv},
arxivId = {1605.06432},
author = {Karl, Maximilian and Soelch, Maximilian and Bayer, Justin and {Van Der Smagt}, Patrick},
eprint = {1605.06432},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Karl et al.{\_}2017{\_}Deep variational Bayes filters Unsupervised learning of state space models from raw data.pdf:pdf},
journal = {5th International Conference on Learning Representations, ICLR 2017 - Conference Track Proceedings},
number = {ii},
pages = {1--13},
title = {{Deep variational Bayes filters: Unsupervised learning of state space models from raw data}},
year = {2017}
}
@article{Malenka2004,
abstract = {LTP and LTD, the long-term potentiation and depression of excitatory synaptic transmission, are widespread phenomena expressed at possibly every excitatory synapse in the mammalian brain. It is now clear that "LTP" and "LTD" are not unitary phenomena. Their mechanisms vary depending on the synapses and circuits in which they operate. Here we review those forms of LTP and LTD for which mechanisms have been most firmly established. Examples are provided that show how these mechanisms can contribute to experience-dependent modifications of brain function.},
author = {Malenka, Robert C. and Bear, Mark F.},
doi = {10.1016/j.neuron.2004.09.012},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Malenka, Bear{\_}2004{\_}LTP and LTD An embarrassment of riches.pdf:pdf},
issn = {08966273},
journal = {Neuron},
number = {1},
pages = {5--21},
pmid = {15450156},
title = {{LTP and LTD: An embarrassment of riches}},
volume = {44},
year = {2004}
}
@article{Andrews-Hanna2012,
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Andrews-Hanna, Jessica R.},
doi = {10.1177/1073858411403316},
eprint = {NIHMS150003},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Andrews-Hanna{\_}2012{\_}The Brain's Default Network and Its Adaptive Role in Internal Mentation.pdf:pdf},
isbn = {6176321972},
issn = {1073-8584},
journal = {The Neuroscientist},
month = {jun},
number = {3},
pages = {251--270},
pmid = {1000000221},
title = {{The Brain's Default Network and Its Adaptive Role in Internal Mentation}},
url = {http://journals.sagepub.com/doi/10.1177/1073858411403316},
volume = {18},
year = {2012}
}
@article{Munos2014,
abstract = {This work covers several aspects of the optimism in the face of uncertainty principle applied to large scale optimization problems under finite numerical budget. The initial motivation for the research reported here originated from the empirical success of the so-called Monte-Carlo Tree Search method popularized in Computer Go and further extended to many other games as well as optimization and planning problems. Our objective is to contribute to the development of theoretical foundations of the field by characterizing the complexity of the underlying optimization problems and designing efficient algorithms with performance guarantees. The main idea presented here is that it is possible to decompose a complex decision making problem (such as an optimization problem in a large search space) into a sequence of elementary decisions, where each decision of the sequence is solved using a (stochastic) multi-armed bandit (simple mathematical model for decision making in stochastic environments). This so-called hierarchical bandit approach (where the reward observed by a bandit in the hierarchy is itself the return of another bandit at a deeper level) possesses the nice feature of starting the exploration by a quasi-uniform sampling of the space and then focusing progressively on the most promising area, at different scales, according to the evaluations observed so far, until eventually performing a local search around the global optima of the function. The performance of the method is assessed in terms of the optimality of the returned solution as a function of the number of function evaluations. Our main contribution to the field of function optimization is a class of hierarchical optimistic algorithms designed for general search spaces (such as metric spaces, trees, graphs, Euclidean spaces) with different algorithmic instantiations depending on whether the evaluations are noisy or noiseless and whether some measure of the "smoothness" of the function is known or unknown. The performance of the algorithms depends on the "local" behavior of the function around its global optima expressed in terms of the quantity of near-optimal states measured with some metric. If this local smoothness of the function is known then one can design very efficient optimization algorithms (with convergence rate independent of the space dimension). When this information is unknown, one can build adaptive techniques which, in some cases, perform almost as well as when it is known. In order to be self-contained, we start with a brief introduction to the stochastic multi-armed bandit problem in Chapter 1 and describe the UCB (Upper Confidence Bound) strategy and several extensions. In Chapter 2 we present the Monte-Carlo Tree Search method applied to Computer Go and show the limitations of previous algorithms such as UCT (UCB applied to Trees). This provides motivation for designing theoretically well-founded optimistic optimization algorithms. The main contributions on hierarchical optimistic optimization are described in Chapters 3 and 4 where the general setting of a semimetric space is introduced and algorithms designed for optimizing a function assumed to be locally smooth (around its maxima) with respect to a semi-metric are presented and analyzed. Chapter 3 considers the case when the semi-metric is known and can be used by the algorithm, whereas Chapter 4 considers the case when it is not known and describes an adaptive technique that does almost as well as when it is known. Finally in Chapter 5 we describe optimistic strategies for a specific structured problem, namely the planning problem in Markov decision processes with infinite horizon discounted rewards. {\textcopyright} 2014 R. Munos.},
author = {Munos, R{\'{e}}mi},
doi = {10.1561/2200000038},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Munos{\_}2014{\_}From bandits to Monte-Carlo tree search The optimistic principle applied to optimization and planning.pdf:pdf},
issn = {19358237},
journal = {Foundations and Trends in Machine Learning},
number = {1},
pages = {1--129},
title = {{From bandits to Monte-Carlo tree search: The optimistic principle applied to optimization and planning}},
volume = {7},
year = {2014}
}
@article{Zhu2019,
abstract = {Modeling sequential data has been a hot research field for decades. One of the most challenge problems in this field is modeling real-world high-dimensional sequential data with limited training samples. This is mainly due to the following two reasons. First, if the dimension of the data is significantly greater then the number of the data, it may result in the over-fitting problem. Second, the dynamic behavior of the real-world data is very complex and difficult to approximate. To overcome these two problems, we propose a multi-kernel Gaussian process latent variable regression model for high-dimensional sequential data modeling and prediction. In our model, we design a regression model based on the Gaussian process latent variable model. Furthermore, a multi-kernel learning model is designed to automatically construct suitable nonlinear kernel for various types of sequential data. We evaluate the effectiveness of our method using two types of real-world high-dimensional sequential data, including the human motion data and the motion texture video data. In addition, our method is compared with several representative sequential data modeling methods. Experimental results show that our method achieves promising modeling capability and is capable of predict human motion and texture video with higher quality.},
author = {Zhu, Ziqi and Zhang, Jiayuan and Zou, Jixin and Deng, Chunhua},
doi = {10.1016/j.neucom.2018.07.082},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Zhu et al.{\_}2019{\_}Multi-kernel Gaussian process latent variable regression model for high-dimensional sequential data modeling.pdf:pdf},
issn = {18728286},
journal = {Neurocomputing},
keywords = {Gaussian process latent variable model,High-dimensional data,Kernel learning,Sequential data modeling},
pages = {3--15},
publisher = {Elsevier B.V.},
title = {{Multi-kernel Gaussian process latent variable regression model for high-dimensional sequential data modeling}},
volume = {348},
year = {2019}
}
@article{TransSocBRaymondJDolanKarlFriston2014,
abstract = {This paper considers goal-directed decision-making in terms of embodied or active inference. We associate bounded rationality with approximate Bayesian inference that optimizes a free energy bound on model evidence. Several constructs such as expected utility, exploration or novelty bonuses, softmax choice rules and optimism bias emerge as natural consequences of free energy minimization. Previous accounts of active inference have focused on predictive coding . In this paper, we consider variational Bayes as a scheme that the brain might use for approximate Bayesian inference. This scheme provides formal constraints on the computational anatomy of inference and action, which appear to be remarkably consistent with neuroanatomy. Active inference contextualizes optimal decision theory within embodied inference, where goals become prior beliefs. For example, expected utility theory emerges as a special case of free energy minimization, where the sensitivity or inverse temperature (associated with softmax functions and quantal response equilibria) has a unique and Bayes-optimal solution. Crucially, this sensitivity corresponds to the precision of beliefs about behaviour. The changes in precision during variational updates are remarkably reminiscent of empirical dopaminergic responses—and they may provide a new perspective on the role of dopamine in assimilating reward prediction errors to optimize decision-making.},
author = {Friston, Karl and Schwartenbeck, Philipp and FitzGerald, Thomas and Moutoussis, Michael and Behrens, Timothy and Dolan, Raymond J.},
doi = {10.1098/rstb.2013.0481},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston et al.{\_}2014{\_}The anatomy of choice dopamine and decision-making References Subject collections httprstb.royalsocietypublishing.or.pdf:pdf},
issn = {0962-8436},
journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
keywords = {Bayesian inference,Subject Areas: behaviour Keywords: active inferenc,agency,bounded rationality,free energy,utility theory},
month = {nov},
number = {1655},
pages = {20130481},
title = {{The anatomy of choice: dopamine and decision-making}},
url = {http://rstb.royalsocietypublishing.org/content/369/1655/20130481.full.html{\#}related-urlshttp://rstb.royalsocietypublishing.org/content/369/1655/20130481.full.html{\#}ref-list-1 https://royalsocietypublishing.org/doi/10.1098/rstb.2013.0481},
volume = {369},
year = {2014}
}
@article{Friston2013b,
abstract = {This paper presents a heuristic proof (and simulations of a primordial soup) suggesting that life-or biological self-organization-is an inevitable and emergent property of any (ergodic) random dynamical system that possesses a Markov blanket. This conclusion is based on the following arguments: if the coupling among an ensemble of dynamical systems is mediated by short-range forces, then the states of remote systems must be conditionally independent. These independencies induce a Markov blanket that separates internal and external states in a statistical sense. The existence of a Markov blanket means that internal states will appear to minimize a free energy functional of the states of their Markov blanket. Crucially, this is the same quantity that is optimized in Bayesian inference. Therefore, the internal states (and their blanket) will appear to engage in active Bayesian inference. In other words, they will appear to model-and act on-their world to preserve their functional and structural integrity, leading to homoeostasis and a simple form of autopoiesis. {\textcopyright} 2013 The Author(s).},
author = {Friston, Karl},
doi = {10.1098/rsif.2013.0475},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston{\_}2013{\_}Life as we know it(2).pdf:pdf},
issn = {17425662},
journal = {Journal of the Royal Society Interface},
keywords = {Active inference,Autopoiesis,Ergodicity,Free energy,Random attractor,Self-organization},
number = {86},
pmid = {23825119},
title = {{Life as we know it}},
volume = {10},
year = {2013}
}
@incollection{Barlow1961,
abstract = {In W.A. Rosenblith, editor, Sensory Communication, pages 217–234. MIT Press, Cambridge, MA, 1961.},
annote = {Builds uppon MacKay's early intuition of a predictive coding model of information flow with a simple but interesting formulation of message coding that naturally reduces information redundancy. Signals that are very frequent (or expected) are not propagated further (or at least atenuated)

Tags: [ETR][PRE][EVT][HIF][PCO][CHU][IFD]},
author = {Barlow, H. B.},
booktitle = {Sensory Communication},
doi = {10.7551/mitpress/9780262518420.003.0013},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Barlow{\_}1961{\_}Possible Principles Underlying the Transformations of Sensory Messages.pdf:pdf},
pages = {216--234},
publisher = {The MIT Press},
title = {{Possible Principles Underlying the Transformations of Sensory Messages}},
url = {http://www.worldcat.org/oclc/967671089},
year = {1961}
}
@article{Friston2012b,
abstract = {If perception corresponds to hypothesis testing (Gregory, 1980); then visual searches might be construed as experiments that generate sensory data. In this work, we explore the idea that saccadic eye movements are optimal experiments, in which data are gathered to test hypotheses or beliefs about how those data are caused. This provides a plausible model of visual search that can be motivated from the basic principles of self-organized behavior: namely, the imperative to minimize the entropy of hidden states of the world and their sensory consequences.This imperative is met if agents sample hidden states of the world efficiently.This efficient sampling of salient information can be derived in a fairly straightforward way, using approximate Bayesian inference and variational free-energy minimization. Simulations of the resulting active inference scheme reproduce sequential eye movements that are reminiscent of empirically observed saccades and provide some counterintuitive insights into the way that sensory evidence is accumulated or assimilated into beliefs about the world. {\textcopyright} 2012 Friston, Adams, Perrinet and Breakspear.},
author = {Friston, Karl J. and Adams, Rick A. and Perrinet, Laurent and Breakspear, Michael},
doi = {10.3389/fpsyg.2012.00151},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston et al.{\_}2012{\_}Perceptions as hypotheses Saccades as experiments.pdf:pdf},
issn = {16641078},
journal = {Frontiers in Psychology},
keywords = {Active inference,Bayesian inference,Exploration,Free energy,Perception,Salience,Surprise,Visual search},
number = {MAY},
pages = {1--20},
title = {{Perceptions as hypotheses: Saccades as experiments}},
volume = {3},
year = {2012}
}
@inproceedings{Toussaint2009,
abstract = {The general stochastic optimal control (SOC) problem in robotics scenarios is often too complex to be solved exactly and in near real time. A classical approximate solution is to first compute an optimal (deterministic) trajectory and then solve a local linear-quadratic-gaussian (LQG) perturbation model to handle the system stochasticity. We present a new algorithm for this approach which improves upon previous algorithms like iLQG. We consider a probabilistic model for which the maximum likelihood (ML) trajectory coincides with the optimal trajectory and which, in the LQG case, reproduces the classical SOC solution. The algorithm then utilizes approximate inference methods (similar to expectation propagation) that efficiently generalize to non-LQG systems. We demonstrate the algorithm on a simulated 39-DoF humanoid robot.},
author = {Toussaint, Marc},
booktitle = {Proceedings of the 26th International Conference On Machine Learning, ICML 2009},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Toussaint{\_}2009{\_}Robot trajectory optimization using approximate inference.pdf:pdf},
isbn = {9781605585161},
pages = {1049--1056},
title = {{Robot trajectory optimization using approximate inference}},
year = {2009}
}
@article{ODoherty2003,
abstract = {Temporal difference learning has been proposed as a model for Pavlovian conditioning, in which an animal learns to predict delivery of reward following presentation of a conditioned stimulus (CS). A key component of this model is a prediction error signal, which, before learning, responds at the time of presentation of reward but, after learning, shifts its response to the time of onset of the CS. In order to test for regions manifesting this signal profile, subjects were scanned using event-related fMRI while undergoing appetitive conditioning with a pleasant taste reward. Regression analyses revealed that responses in ventral striatum and orbitofrontal cortex were significantly correlated with this error signal, suggesting that, during appetitive conditioning, computations described by temporal difference learning are expressed in the human brain.},
author = {O'Doherty, John P. and Dayan, Peter and Friston, Karl J. and Critchley, Hugo and Dolan, Raymond J.},
doi = {10.1016/S0896-6273(03)00169-7},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/O'Doherty et al.{\_}2003{\_}Temporal difference models and reward-related learning in the human brain.pdf:pdf},
issn = {08966273},
journal = {Neuron},
number = {2},
pages = {329--337},
pmid = {12718865},
title = {{Temporal difference models and reward-related learning in the human brain}},
volume = {38},
year = {2003}
}
@article{Air2019,
author = {Air, Water From},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop//Hoffman{\_}2019{\_}Reality The Greatest Illusion of All How Evolution Has Blinded Us to the Truth about the World.pdf:pdf},
title = {{Reality: The Greatest Illusion of All}},
year = {2019}
}
@article{Hornik1991,
abstract = {We show that standard multilayer feedforward networks with as few as a single hidden layer and arbitrary bounded and nonconstant activation function are universal approximators with respect to Lp(mu) performance criteria, for arbitrary finite input environment measures mu, provided only that sufficiently many hidden units are available. If the activation function is continuous, bounded and nonconstant, then continuous mappings can be learned uniformly over compact input sets. We also give very general conditions ensuring that networks with sufficiently smooth activation functions are capable of arbitrarily accurate approximation to a function and its derivatives.},
author = {Hornik, Kurt},
doi = {10.1016/0893-6080(91)90009-T},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Hornik{\_}1991{\_}Approximation capabilities of multilayer feedforward networks.pdf:pdf},
issn = {08936080},
journal = {Neural Networks},
keywords = {Lp(mu) approximation,Sobolev spaces,activation function,input environment measure,multilayer feedforward networks,smooth approximation,uniform approximation,universal approximation capabilities},
number = {2},
pages = {251--257},
title = {{Approximation capabilities of multilayer feedforward networks}},
url = {https://linkinghub.elsevier.com/retrieve/pii/089360809190009T},
volume = {4},
year = {1991}
}
@article{Hopfield2000a,
author = {Hopfield, John J.},
doi = {10.1038/81484},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Hopfield{\_}2000{\_}On theorists and data in computational neuroscience.pdf:pdf},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {nov},
number = {S11},
pages = {1204--1204},
publisher = {Nature America},
title = {{On theorists and data in computational neuroscience}},
url = {http://www.nature.com/articles/nn1100{\_}1204},
volume = {3},
year = {2000}
}
@article{Shannon1948,
author = {Shannon, C. E.},
doi = {10.1002/j.1538-7305.1948.tb01338.x},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Shannon{\_}1948{\_}A Mathematical Theory of Communication.pdf:pdf},
issn = {00058580},
journal = {Bell System Technical Journal},
month = {jul},
number = {3},
pages = {379--423},
title = {{A Mathematical Theory of Communication}},
url = {https://ieeexplore.ieee.org/document/6773024},
volume = {27},
year = {1948}
}
@article{Kiebel2009,
abstract = {The brain's decoding of fast sensory streams is currently impossible to emulate, even approximately, with artificial agents. For example, robust speech recognition is relatively easy for humans but exceptionally difficult for artificial speech recognition systems. In this paper, we propose that recognition can be simplified with an internal model of how sensory input is generated, when formulated in a Bayesian framework. We show that a plausible candidate for an internal or generative model is a hierarchy of 'stable heteroclinic channels'. This model describes continuous dynamics in the environment as a hierarchy of sequences, where slower sequences cause faster sequences. Under this model, online recognition corresponds to the dynamic decoding of causal sequences, giving a representation of the environment with predictive power on several timescales. We illustrate the ensuing decoding or recognition scheme using synthetic sequences of syllables, where syllables are sequences of phonemes and phonemes are sequences of sound-wave modulations. By presenting anomalous stimuli, we find that the resulting recognition dynamics disclose inference at multiple time scales and are reminiscent of neuronal dynamics seen in the real brain. {\textcopyright} 2009 Kiebel et al.},
author = {Kiebel, Stefan J. and {Von Kriegstein}, Katharina and Daunizeau, Jean and Friston, Karl J.},
doi = {10.1371/journal.pcbi.1000464},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Kiebel et al.{\_}2009{\_}Recognizing sequences of sequences.pdf:pdf},
issn = {1553734X},
journal = {PLoS Computational Biology},
number = {8},
pmid = {19680429},
title = {{Recognizing sequences of sequences}},
volume = {5},
year = {2009}
}
@article{Harrison2006a,
abstract = {The medial temporal lobe may play a critical role in binding successive events into memory while encoding contextual information in implicit and explicit memory tasks. Information theory provides a quantitative basis to model contextual information engendered by conditional dependence between, or conditional uncertainty about, consecutive events in a sequence. We show that information theoretic indices characterizing contextual dependence within a sequential reaction time task (SRTT) predict regional responses, measured by fMRI, in areas associated with sequence learning and navigation. Specifically, activity of a distributed paralimbic system, centered on the left hippocampus, correlated selectively with predictability as measured with mutual information. This is clear evidence that the brain is sensitive to the probabilistic context in which events are encountered. This is potentially important for theories about how the brain represents uncertainty and makes perceptual inferences, particularly those based on predictive coding and hierarchical Bayes. {\textcopyright} 2006 Elsevier Ltd. All rights reserved.},
author = {Harrison, Lee M. and Duggins, A. and Friston, Karl J.},
doi = {10.1016/j.neunet.2005.11.002},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Harrison, Duggins, Friston{\_}2006{\_}Encoding uncertainty in the hippocampus.pdf:pdf},
issn = {08936080},
journal = {Neural Networks},
keywords = {1st order Markov sequence,Bayesian observer,Implicit learning,Information theory,Medial temporal lobe,Predictability,Sequential reaction time task (SRTT)},
number = {5},
pages = {535--546},
title = {{Encoding uncertainty in the hippocampus}},
volume = {19},
year = {2006}
}
@misc{Hijne2020,
author = {Hijne, I L},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Hijne{\_}2020{\_}Generalised Motions in Active Inference by finite differences.pdf:pdf},
institution = {TU Delft},
title = {{Generalised Motions in Active Inference by finite differences}},
url = {http://resolver.tudelft.nl/uuid:9102f269-ca73-4281-99e0-ea911282859e},
year = {2020}
}
@article{Legg2007a,
abstract = {This paper is a survey of a large number of informal definitions of ``intelligence'' that the authors have collected over the years. Naturally, compiling a complete list would be impossible as many definitions of intelligence are buried deep inside articles and books. Nevertheless, the 70-odd definitions presented here are, to the authors' knowledge, the largest and most well referenced collection there is.},
archivePrefix = {arXiv},
arxivId = {0706.3639},
author = {Legg, Shane and Hutter, Marcus},
eprint = {0706.3639},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Legg, Hutter{\_}2007{\_}A Collection of Definitions of Intelligence.pdf:pdf},
keywords = {artificial,collective,intelligence definitions,psychologist,universal},
month = {jun},
pages = {1--12},
title = {{A Collection of Definitions of Intelligence}},
url = {http://arxiv.org/abs/0706.3639},
year = {2007}
}
@article{Kanai2015,
abstract = {This paper considers neuronal architectures from a computational perspective and asks what aspects of neuroanatomyand neurophysiology can be disclosed by the nature of neuronal computations? In particular, we extend current formulations of the brain as an organ of inference—based upon hierarchical predictive coding—and consider how these inferences are orchestrated. In other words,whatwould the brain require to dynamically coordinate and contextualize its message passing to optimize its computational goals? The answer that emerges rests on the delicate (modulatory) gain control of neuronal populations that select and coordinate (prediction error) signals that ascend cortical hierarchies. This is important because it speaks to a hierarchical anatomy of extrinsic (between region) connections that form two distinct classes, namely a class of driving (first-order) connections that are concerned with encoding the content of neuronal representations and a class of modulatory (second-order) connections that establish context—in the form of the salience or precision ascribed to content.We explore the implications of this distinction from a formal perspective (using simulations of feature–ground segregation) and consider the neurobiological substrates of the ensuing precision-engineered dynamics, with a special focus on the pulvinar and attention.},
author = {Kanai, Ryota and Komura, Yutaka and Shipp, Stewart and Friston, Karl J.},
doi = {10.1098/rstb.2014.0169},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Kanai et al.{\_}2015{\_}Cerebral hierarchies Predictive processing, precision and the pulvinar.pdf:pdf},
issn = {14712970},
journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
keywords = {Attention,Neuromodulation,Neuronal computational,Precision,Predictive coding,Pulvinar},
number = {1668},
title = {{Cerebral hierarchies: Predictive processing, precision and the pulvinar}},
volume = {370},
year = {2015}
}
@article{Raichle2015,
abstract = {The brain's default mode network consists of discrete, bilateral and symmetrical cortical areas, in the medial and lateral parietal, medial prefrontal, and medial and lateral temporal cortices of the human, nonhuman primate, cat, and rodent brains. Its discovery was an unexpected consequence of brain-imaging studies first performed with positron emission tomography in which various novel, attention-demanding, and non-self-referential tasks were compared with quiet repose either with eyes closed or with simple visual fixation. The default mode network consistently decreases its activity when compared with activity during these relaxed nontask states. The discovery of the default mode network reignited a longstanding interest in the significance of the brain's ongoing or intrinsic activity. Presently, studies of the brain's intrinsic activity, popularly referred to as resting-state studies, have come to play a major role in studies of the human brain in health and disease. The brain's default mode network plays a central role in this work.},
author = {Raichle, Marcus E.},
doi = {10.1146/annurev-neuro-071013-014030},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Raichle{\_}2015{\_}The Brain's Default Mode Network.pdf:pdf},
issn = {0147-006X},
journal = {Annual Review of Neuroscience},
keywords = {Activation,Attention,Baseline,Functional connectivity,Intrinsic activity,Memory,Resting state,Self},
month = {jul},
number = {1},
pages = {433--447},
pmid = {25938726},
title = {{The Brain's Default Mode Network}},
url = {http://www.annualreviews.org/doi/10.1146/annurev-neuro-071013-014030},
volume = {38},
year = {2015}
}
@article{Pinotsis2012,
author = {Pinotsis, Dimitris and Moran, R. J. and Friston, Karl J.},
doi = {10.1016/j.neuroimage.2011.08.020},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Pinotsis, Moran, Friston{\_}2012{\_}Dynamic causal modeling with neural fields.pdf:pdf},
issn = {10538119},
journal = {NeuroImage},
month = {jan},
number = {2},
pages = {1261--1274},
title = {{Dynamic causal modeling with neural fields}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811911009098},
volume = {59},
year = {2012}
}
@article{Millidge2020a,
abstract = {Active Inference (AIF) is an emerging framework in the brain sciences which suggests that biological agents act to minimise a variational bound on model evidence. Control-as-Inference (CAI) is a framework within reinforcement learning which casts decision making as a variational inference problem. While these frameworks both consider action selection through the lens of variational inference, their relationship remains unclear. Here, we provide a formal comparison between them and demonstrate that the primary difference arises from how value is incorporated into their respective generative models. In the context of this comparison, we highlight several ways in which these frameworks can inform one another.},
archivePrefix = {arXiv},
arxivId = {2006.12964},
author = {Millidge, Beren and Tschantz, Alexander and Seth, Anil K and Buckley, Christopher L},
eprint = {2006.12964},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Millidge et al.{\_}2020{\_}On the Relationship Between Active Inference and Control as Inference.pdf:pdf},
title = {{On the Relationship Between Active Inference and Control as Inference}},
year = {2020}
}
@article{Tschantz2019,
abstract = {In reinforcement learning (RL), agents often operate in partially observed and uncertain environments. Model-based RL suggests that this is best achieved by learning and exploiting a probabilistic model of the world. 'Active inference' is an emerging normative framework in cognitive and computational neuroscience that offers a unifying account of how biological agents achieve this. On this framework, inference, learning and action emerge from a single imperative to maximize the Bayesian evidence for a niched model of the world. However, implementations of this process have thus far been restricted to low-dimensional and idealized situations. Here, we present a working implementation of active inference that applies to high-dimensional tasks, with proof-of-principle results demonstrating efficient exploration and an order of magnitude increase in sample efficiency over strong model-free baselines. Our results demonstrate the feasibility of applying active inference at scale and highlight the operational homologies between active inference and current model-based approaches to RL.},
archivePrefix = {arXiv},
arxivId = {1911.10601},
author = {Tschantz, Alexander and Baltieri, Manuel and Seth, Anil K. and Buckley, Christopher L.},
eprint = {1911.10601},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Tschantz et al.{\_}2019{\_}Scaling active inference.pdf:pdf},
journal = {arXiv},
month = {nov},
pages = {1--13},
title = {{Scaling active inference}},
year = {2019}
}
@incollection{Sutton2018,
abstract = {Presents the book "Reinforcement Learning: An Introduction," written by Richard S. Sutton and Andrew G. Barto and published by the Massachusetts Institute of Technology (MIT) Press in 1998. The book is a textbook targeted toward engineers and scientists in artificial intelligence, operations research, neural networks, and control systems. Examines a computation approach to learning from interaction with environment. 1. Introduction -- 2. Evaluative feedback -- 3. The reinforcement learning problem -- 4. Dynamic programming -- 5. Monte carlo methods -- 6. Temporal-difference learning -- 7. Eligibility traces -- 8. Generalization and function approximation -- 9. Planning and learning -- 10. Dimensions of reinforcement learning -- 11. Case studies.},
author = {Sutton, Richard S. and Barto, Andrew G.},
booktitle = {Reinforcement Learning: an introduction},
chapter = {17},
edition = {2},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop//Sutton, Barto{\_}2018{\_}Frontiers (in reinforcement learning).pdf:pdf},
isbn = {9780262193986},
pages = {460--480},
publisher = {The MIT Press},
title = {{Frontiers (in reinforcement learning)}},
year = {2018}
}
@article{Hooker2020,
abstract = {Hardware, systems and algorithms research communities have historically had different incentive structures and fluctuating motivation to engage with each other explicitly. This historical treatment is odd given that hardware and software have frequently determined which research ideas succeed (and fail). This essay introduces the term hardware lottery to describe when a research idea wins because it is suited to the available software and hardware and not because the idea is superior to alternative research directions. Examples from early computer science history illustrate how hardware lotteries can delay research progress by casting successful ideas as failures. These lessons are particularly salient given the advent of domain specialized hardware which make it increasingly costly to stray off of the beaten path of research ideas. This essay posits that the gains from progress in computing are likely to become even more uneven, with certain research directions moving into the fast-lane while progress on others is further obstructed.},
archivePrefix = {arXiv},
arxivId = {2009.06489},
author = {Hooker, Sara},
eprint = {2009.06489},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Hooker{\_}2020{\_}The Hardware Lottery.pdf:pdf},
journal = {arXiv},
month = {sep},
title = {{The Hardware Lottery}},
year = {2020}
}
@article{Kaplan2018a,
abstract = {This paper introduces an active inference formulation of planning and navigation. It illustrates how the exploitation–exploration dilemma is dissolved by acting to minimise uncertainty (i.e. expected surprise or free energy). We use simulations of a maze problem to illustrate how agents can solve quite complicated problems using context sensitive prior preferences to form subgoals. Our focus is on how epistemic behaviour—driven by novelty and the imperative to reduce uncertainty about the world—contextualises pragmatic or goal-directed behaviour. Using simulations, we illustrate the underlying process theory with synthetic behavioural and electrophysiological responses during exploration of a maze and subsequent navigation to a target location. An interesting phenomenon that emerged from the simulations was a putative distinction between ‘place cells'—that fire when a subgoal is reached—and ‘path cells'—that fire until a subgoal is reached.},
author = {Kaplan, Raphael and Friston, Karl J.},
doi = {10.1007/s00422-018-0753-2},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Kaplan, Friston{\_}2018{\_}Planning and navigation as active inference.pdf:pdf},
issn = {14320770},
journal = {Biological Cybernetics},
keywords = {Active inference,Bayesian,Curiosity,Epistemic value,Exploitation,Exploration,Free energy,Novelty,Salience},
number = {4},
pages = {323--343},
publisher = {Springer Berlin Heidelberg},
title = {{Planning and navigation as active inference}},
url = {https://doi.org/10.1007/s00422-018-0753-2},
volume = {112},
year = {2018}
}
@article{Luczak2015,
abstract = {Cortical circuits work through the generation of coordinated, large-scale activity patterns. In sensory systems, the onset of a discrete stimulus usually evokes a temporally organized packet of population activity lasting {\^{a}} 1/450-200 ms. The structure of these packets is partially stereotypical, and variation in the exact timing and number of spikes within a packet conveys information about the identity of the stimulus. Similar packets also occur during ongoing stimuli and spontaneously. We suggest that such packets constitute the basic building blocks of cortical coding.},
author = {Luczak, Artur and McNaughton, Bruce L. and Harris, Kenneth D.},
doi = {10.1038/nrn4026},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Luczak, McNaughton, Harris{\_}2015{\_}Packet-based communication in the cortex.pdf:pdf},
issn = {1471-003X},
journal = {Nature Reviews Neuroscience},
month = {dec},
number = {12},
pages = {745--755},
pmid = {26507295},
publisher = {Nature Publishing Group},
title = {{Packet-based communication in the cortex}},
url = {http://dx.doi.org/10.1038/nrn4026 http://www.nature.com/articles/nrn4026},
volume = {16},
year = {2015}
}
@article{Daunizeau2010,
abstract = {In this paper, we present a generic approach that can be used to infer how subjects make optimal decisions under uncertainty. This approach induces a distinction between a subject's perceptual model, which underlies the representation of a hidden "state of affairs" and a response model, which predicts the ensuing behavioural (or neurophysiological) responses to those inputs. We start with the premise that subjects continuously update a probabilistic representation of the causes of their sensory inputs to optimise their behaviour. In addition, subjects have preferences or goals that guide decisions about actions given the above uncertain representation of these hidden causes or state of affairs. From a Bayesian decision theoretic perspective, uncertain representations are so-called "posterior" beliefs, which are influenced by subjective "prior" beliefs. Preferences and goals are encoded through a "loss" (or "utility") function, which measures the cost incurred by making any admissible decision for any given (hidden) state of affair. By assuming that subjects make optimal decisions on the basis of updated (posterior) beliefs and utility (loss) functions, one can evaluate the likelihood of observed behaviour. Critically, this enables one to "observe the observer", i.e. identify (context- or subject-dependent) prior beliefs and utility-functions using psychophysical or neurophysiological measures. In this paper, we describe the main theoretical components of this meta-Bayesian approach (i.e. a Bayesian treatment of Bayesian decision theoretic predictions). In a companion paper ('Observing the observer (II): deciding when to decide'), we describe a concrete implementation of it and demonstrate its utility by applying it to simulated and real reaction time data from an associative learning task. {\textcopyright} 2010 Daunizeau et al.},
author = {Daunizeau, Jean and den Ouden, Hanneke E.M. and Pessiglione, Matthias and Kiebel, Stefan J. and Stephan, Klaas E. and Friston, Karl J.},
doi = {10.1371/journal.pone.0015554},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Daunizeau et al.{\_}2010{\_}Observing the observer (I) Meta-bayesian models of learning and decision-making.pdf:pdf},
issn = {19326203},
journal = {PLoS ONE},
number = {12},
pmid = {21179480},
title = {{Observing the observer (I): Meta-bayesian models of learning and decision-making}},
volume = {5},
year = {2010}
}
@article{Fernandez-Delgado2014,
abstract = {We evaluate 179 classifiers arising from 17 families (discriminant analysis, Bayesian, neural networks, support vector machines, decision trees, rule-based classifi ers, boosting, bagging, stacking, random forests and other ensembles, generalized linear models, nearestneighbors, partial least squares and principal component regression, logistic and multinomial regression, multiple adaptive regression splines and other methods), implemented in Weka, R (with and without the caret package), C and Matlab, including all the relevant classifiers available today. We use 121 data sets, which represent the whole UCI data base (excluding the large-scale problems) and other own real problems, in order to achieve significant conclusions about the classifier behavior, not dependent on the data set collection. The classifiers most likely to be the bests are the random forest (RF) versions, the best of which (implemented in R and accessed via caret) achieves 94.1{\%} of the maximum accuracy overcoming 90{\%} in the 84.3{\%} of the data sets. However, the difference is not statistically significant with the second best, the SVM with Gaussian kernel implemented in C using LibSVM, which achieves 92.3{\%} of the maximum accuracy. A few models are clearly better than the remaining ones: random forest, SVM with Gaussian and polynomial kernels, extreme learning machine with Gaussian kernel, C5.0 and avNNet (a committee of multi-layer perceptrons implemented in R with the caret package). The random forest is clearly the best family of classifiers (3 out of 5 bests classi ers are RF), followed by SVM (4 classifiers in the top-10), neural networks and boosting ensembles (5 and 3 members in the top-20, respectively).},
author = {Fern{\'{a}}ndez-Delgado, Manuel and Cernadas, Eva and Barro, Sen{\'{e}}n and Amorim, Dinani},
doi = {10.1117/1.JRS.11.015020},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Fern{\'{a}}ndez-Delgado et al.{\_}2014{\_}Do we need hundreds of classifiers to solve real world classification problems.pdf:pdf},
issn = {15337928},
journal = {Journal of Machine Learning Research},
keywords = {Bayesian classifiers,Classification,Decision trees,Discriminant analysis,Ensembles,Generalized linear models,Logistic and multinomial regression,Multiple adaptive regression splines,Nearest-neighbors,Neural networks,Partial least squares and principal component regr,Random forest,Rule-based classifiers,Support vector machine,UCI data base},
pages = {3133--3181},
title = {{Do we need hundreds of classifiers to solve real world classification problems?}},
volume = {15},
year = {2014}
}
@misc{Hafner2020,
abstract = {We introduce a unified objective for action and perception of intelligent agents. Extending representation learning and control, we minimize the joint divergence between the combined system of agent and environment and a target distribution. Intuitively, such agents use perception to align their beliefs with the world, and use actions to align the world with their beliefs. Minimizing the joint divergence to an expressive target maximizes the mutual information between the agent's representations and inputs, thus inferring representations that are informative of past inputs and exploring future inputs that are informative of the representations. This lets us explain intrinsic objectives, such as representation learning, information gain, empowerment, and skill discovery from minimal assumptions. Moreover, interpreting the target distribution as a latent variable model suggests powerful world models as a path toward highly adaptive agents that seek large niches in their environments, rendering task rewards optional. The framework provides a common language for comparing a wide range of objectives, advances the understanding of latent variables for decision making, and offers a recipe for designing novel objectives. We recommend deriving future agent objectives the joint divergence to facilitate comparison, to point out the agent's target distribution, and to identify the intrinsic objective terms needed to reach that distribution.},
archivePrefix = {arXiv},
arxivId = {2009.01791},
author = {Hafner, Danijar and Ortega, Pedro A. and Ba, Jimmy and Parr, Thomas and Friston, Karl J. and Heess, Nicolas},
eprint = {2009.01791},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Hafner et al.{\_}2020{\_}Action and Perception as Divergence Minimization.pdf:pdf},
month = {sep},
pages = {1--24},
title = {{Action and Perception as Divergence Minimization}},
url = {http://arxiv.org/abs/2009.01791},
year = {2020}
}
@article{Attias2003,
abstract = {This paper presents and demonstrates a new$\backslash$n$\backslash$napproach to the problem of planning under$\backslash$n$\backslash$nuncertainty. Actions are treated as hidden$\backslash$n$\backslash$nvariables, with their own prior distributions,$\backslash$n$\backslash$nin a probabilistic generative model involv-$\backslash$n$\backslash$ning actions and states. Planning is done by$\backslash$n$\backslash$ncomputing the posterior distribution over ac-$\backslash$n$\backslash$ntions, conditioned on reaching the goal state$\backslash$n$\backslash$nwithin a specified number of steps. Under$\backslash$n$\backslash$nthe new formulation, the toolbox of inference$\backslash$n$\backslash$ntechniques be brought to bear on the plan-$\backslash$n$\backslash$nning problem. This paper focuses on prob-$\backslash$n$\backslash$nlems with discrete actions and states, and$\backslash$n$\backslash$ndiscusses some extensions.},
author = {Attias, H},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Attias{\_}2003{\_}Planning by probabilistic inference.pdf:pdf},
journal = {Proc. of the 9th Int. Workshop on Artificial Intelligence and Statistics},
title = {{Planning by probabilistic inference}},
year = {2003}
}
@article{Hopfield2008,
abstract = {The algorithms that simple feedback neural circuits representing a brain area can rapidly carry out are often adequate to solve easy problems but for more difficult problems can return incorrect answers. A new excitatory- inhibitory circuit model of associative memory displays the common human problem of failing to rapidly find a memory when only a small clue is present. The memory model and a related computational network for solving Sudoku puzzles produce answers that contain implicit check bits in the representation of information across neurons, allowing a rapid evaluation of whether the putative answer is correct or incorrect through a computation related to visual pop-out. This fact may account for our strong psychological feeling of right or wrong when we retrieve a nominal memory from a minimal clue. This information allows more difficult computations or memory retrievals to be done in a serial fashion by using the fast but limited capabilities of a computational module multiple times. The mathematics of the excitatoryinhibitory circuits for associative memory and for Sudoku, both of which are understood in terms of energy or Lyapunov functions, is described in detail. {\textcopyright} 2008 Massachusetts Institute of Technology.},
author = {Hopfield, John J.},
doi = {10.1162/neco.2008.09-06-345},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Hopfield{\_}2008{\_}Searching for memories, Sudoku, implicit check bits, and the iterative use of not-always-correct rapid neural computation.pdf:pdf},
issn = {08997667},
journal = {Neural Computation},
number = {5},
pages = {1119--1164},
pmid = {18199026},
title = {{Searching for memories, Sudoku, implicit check bits, and the iterative use of not-always-correct rapid neural computation}},
volume = {20},
year = {2008}
}
@article{Tucker2018,
abstract = {Deep latent variable models have become a popular model choice due to the scalable learning algorithms introduced by (Kingma {\&} Welling, 2013; Rezende et al., 2014). These approaches maximize a variational lower bound on the intractable log likelihood of the observed data. Burda et al. (2015) introduced a multi-sample variational bound, IWAE, that is at least as tight as the standard variational lower bound and becomes increasingly tight as the number of samples increases. Counterintuitively, the typical inference network gradient estimator for the IWAE bound performs poorly as the number of samples increases (Rainforth et al., 2018; Le et al., 2018). Roeder et al. (2017) propose an improved gradient estimator, however, are unable to show it is unbiased. We show that it is in fact biased and that the bias can be estimated efficiently with a second application of the reparameterization trick. The doubly reparameterized gradient (DReG) estimator does not suffer as the number of samples increases, resolving the previously raised issues. The same idea can be used to improve many recently introduced training techniques for latent variable models. In particular, we show that this estimator reduces the variance of the IWAE gradient, the reweighted wake-sleep update (RWS) (Bornschein {\&} Bengio, 2014), and the jackknife variational inference (JVI) gradient (Nowozin, 2018). Finally, we show that this computationally efficient, unbiased drop-in gradient estimator translates to improved performance for all three objectives on several modeling tasks.},
archivePrefix = {arXiv},
arxivId = {1810.04152},
author = {Tucker, George and Lawson, Dieterich and Gu, Shixiang and Maddison, Chris J},
eprint = {1810.04152},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Tucker et al.{\_}2018{\_}Doubly Reparameterized Gradient Estimators for Monte Carlo Objectives.pdf:pdf},
month = {oct},
number = {2015},
pages = {1--14},
title = {{Doubly Reparameterized Gradient Estimators for Monte Carlo Objectives}},
url = {http://arxiv.org/abs/1810.04152},
year = {2018}
}
@article{Kingma2014,
abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
archivePrefix = {arXiv},
arxivId = {1312.6114},
author = {Kingma, Diederik P. and Welling, Max},
eprint = {1312.6114},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Kingma, Welling{\_}2014{\_}Auto-encoding variational bayes.pdf:pdf},
journal = {2nd International Conference on Learning Representations, ICLR 2014 - Conference Track Proceedings},
number = {Ml},
pages = {1--14},
title = {{Auto-encoding variational bayes}},
year = {2014}
}
@article{Keirse1995,
abstract = {OBJECTIVE: The trial was conducted to obtain an unbiased comparison of the relative merits of endocervical and vaginal prostaglandin E2 gel in a weighted case mix of parous and nulliparous women with favorable and unfavorable cervical features. STUDY DESIGN: Multicenter ranodmized trial with 285 participants, (three exclusions) was performed with sealed envelopes stratified for parity and Bishop score. RESULTS: Outcomes of labor and delivery were clearly related to the cervical score at trial entry, especially in nulliparous women. Endocervical prostaglandin E2 had a more marked effect on cervical ripeness than did vaginal prostaglandin E2, but this did not result in any differences in more substantive outcomes. Frequencies of delivery within 12 (50{\%}) and 24 hours (77.7{\%}), cesarean section (7.3{\%}), instrumental vaginal delivery (11.7{\%}), and poor infant outcomes were similar with both preparations. CONCLUSION: Because differences in effectiveness between endocervical and vaginal prostaglandin E2 in triacetin gel are marginal, preferences of women and clinicians can determine the choice between them. {\textcopyright} 1995, All rights reserved.},
author = {Keirse, Marc J.N.C. and {de Koning Gans}, Henk J.},
doi = {10.1016/0002-9378(95)90441-7},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Keirse, de Koning Gans{\_}1995{\_}Randomized comparison of the effects of endocervical and vaginal prostaglandin E2 gel in women with various.pdf:pdf},
issn = {00029378},
journal = {American Journal of Obstetrics and Gynecology},
keywords = {Prostaglandin E2,cervical ripening,cesarean section,induction of labor,operative delivery,randomized controlled trial},
number = {6},
pages = {1859--1864},
title = {{Randomized comparison of the effects of endocervical and vaginal prostaglandin E2 gel in women with various degrees of cervical ripeness}},
volume = {173},
year = {1995}
}
@book{Ziegel1997,
abstract = {Te lenen},
annote = {The refered pages show how normal linear dynamic models can be used with non-normal data by applying some transformations},
author = {Ziegel, Eric R. and West, M. and Harrison, J.},
booktitle = {Technometrics},
doi = {10.2307/1271526},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Ziegel, West, Harrison{\_}1997{\_}Bayesian Forecasting and Dynamic Models.pdf:pdf},
issn = {00401706},
number = {4},
pages = {353--364},
title = {{Bayesian Forecasting and Dynamic Models}},
volume = {39},
year = {1997}
}
@article{Friston2012,
abstract = {It has been suggested recently that action and perception can be understood as minimising the free energy of sensory samples. This ensures that agents sample the environment to maximise the evidence for their model of the world, such that exchanges with the environment are predictable and adaptive. However, the free energy account does not invoke reward or cost-functions from reinforcement-learning and optimal control theory. We therefore ask whether reward is necessary to explain adaptive behaviour. The free energy formulation uses ideas from statistical physics to explain action in terms of minimising sensory surprise. Conversely, reinforcement-learning has its roots in behaviourism and engineering and assumes that agents optimise a policy to maximise future reward. This paper tries to connect the two formulations and concludes that optimal policies correspond to empirical priors on the trajectories of hidden environmental states, which compel agents to seek out the (valuable) states they expect to encounter. Copyright {\textcopyright} 2012 Karl Friston and Ping Ao.},
author = {Friston, Karl J. and Ao, Ping},
doi = {10.1155/2012/937860},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston, Ao{\_}2012{\_}Free energy, value, and attractors.pdf:pdf},
issn = {1748670X},
journal = {Computational and Mathematical Methods in Medicine},
title = {{Free energy, value, and attractors}},
volume = {2012},
year = {2012}
}
@misc{Stanton2018,
abstract = {Traditional exploration methods in reinforcement learning (RL) require agents to perform random actions to find rewards. But these approaches struggle on sparse-reward domains like Montezuma's Revenge where the probability that any random action sequence leads to reward is extremely low. Recent algorithms have performed well on such tasks by encouraging agents to visit new states or perform new actions in relation to all prior training episodes (which we call across-training novelty). But such algorithms do not consider whether an agent exhibits intra-life novelty: doing something new within the current episode, regardless of whether those behaviors have been performed in previous episodes. We hypothesize that across-training novelty might discourage agents from revisiting initially non-rewarding states that could become important stepping stones later in training—a problem remedied by encouraging intra-life novelty. We introduce Curiosity Search for deep reinforcement learning, or Deep Curiosity Search (DeepCS), which encourages intra-life exploration by rewarding agents for visiting as many different states as possible within each episode, and show that DeepCS matches the performance of current state-of-the-art methods on Montezuma's Revenge. We further show that DeepCS improves exploration on Amidar, Freeway, Gravitar, and Tutankham (many of which are hard exploration games). Surprisingly, DeepCS also doubles A2C performance on Seaquest, a game we would not have expected to benefit from intra-life exploration because the arena is small and already easily navigated by naive exploration techniques. In one run, DeepCS achieves a maximum training score of 80,000 points on Seaquest—higher than any methods other than Ape-X. The strong performance of DeepCS on these sparse- and dense-reward tasks suggests that encouraging intra-life novelty is an interesting, new approach for improving performance in Deep RL and motivates further research into hybridizing across-training and intra-life exploration methods.},
archivePrefix = {arXiv},
arxivId = {1806.00553},
author = {Stanton, Christopher and Clune, Jeff},
booktitle = {arXiv},
eprint = {1806.00553},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Stanton, Clune{\_}2018{\_}Deep curiosity search Intra-life exploration can improve performance on challenging deep reinforcement learning prob.pdf:pdf},
title = {{Deep curiosity search: Intra-life exploration can improve performance on challenging deep reinforcement learning problems}},
year = {2018}
}
@article{Calvo2020,
abstract = {Hypotheses The drive to survive is a biological universal. Intelligent behaviour is usually recognized when individual organisms including plants, in the face of fiercely competitive or adverse, real-world circumstances, change their behaviour to improve their probability of survival. Scope This article explains the potential relationship of intelligence to adaptability and emphasizes the need to recognize individual variation in intelligence showing it to be goal directed and thus being purposeful. Intelligent behaviour in single cells and microbes is frequently reported. Individual variation might be underpinned by a novel learning mechanism, described here in detail. The requirements for real-world circumstances are outlined, and the relationship to organic selection is indicated together with niche construction as a good example of intentional behaviour that should improve survival. Adaptability is important in crop development but the term may be complex incorporating numerous behavioural traits some of which are indicated. Conclusion There is real biological benefit to regarding plants as intelligent both from the fundamental issue of understanding plant life but also from providing a direction for fundamental future research and in crop breeding.},
author = {Calvo, Paco and Gagliano, Monica and Souza, Gustavo M. and Trewavas, Anthony},
doi = {10.1093/aob/mcz155},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Calvo et al.{\_}2020{\_}Plants are intelligent, here's how.pdf:pdf},
issn = {10958290},
journal = {Annals of Botany},
keywords = {Adaptability,Intelligence,Learning,Real-world circumstances,Selection,Systems biology},
number = {1},
pages = {11--28},
pmid = {31563953},
title = {{Plants are intelligent, here's how}},
volume = {125},
year = {2020}
}
@article{Lainscsek2019,
abstract = {Most natural systems, including the brain, are highly nonlinear and complex, and determining information flow among the components that make up these dynamic systems is challenging. One such example is identifying abnormal causal interactions among different brain areas that give rise to epileptic activities. Here, we introduce cross-dynamical delay differential analysis, an extension of delay differential analysis, as a tool to establish causal relationships from time series signals. Our method can infer causality from short time series signals as well as in the presence of noise. Furthermore, we can determine the onset of generalized synchronization directly from time series data, without having to consult the underlying equations. We first validate our method on simulated datasets from coupled dynamical systems and apply the method to intracranial electroencephalography data obtained from epilepsy patients to better characterize large-scale information flow during epilepsy.},
author = {Lainscsek, Claudia and Gonzalez, Christopher E. and Sampson, Aaron L. and Cash, Sydney S. and Sejnowski, Terrence J.},
doi = {10.1063/1.5126125},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Lainscsek et al.{\_}2019{\_}Causality detection in cortical seizure dynamics using cross-dynamical delay differential analysis.pdf:pdf},
issn = {1054-1500},
journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
month = {oct},
number = {10},
pages = {101103},
pmid = {31675829},
publisher = {AIP Publishing LLC},
title = {{Causality detection in cortical seizure dynamics using cross-dynamical delay differential analysis}},
url = {http://aip.scitation.org/doi/10.1063/1.5126125},
volume = {29},
year = {2019}
}
@book{Durstewitz2017,
abstract = {The computational and cognitive properties of neural systems are often thought to be implemented in terms of their (stochastic) network dynamics. Hence, recovering the system dynamics from experimentally observed neuronal time series, like multiple single-unit recordings or neuroimaging data, is an important step toward understanding its computations. Ideally, one would not only seek a (lower-dimensional) state space representation of the dynamics, but would wish to have access to its statistical properties and their generative equations for in-depth analysis. Recurrent neural networks (RNNs) are a computationally powerful and dynamically universal formal framework which has been extensively studied from both the computational and the dynamical systems perspective. Here we develop a semi-analytical maximum-likelihood estimation scheme for piecewise-linear RNNs (PLRNNs) within the statistical framework of state space models, which accounts for noise in both the underlying latent dynamics and the observation process. The Expectation-Maximization algorithm is used to infer the latent state distribution, through a global Laplace approximation, and the PLRNN parameters iteratively. After validating the procedure on toy examples, and using inference through particle filters for comparison, the approach is applied to multiple single-unit recordings from the rodent anterior cingulate cortex (ACC) obtained during performance of a classical working memory task, delayed alternation. Models estimated from kernel-smoothed spike time data were able to capture the essential computational dynamics underlying task performance, including stimulus-selective delay activity. The estimated models were rarely multi-stable, however, but rather were tuned to exhibit slow dynamics in the vicinity of a bifurcation point. In summary, the present work advances a semi-analytical (thus reasonably fast) maximum-likelihood estimation framework for PLRNNs that may enable to recover relevant aspects of the nonlinear dynamics underlying observed neuronal time series, and directly link these to computational properties.},
author = {Durstewitz, Daniel},
booktitle = {PLoS Computational Biology},
doi = {10.1371/journal.pcbi.1005542},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Durstewitz{\_}2017{\_}A state space approach for piecewise-linear recurrent neural networks for identifying computational dynamics from neural.pdf:pdf},
isbn = {1111111111},
issn = {15537358},
number = {6},
pages = {1--33},
pmid = {28574992},
title = {{A state space approach for piecewise-linear recurrent neural networks for identifying computational dynamics from neural measurements}},
volume = {13},
year = {2017}
}
@article{Pearl1995,
abstract = {The primary aim of this paper is to show how graphical models can be used as a mathematical language for integrating statistical and subject-matter information. In particular, the paper develops a principled, nonparametric framework for causal inference, in which diagrams are queried to determine if the assumptions available are sufficient for identifying causal effects from nonexperimental data. If so the diagrams can be queried to produce mathematical expressions for causal effects in terms of observed distributions; otherwise, the diagrams can be queried to suggest additional observations or auxiliary experiments from which the desired inferences can be obtained. {\textcopyright} 1995 Biometrika Trust.},
author = {Pearl, Judea},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Pearl{\_}1995{\_}Causal diagrams for empirical research.pdf:pdf},
issn = {00063444},
journal = {Biometrika},
keywords = {Causal inference,Graph model,Structural equations,Treatment effect},
number = {4},
pages = {669--688},
title = {{Causal diagrams for empirical research}},
url = {https://www.jstor.org/stable/2337329?origin=crossref},
volume = {82},
year = {1995}
}
@article{Friston2019,
abstract = {This monograph attempts a theory of every 'thing' that can be distinguished from other things in a statistical sense. The ensuing statistical independencies, mediated by Markov blankets, speak to a recursive composition of ensembles (of things) at increasingly higher spatiotemporal scales. This decomposition provides a description of small things; e.g., quantum mechanics - via the Schrodinger equation, ensembles of small things - via statistical mechanics and related fluctuation theorems, through to big things - via classical mechanics. These descriptions are complemented with a Bayesian mechanics for autonomous or active things. Although this work provides a formulation of every thing, its main contribution is to examine the implications of Markov blankets for self-organisation to nonequilibrium steady-state. In brief, we recover an information geometry and accompanying free energy principle that allows one to interpret the internal states of something as representing or making inferences about its external states. The ensuing Bayesian mechanics is compatible with quantum, statistical and classical mechanics and may offer a formal description of lifelike particles.},
archivePrefix = {arXiv},
arxivId = {1906.10184},
author = {Friston, Karl J.},
eprint = {1906.10184},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston{\_}2019{\_}A free energy principle for a particular physics.pdf:pdf},
keywords = {active inference,active particles,autopoiesis,bayesian,entropy,free energy,markov blanket,nonequilibrium steady-state,random dynamical attractor,self-organisation,variational},
pages = {1--148},
title = {{A free energy principle for a particular physics}},
year = {2019}
}
@article{Postels2019,
abstract = {We present a sampling-free approach for computing the epistemic uncertainty of a neural network. Epistemic uncertainty is an important quantity for the deployment of deep neural networks in safety-critical applications, since it represents how much one can trust predictions on new data. Recently promising works were proposed using noise injection combined with Monte-Carlo sampling at inference time to estimate this quantity (e.g. Monte-Carlo dropout). Our main contribution is an approximation of the epistemic uncertainty estimated by these methods that does not require sampling, thus notably reducing the computational overhead. We apply our approach to large-scale visual tasks (ie, semantic segmentation and depth regression) to demonstrate the advantages of our method compared to sampling-based approaches in terms of quality of the uncertainty estimates as well as of computational overhead.},
archivePrefix = {arXiv},
arxivId = {1908.00598},
author = {Postels, Janis and Ferroni, Francesco and Coskun, Huseyin and Navab, Nassir and Tombari, Federico},
doi = {10.1109/ICCV.2019.00302},
eprint = {1908.00598},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Postels et al.{\_}2019{\_}Sampling-free epistemic uncertainty estimation using approximated variance propagation.pdf:pdf},
isbn = {9781728148038},
issn = {15505499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
pages = {2931--2940},
title = {{Sampling-free epistemic uncertainty estimation using approximated variance propagation}},
volume = {2019-Octob},
year = {2019}
}
@article{Chung2014,
abstract = {In this paper we compare different types of recurrent units in recurrent neural networks (RNNs). Especially, we focus on more sophisticated units that implement a gating mechanism, such as a long short-term memory (LSTM) unit and a recently proposed gated recurrent unit (GRU). We evaluate these recurrent units on the tasks of polyphonic music modeling and speech signal modeling. Our experiments revealed that these advanced recurrent units are indeed better than more traditional recurrent units such as tanh units. Also, we found GRU to be comparable to LSTM.},
archivePrefix = {arXiv},
arxivId = {1412.3555},
author = {Chung, Junyoung and Gulcehre, Caglar and Cho, KyungHyun and Bengio, Yoshua},
eprint = {1412.3555},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Chung et al.{\_}2014{\_}Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling.pdf:pdf},
month = {dec},
pages = {1--9},
title = {{Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling}},
url = {http://arxiv.org/abs/1412.3555},
year = {2014}
}
@article{ODonogue2018,
archivePrefix = {arXiv},
arxivId = {arXiv:1807.09647v2},
author = {Donoghue, Brendan O},
eprint = {arXiv:1807.09647v2},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Donoghue{\_}2018{\_}Variational Bayesian Reinforcement Learning with Regret Bounds.pdf:pdf},
journal = {ArXiv},
keywords = {1,bayesian regret,dits,exploration-exploitation,introduction and related work,learning problem,markov decision processes,multi-armed ban-,reinforcement learning,we consider the reinforcement,whereby an agent interacts,with an environment},
title = {{Variational Bayesian Reinforcement Learning with Regret Bounds}},
year = {2018}
}
@article{Krotov2019,
abstract = {It is widely believed that end-to-end training with the backpropagation algorithm is essential for learning good feature detectors in early layers of artificial neural networks, so that these detectors are useful for the task performed by the higher layers of that neural network. At the same time, the traditional form of backpropagation is biologically implausible. In the present paper we propose an unusual learning rule, which has a degree of biological plausibility and which is motivated by Hebb's idea that change of the synapse strength should be local—i.e., should depend only on the activities of the pre- and postsynaptic neurons. We design a learning algorithm that utilizes global inhibition in the hidden layer and is capable of learning early feature detectors in a completely unsupervised way. These learned lower-layer feature detectors can be used to train higher-layer weights in a usual supervised way so that the performance of the full network is comparable to the performance of standard feedforward networks trained end-to-end with a backpropagation algorithm on simple tasks.},
archivePrefix = {arXiv},
arxivId = {1806.10181},
author = {Krotov, Dmitry and Hopfield, John J.},
doi = {10.1073/pnas.1820458116},
eprint = {1806.10181},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Krotov, Hopfield{\_}2019{\_}Unsupervised learning by competing hidden units.pdf:pdf},
issn = {10916490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Backpropagation,Biological deep learning,Hebbian-like plasticity},
number = {16},
pages = {7723--7731},
pmid = {30926658},
title = {{Unsupervised learning by competing hidden units}},
volume = {116},
year = {2019}
}
@article{Friston2015,
abstract = {This paper considers communication in terms of inference about the behaviour of others (and our own behaviour). It is based on the premise that our sensations are largely generated by other agents like ourselves. This means, we are trying to infer how our sensations are caused by others, while they are trying to infer our behaviour: for example, in the dialogue between two speakers. We suggest that the infinite regress induced by modelling another agent - who is modelling you - can be finessed if you both possess the same model. In other words, the sensations caused by others and oneself are generated by the same process. This leads to a view of communication based upon a narrative that is shared by agents who are exchanging sensory signals. Crucially, this narrative transcends agency - and simply involves intermittently attending to and attenuating sensory input. Attending to sensations enables the shared narrative to predict the sensations generated by another (i.e. to listen), while attenuating sensory input enables one to articulate the narrative (i.e. to speak). This produces a reciprocal exchange of sensory signals that, formally, induces a generalised synchrony between internal (neuronal) brain states generating predictions in both agents. We develop the arguments behind this perspective, using an active (Bayesian) inference framework and offer some simulations (of birdsong) as proof of principle.},
author = {Friston, Karl J. and Frith, Christopher D.},
doi = {10.1016/j.concog.2014.12.003},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston, Frith{\_}2015{\_}A Duet for one.pdf:pdf},
issn = {10902376},
journal = {Consciousness and Cognition},
keywords = {Active inference,Attention,Bayesian,Communication,Generalised synchrony,Predictive coding,Sensory attenuation,Theory of mind},
pages = {390--405},
title = {{A Duet for one}},
volume = {36},
year = {2015}
}
@article{Dewar2008,
abstract = {Recently there has been growing interest in the use of maximum relative entropy (MaxREnt) as a tool for statistical inference in ecology. In contrast, here we propose MaxREnt as a tool for applying statistical mechanics to ecology. We use MaxREnt to explain and predict species abundance patterns in ecological communities in terms of the most probable behaviour under given environmental constraints, in the same way that statistical mechanics explains and predicts the behaviour of thermodynamic systems. We show that MaxREnt unifies a number of different ecological patterns: (i) at relatively local scales a unimodal biodiversity-productivity relationship is predicted in good agreement with published data on grassland communities, (ii) the predicted relative frequency of rare vs. abundant species is very similar to the empirical lognormal distribution, (iii) both neutral and non-neutral species abundance patterns are explained, (iv) on larger scales a monotonic biodiversity-productivity relationship is predicted in agreement with the species-energy law, (v) energetic equivalence and power law self-thinning behaviour are predicted in resource-rich communities. We identify mathematical similarities between these ecological patterns and the behaviour of thermodynamic systems, and conclude that the explanation of ecological patterns is not unique to ecology but rather reflects the generic statistical behaviour of complex systems with many degrees of freedom under very general types of environmental constraints. {\textcopyright} 2007 Elsevier Ltd. All rights reserved.},
author = {Dewar, Roderick C. and Port{\'{e}}, Annabel},
doi = {10.1016/j.jtbi.2007.12.007},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Dewar, Port{\'{e}}{\_}2008{\_}Statistical mechanics unifies different ecological patterns.pdf:pdf},
issn = {00225193},
journal = {Journal of Theoretical Biology},
keywords = {Abundance distribution,Biodiversity,Community ecology,Relative entropy},
month = {apr},
number = {3},
pages = {389--403},
pmid = {18237750},
title = {{Statistical mechanics unifies different ecological patterns}},
volume = {251},
year = {2008}
}
@article{Rao1999,
abstract = {We describe a model of visual processing in which feedback connections from a higher- to a lower-order visual cortical area carry predictions of lower-level neural activities, whereas the feedforward connections carry the residual errors between the predictions and the actual lower-level activities. When exposed to natural images, a hierarchical network of model neurons implementing such a model developed simple-cell-like receptive fields. A subset of neurons responsible for carrying the residual errors showed endstopping and other extra-classical receptive-field effects. These results suggest that rather than being exclusively feedforward phenomena, nonclassical surround effects in the visual cortex may also result from cortico-cortical feedback as a consequence of the visual system using an efficient hierarchical strategy for encoding natural images.},
author = {Rao, Rajesh P.N. and Ballard, Dana H.},
doi = {10.1038/4580},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Rao, Ballard{\_}1999{\_}Predictive coding in the visual cortex A functional interpretation of some extra-classical receptive-field effects.pdf:pdf},
issn = {10976256},
journal = {Nature Neuroscience},
number = {1},
pages = {79--87},
pmid = {10195184},
title = {{Predictive coding in the visual cortex: A functional interpretation of some extra-classical receptive-field effects}},
volume = {2},
year = {1999}
}
@article{Wolpert1996,
abstract = {Based on theoretical and computational studies it has been suggested that the central nervous system (CNS) internally simulates the behaviour of the motor system in planning, control and learning. Such an internal "forward" model is a representation of the motor system that uses the current state of the motor system and motor command to predict the next state. We will outline the uses of such internal models for solving several fundamental computational problems in motor control and then review the evidence for their existence and use by the CNS. Finally we speculate how the location of an internal model within the CNS may be identified. Copyright 1996 Elsevier Science Ltd.},
author = {Wolpert, D M and Miall, R C},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Wolpert, Miall{\_}1996{\_}Forward Models for Physiological Motor Control.pdf:pdf},
issn = {1879-2782},
journal = {Neural Networks},
keywords = {control,m1,motor},
number = {8},
pages = {1265--1279},
pmid = {12662535},
title = {{Forward Models for Physiological Motor Control.}},
volume = {9},
year = {1996}
}
@book{Schroeder2000,
abstract = {Derivation of the second law of thermodynamics from Einstein solids},
author = {Schroeder, Daniel V.},
isbn = {0201380277},
pages = {53--84},
publisher = {Robin J. Heyden},
title = {{An Introduction to Thermal Physics}},
year = {2000}
}
@article{Zuo2005,
abstract = {Synapse formation and elimination occur throughout life, but the magnitude of such changes at distinct developmental stages remains unclear. Using transgenic mice overexpressing yellow fluorescent protein and transcranial two-photon microscopy, we repeatedly imaged dendritic spines on the apical dendrites of layer 5 pyramidal neurons. In young adolescent mice (1-month-old), 13{\%}-20{\%} of spines were eliminated and 5{\%}-8{\%} formed over 2 weeks in barrel, motor, and frontal cortices, indicating a cortical-wide spine loss during this developmental period. As animals mature, there is also a substantial loss of dendritic filopodia involved in spinogenesis. In adult mice (4-6 months old), 3{\%}-5{\%} of spines were eliminated and formed over 2 weeks in various cortical regions. Over 18 months, only 26{\%} of spines were eliminated and 19{\%} formed in adult barrel cortex. Thus, after a concurrent loss of spines and spine precursors in diverse regions of young adolescent cortex, spines become stable and a majority of them can last throughout life. Copyright {\textcopyright}2005 by Elsevier Inc.},
author = {Zuo, Yi and Lin, Aerie and Chang, Paul and Gan, Wen Biao},
doi = {10.1016/j.neuron.2005.04.001},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Zuo et al.{\_}2005{\_}Development of long-term dendritic spine stability in diverse regions of cerebral cortex.pdf:pdf},
issn = {08966273},
journal = {Neuron},
number = {2},
pages = {181--189},
title = {{Development of long-term dendritic spine stability in diverse regions of cerebral cortex}},
volume = {46},
year = {2005}
}
@article{LoaizaGanem2019,
abstract = {Variational autoencoders (VAE) have quickly become a central tool in machine learning, applicable to a broad range of data types and latent variable models. By far the most common first step, taken by seminal papers and by core software libraries alike, is to model MNIST data using a deep network parameterizing a Bernoulli likelihood. This practice contains what appears to be and what is often set aside as a minor inconvenience: the pixel data is [0, 1] valued, not {\{}0, 1{\}} as supported by the Bernoulli likelihood. Here we show that, far from being a triviality or nuisance that is convenient to ignore, this error has profound importance to VAE, both qualitative and quantitative. We introduce and fully characterize a new [0, 1]-supported, single parameter distribution: the continuous Bernoulli, which patches this pervasive bug in VAE. This distribution is not nitpicking; it produces meaningful performance improvements across a range of metrics and datasets, including sharper image samples, and suggests a broader class of performant VAE.1,.},
author = {Loaiza-Ganem, Gabriel and Cunningham, John P.},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Loaiza-Ganem, Cunningham{\_}2019{\_}The continuous bernoulli Fixing a pervasive error in variational autoencoders.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
number = {NeurIPS},
pages = {1--11},
title = {{The continuous bernoulli: Fixing a pervasive error in variational autoencoders}},
volume = {32},
year = {2019}
}
@article{Hoffman2019,
author = {Hoffman, Donald},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop//Hoffman{\_}2019{\_}Reality The Greatest Illusion of All How Evolution Has Blinded Us to the Truth about the World.pdf:pdf},
journal = {New Scientist Weekly},
pages = {34--37},
publisher = {New scientist},
title = {{Reality: The Greatest Illusion of All: How Evolution Has Blinded Us to the Truth about the World}},
url = {https://books.google.nl/books?id=ycKyzQEACAAJ},
year = {2019}
}
@article{Friston2010a,
abstract = {We have previously tried to explain perceptual inference and learning under a free-energy principle that pursues Helmholtz's agenda to understand the brain in terms of energy minimization. It is fairly easy to show that making inferences about the causes of sensory data can be cast as the minimization of a free-energy bound on the likelihood of sensory inputs, given an internal model of how they were caused. In this article, we consider what would happen if the data themselves were sampled to minimize this bound. It transpires that the ensuing active sampling or inference is mandated by ergodic arguments based on the very existence of adaptive agents. Furthermore, it accounts for many aspects of motor behavior; from retinal stabilization to goal-seeking. In particular, it suggests that motor control can be understood as fulfilling prior expectations about proprioceptive sensations. This formulation can explain why adaptive behavior emerges in biological agents and suggests a simple alternative to optimal control theory. We illustrate these points using simulations of oculomotor control and then apply to same principles to cued and goal-directed movements. In short, the free-energy formulation may provide an alternative perspective on the motor control that places it in an intimate relationship with perception. {\textcopyright} 2010 Springer-Verlag.},
author = {Friston, Karl J. and Daunizeau, Jean and Kilner, James M. and Kiebel, Stefan J.},
doi = {10.1007/s00422-010-0364-z},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston et al.{\_}2010{\_}Action and behavior A free-energy formulation.pdf:pdf},
issn = {03401200},
journal = {Biological Cybernetics},
keywords = {Bayesian,Computational,Control,Hierarchical,Motor,Priors},
number = {3},
pages = {227--260},
pmid = {20148260},
title = {{Action and behavior: A free-energy formulation}},
volume = {102},
year = {2010}
}
@inproceedings{Millidge2020,
author = {Millidge, Beren and Tschantz, Alexander and Buckley, Christopher},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Millidge, Tschantz, Buckley{\_}2020{\_}Predictive Coding Approximates Backprop along Arbitrary Computation Graphs.pdf:pdf},
isbn = {9781633212817},
title = {{Predictive Coding Approximates Backprop along Arbitrary Computation Graphs}},
url = {https://arxiv.org/abs/2006.04182},
year = {2020}
}
@article{Harrison2005,
abstract = {Cortical activity is the product of interactions among neuronal populations. Macroscopic electrophysiological phenomena are generated by these interactions. In principle, the mechanisms of these interactions afford constraints on biologically plausible models of electrophysiological responses. In other words, the macroscopic features of cortical activity can be modelled in terms of the microscopic behaviour of neurons. An evoked response potential (ERP) is the mean electrical potential measured from an electrode on the scalp, in response to some event. The purpose of this paper is to outline a population density approach to modelling ERPs. We propose a biologically plausible model of neuronal activity that enables the estimation of physiologically meaningful parameters from electrophysiological data. The model encompasses four basic characteristics of neuronal activity and organization: (i) neurons are dynamic units, (ii) driven by stochastic forces, (iii) organized into populations with similar biophysical properties and response characteristics and (iv) multiple populations interact to form functional networks. This leads to a formulation of population dynamics in terms of the Fokker-Planck equation. The solution of this equation is the temporal evolution of a probability density over state-space, representing the distribution of an ensemble of trajectories. Each trajectory corresponds to the changing state of a neuron. Measurements can be modelled by taking expectations over this density, e.g. mean membrane potential, firing rate or energy consumption per neuron. The key motivation behind our approach is that ERPs represent an average response over many neurons. This means it is sufficient to model the probability density over neurons, because this implicitly models their average state. Although the dynamics of each neuron can be highly stochastic, the dynamics of the density is not. This means we can use Bayesian inference and estimation tools that have already been established for deterministic systems. The potential importance of modelling density dynamics (as opposed to more conventional neural mass models) is that they include interactions among the moments of neuronal states (e.g. the mean depolarization may depend on the variance of synaptic currents through nonlinear mechanisms). Here, we formulate a population model, based on biologically informed model-neurons with spike-rate adaptation and synaptic dynamics. Neuronal sub-populations are coupled to form an observation model, with the aim of estimating and making inferences about coupling among sub-populations using real data. We approximate the time-dependent solution of the system using a bi-orthogonal set and first-order perturbation expansion. For didactic purposes, the model is developed first in the context of deterministic input, and then extended to include stochastic effects. The approach is demonstrated using synthetic data, where model parameters are identified using a Bayesian estimation scheme we have described previously. {\textcopyright} 2005 The Royal Society.},
author = {Harrison, Lee M. and David, Olivier and Friston, Karl J.},
doi = {10.1098/rstb.2005.1648},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Harrison, David, Friston{\_}2005{\_}Stochastic models of neuronal dynamics.pdf:pdf},
issn = {09628436},
journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
keywords = {Evoked response potentials,Fokker-Planck equation,Generative models,Population dynamics,Synthetic data,System identification},
number = {1457},
pages = {1075--1091},
title = {{Stochastic models of neuronal dynamics}},
volume = {360},
year = {2005}
}
@article{FitzGerald2015a,
abstract = {Deciding how much evidence to accumulate before making a decision is a problem we and other animals often face, but one that is not completely understood. This issue is particularly important because a tendency to sample less information (often known as reflection impulsivity) is a feature in several psychopathologies, such as psychosis. A formal understanding of information sampling may therefore clarify the computational anatomy of psychopathology. In this theoretical letter, we consider evidence accumulation in terms of active (Bayesian) inference using a generic model of Markov decision processes. Here, agents are equipped with beliefs about their own behavior—in this case, that they will make informed decisions. Normative decision making is then modeled using variational Bayes to minimize surprise about choice outcomes. Under this scheme, different facets of belief updating map naturally onto the functional anatomy of the brain (at least at a heuristic level). Of particular interest is the key role played by the expected precision of beliefs about control, which we have previously suggested may be encoded by dopaminergic neurons in the midbrain. We show that manipulating expected precision strongly affects how much information an agent characteristically samples, and thus provides a possible link between impulsivity and dopaminergic dysfunction. Our study therefore represents a step toward understanding evidence accumulation in terms of neurobiologically plausible Bayesian inference and may cast light on why this process is disordered in psychopathology.},
archivePrefix = {arXiv},
arxivId = {1803.01446},
author = {FitzGerald, Thomas H. B. and Schwartenbeck, Philipp and Moutoussis, Michael and Dolan, Raymond J. and Friston, Karl},
doi = {10.1162/NECO_a_00699},
eprint = {1803.01446},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/FitzGerald et al.{\_}2015{\_}Active Inference, Evidence Accumulation, and the Urn Task.pdf:pdf},
issn = {0899-7667},
journal = {Neural Computation},
keywords = {active inference,bayesian,bounded rationality,dopamine,evidence accumulation,free energy,inference,schizophrenia,utility theory},
month = {feb},
number = {2},
pages = {306--328},
title = {{Active Inference, Evidence Accumulation, and the Urn Task}},
url = {http://arxiv.org/abs/1803.01446 https://www.mitpressjournals.org/doi/abs/10.1162/NECO{\_}a{\_}00699},
volume = {27},
year = {2015}
}
@article{Hopfield2000,
abstract = {Recognition of complex temporal sequences is a general sensory problem that requires integration of information over time. We describe a very simple 'organism' that performs this task, exemplified here by recognition of spoken monosyllables. The network's computation can be understood through the application of simple but generally unexploited principles describing neural activity. The organism is a network of very simple neurons and synapses; the experiments are simulations. The network's recognition capabilities are robust to variations across speakers, simple masking noises, and large variations in system parameters. The network principles underlying recognition of short temporal sequences are applied here to speech, but similar ideas can be applied to aspects of vision, touch, and olfaction. In this article, we describe only properties of the system that could be measured if it were a real biological organism. We delay publication of the principles behind the network's operation as an intellectual challenge: The essential principles of operation can be deduced based on the experimental results presented here alone. An interactive web site (http://neuron.princeton.edu/-moment) is available to allow readers to design and carry out their own experiments on the organism.},
author = {Hopfield, John J. and Brody, Carlos D.},
doi = {10.1073/pnas.250483697},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Hopfield, Brody{\_}2000{\_}What is a moment 'Cortical' sensory integration over a brief interval.pdf:pdf},
issn = {00278424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
number = {25},
pages = {13919--13924},
title = {{What is a moment? 'Cortical' sensory integration over a brief interval}},
volume = {97},
year = {2000}
}
@article{Stephan2010,
abstract = {Dynamic causal modeling (DCM) is a generic Bayesian framework for inferring hidden neuronal states from measurements of brain activity. It provides posterior estimates of neurobiologically interpretable quantities such as the effective strength of synaptic connections among neuronal populations and their context-dependent modulation. DCM is increasingly used in the analysis of a wide range of neuroimaging and electrophysiological data. Given the relative complexity of DCM, compared to conventional analysis techniques, a good knowledge of its theoretical foundations is needed to avoid pitfalls in its application and interpretation of results. By providing good practice recommendations for DCM, in the form of ten simple rules, we hope that this article serves as a helpful tutorial for the growing community of DCM users. {\textcopyright} 2009 Elsevier Inc. All rights reserved.},
author = {Stephan, Klaas E. and Penny, W. D. and Moran, R. J. and den Ouden, Hanneke E.M. and Daunizeau, Jean and Friston, Karl J.},
doi = {10.1016/j.neuroimage.2009.11.015},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Stephan et al.{\_}2010{\_}Ten simple rules for dynamic causal modeling.pdf:pdf},
issn = {10538119},
journal = {NeuroImage},
keywords = {BMS,Bayes factor,Bayesian model selection,DCM,EEG,Effective connectivity,MEG,Model comparison,Model evidence,Nonlinear dynamics,Synaptic plasticity,fMRI},
number = {4},
pages = {3099--3109},
pmid = {19914382},
publisher = {Elsevier Inc.},
title = {{Ten simple rules for dynamic causal modeling}},
url = {http://dx.doi.org/10.1016/j.neuroimage.2009.11.015},
volume = {49},
year = {2010}
}
@article{Hobson2016,
abstract = {This paper presents a theoretical review of rapid eye movement sleep with a special focus on pontine-geniculate-occipital waves and what they might tell us about the functional anatomy of sleep and consciousness. In particular, we review established ideas about the nature and purpose of sleep in terms of protoconsciousness and free energy minimization. By combining these theoretical perspectives, we discover answers to some fundamental questions about sleep: for example, why is homeothermy suspended during sleep? Why is sleep necessary? Why are we not surprised by our dreams? What is the role of synaptic regression in sleep? The imperatives for sleep that emerge also allow us to speculate about the functional role of PGO waves and make some empirical predictions that can, in principle, be tested using recent advances in the modeling of electrophysiological data.},
author = {Hobson, J. A. and Friston, Karl J.},
doi = {10.1016/B978-0-12-809324-5.21972-X},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Hobson, Friston{\_}2016{\_}Waking and dreaming consciousness Neurobiological and functional considerations.pdf:pdf},
isbn = {9780128093245},
journal = {The Curated Reference Collection in Neuroscience and Biobehavioral Psychology},
keywords = {Consciousness,Free energy,Neuromodulation,Neuronal coding,Pontine-geniculate-occipital waves,Prediction,Rapid eye movement sleep,Sleep},
pages = {237--256},
title = {{Waking and dreaming consciousness: Neurobiological and functional considerations}},
year = {2016}
}
@article{Palacios2017,
abstract = {Biological self-organisation is a process of spontaneous pattern formation; namely the emergence of coherent and stable systemic configurations that distinguish themselves from their environment. This process can occur at various spatial scales: from the microscopic (giving rise to cells) to the macroscopic (the emergence of organisms). Self-organisation at each level is essential to account for the hierarchical organisation of living organisms (organelles within cells, within tissues, within organs, etc.). In this paper, we pursue the idea that Markov blankets - statistical boundaries separating states that are external to a system from its internal states - emerge at every possible level of the description of the (living) system. Through simulations, we show that the concept of a Markov blanket is fundamental in defining biological systems and underwrites the nature and form of interactions between successive levels of hierarchical structure. We demonstrate the validity of our argument using simulations, based on the normative principle of variational free energy minimisation. Specifically, we adopt a top-down approach to provide a proof of concept for the claim that the self-organisation of Markov blankets (and blankets of blankets) underwrites the self-evidencing, autopoietic behaviour of living systems.},
author = {Palacios, Ensor Rafael and Razi, Adeel and Parr, Thomas and Kirchhoff, Michael and Friston, Karl},
doi = {10.1101/227181},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Palacios et al.{\_}2017{\_}Biological self-organisation and Markov blankets.pdf:pdf},
journal = {bioRxiv},
keywords = {Active inference,Dynamical systems,Free energy,Markov blanket,Self-organisation},
pages = {1--21},
title = {{Biological self-organisation and Markov blankets}},
year = {2017}
}
@book{Stratonovich1964,
annote = {doi: 10.1080/00401706.1964.10490213},
author = {Stratonovich, R L},
booktitle = {Technometrics},
isbn = {9780677007908},
publisher = {Gordon and Breach},
title = {{Topics in the Theory of Random Noise}},
volume = {1},
year = {1964}
}
@article{Friston2012d,
abstract = {This paper describes a free energy principle that tries to explain the ability of biological systems to resist a natural tendency to disorder. It appeals to circular causality of the sort found in synergetic formulations of self-organization (e.g., the slaving principle) and models of coupled dynamical systems, using nonlinear Fokker Planck equations. Here, circular causality is induced by separating the states of a random dynamical system into external and internal states, where external states are subject to random fluctuations and internal states are not. This reduces the problem to finding some (deterministic) dynamics of the internal states that ensure the system visits a limited number of external states; in other words, the measure of its (random) attracting set, or the Shannon entropy of the external states is small. We motivate a solution using a principle of least action based on variational free energy (from statistical physics) and establish the conditions under which it is formally equivalent to the information bottleneck method. This approach has proved useful in understanding the functional architecture of the brain. The generality of variational free energy minimisation and corresponding information theoretic formulations may speak to interesting applications beyond the neurosciences; e.g., in molecular or evolutionary biology. {\textcopyright} 2012 by the authors.},
author = {Friston, Karl J.},
doi = {10.3390/e14112100},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston{\_}2012{\_}A free energy principle for biological systems.pdf:pdf},
issn = {10994300},
journal = {Entropy},
keywords = {Bayesian,Ergodicity,Free energy,Random dynamical system,Self-organization,Surprise},
number = {11},
pages = {2100--2121},
title = {{A free energy principle for biological systems}},
volume = {14},
year = {2012}
}
@article{Hopfield1994,
author = {Hopfield, John J.},
doi = {10.1006/jtbi.1994.1211},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Hopfield{\_}1994{\_}Physics, Computation, and Why Biology Looks so Different.pdf:pdf},
issn = {00225193},
journal = {Journal of Theoretical Biology},
month = {jul},
number = {1},
pages = {53--60},
title = {{Physics, Computation, and Why Biology Looks so Different}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0022519384712112},
volume = {171},
year = {1994}
}
@inproceedings{Thanh2016,
abstract = {This paper concerns online algorithms for online binary linear classification (OBLC) problems in Machine learning. In a sense of “online” classification, an instance sequence is given step by step and on each round, these problems consist in finding a linear classifier for predicting to which label a new instance belongs. In OBCL, the quality of predictions is assessed by a loss function, specifically 0–1 loss function. In fact, this loss function is nonconvex, nonsmooth and thus, such problems become intractable. In literature, Perceptron is a well-known online classification algorithm, in which one substitutes a surrogate convex loss function for the 0–1 loss function. In this paper, we investigate an efficient DC loss function which is a suitable approximation of the usual 0–1 loss function. Basing on Online DC (Difference of Convex functions) programming and Online DCA (DC Algorithms) [10], we develop an online classification algorithm. Numerical experiments on several test problems show the efficiency of our proposed algorithm with respect to Perceptron.},
author = {Thanh, Ho Vinh and An, Le Thi Hoai and Chien, Bui Dinh},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-662-49390-8_64},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop//Thanh, An, Chien{\_}2016{\_}Maximum Entropy Inverse Reinforcement Learning.pdf:pdf},
isbn = {9783662493892},
issn = {16113349},
keywords = {DC programming,DCA,Online DC optimization,Online DCA,Online binary classification,Perceptron},
pages = {661--670},
title = {{Maximum Entropy Inverse Reinforcement Learning}},
volume = {9622},
year = {2016}
}
@article{Ramstead2020,
abstract = {The aim of this paper is to leverage the free-energy principle and its corollary process theory, active inference, to develop a generic, generalizable model of the representational capacities of living creatures; that is, a theory of phenotypic representation. Given their ubiquity, we are concerned with distributed forms of representation (e.g., population codes), whereby patterns of ensemble activity in living tissue come to represent the causes of sensory input or data. The active inference framework rests on the Markov blanket formalism, which allows us to partition systems of interest, such as biological systems, into internal states, external states, and the blanket (active and sensory) states that render internal and external states conditionally independent of each other. In this framework, the representational capacity of living creatures emerges as a consequence of their Markovian structure and nonequilibrium dynamics, which together entail a dual-aspect information geometry. This entails a modest representational capacity: internal states have an intrinsic information geometry that describes their trajectory over time in state space, as well as an extrinsic information geometry that allows internal states to encode (the parameters of) probabilistic beliefs about (fictive) external states. Building on this, we describe here how, in an automatic and emergent manner, information about stimuli can come to be encoded by groups of neurons bound by a Markov blanket; what is known as the neuronal packet hypothesis. As a concrete demonstration of this type of emergent representation, we present numerical simulations showing that self-organizing ensembles of active inference agents sharing the right kind of probabilistic generative model are able to encode recoverable information about a stimulus array.},
archivePrefix = {arXiv},
arxivId = {2008.03238},
author = {Ramstead, Maxwell J.D. and Hesp, Casper and Tschantz, Alec and Smith, Ryan and Constant, Axel and Friston, Karl},
doi = {10.1016/j.neubiorev.2020.11.024},
eprint = {2008.03238},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Ramstead et al.{\_}2020{\_}Neural and phenotypic representation under the free-energy principle.pdf:pdf},
issn = {01497634},
journal = {arXiv},
keywords = {Neural representation,Neuronal packet hypothesis,P,neural representation,neuronal packet hypothesis,phenotypic representation},
number = {August 2020},
pages = {109--122},
pmid = {33271162},
publisher = {Elsevier Ltd},
title = {{Neural and phenotypic representation under the free-energy principle}},
url = {https://doi.org/10.1016/j.neubiorev.2020.11.024},
volume = {120},
year = {2020}
}
@article{Mackay1956,
abstract = {The wrong approach. I suppose that the most superficial and unconvincing excuse for agreeing to discuss the behaviour of any artificial mechanism before a gathering of psychologists might run somewhat as follows: Experimental psychology has lately come to concern itself more and more with the human being as a ‘black box', having certain characteristic ways of receiving and reacting to information. Perhaps not altogether accidentally, the merchant of automata has discovered that in his stock list there are several artificially contrived black boxes which in principle can be made to receive and react to information in the same characteristic ways. So, he might argue, his artificial black boxes are surely quite as proper subjects of the psychologist's attention as the human ones.},
annote = {From Duplicate 1 (Towards an Information-Flow Model of Human Behaviour - MACKAY, DONALD M.)

Qualitatively describes a young version of the idea of predictive coding

Tags: [MOD][KLT][PCO][EGM]},
author = {Mackay, Donald M.},
doi = {10.1111/j.2044-8295.1956.tb00559.x},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Mackay{\_}1956{\_}Towards an Information-Flow Model of Human Behaviour(2).pdf:pdf;:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Mackay{\_}1956{\_}Towards an Information-Flow Model of Human Behaviour.pdf:pdf},
isbn = {9781351487214},
issn = {00071269},
journal = {British Journal of Psychology},
month = {feb},
number = {1},
pages = {30--43},
title = {{Towards an Information-Flow Model of Human Behaviour}},
url = {http://doi.wiley.com/10.1111/j.2044-8295.1956.tb00559.x},
volume = {47},
year = {1956}
}
@article{Lillicrap2020,
abstract = {During learning, the brain modifies synapses to improve behaviour. In the cortex, synapses are embedded within multilayered networks, making it difficult to determine the effect of an individual synaptic modification on the behaviour of the system. The backpropagation algorithm solves this problem in deep artificial neural networks, but historically it has been viewed as biologically problematic. Nonetheless, recent developments in neuroscience and the successes of artificial neural networks have reinvigorated interest in whether backpropagation offers insights for understanding learning in the cortex. The backpropagation algorithm learns quickly by computing synaptic updates using feedback connections to deliver error signals. Although feedback connections are ubiquitous in the cortex, it is difficult to see how they could deliver the error signals required by strict formulations of backpropagation. Here we build on past and recent developments to argue that feedback connections may instead induce neural activities whose differences can be used to locally approximate these signals and hence drive effective learning in deep networks in the brain.},
annote = {This 2020 paper is still a strong supporter that backpropagation carries error information, instead of forward-propagation.

Tags: [SPC][CCP][BKC][FBC][RFU][BKB][SPS][ANR][WTP][EDF][FDA][BIN][BDM][DLE]},
author = {Lillicrap, Timothy P. and Santoro, Adam and Marris, Luke and Akerman, Colin J. and Hinton, Geoffrey},
doi = {10.1038/s41583-020-0277-3},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Lillicrap et al.{\_}2020{\_}Backpropagation and the brain.pdf:pdf},
issn = {14710048},
journal = {Nature Reviews Neuroscience},
number = {6},
pages = {335--346},
pmid = {32303713},
publisher = {Springer US},
title = {{Backpropagation and the brain}},
url = {http://dx.doi.org/10.1038/s41583-020-0277-3},
volume = {21},
year = {2020}
}
@incollection{Barto2004,
abstract = {This chapter focuses on presenting some key concepts of machine learning, approximate dynamic programming, and the relationships between them. Discussion and comparisons are made based on various aspects of the two fields such as training information, behavioral variety, problem conversion, applicable tasks, and so forth. This chapter mentions many real-world examples to illustrate some of the important distinctions being made. The primary focus of this chapter is a discussion of the concepts and strategies of machine learning, not necessarily algorithmic details. This chapter provides high-level perspective on machine learning and approximate dynamic programming.},
author = {Barto, Andrew G. and Dietterich, Thomas G.},
booktitle = {Handbook of Learning and Approximate Dynamic Programming},
doi = {10.1109/9780470544785.ch2},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Barto, Dietterich{\_}2004{\_}Reinforcement Learning and Its Relationship to Supervised Learning.pdf:pdf},
isbn = {9780470544785},
keywords = {Algorithm design and analysis,Learning,Loss measurement,Machine learning,Supervised learning,Training},
pages = {47--63},
publisher = {IEEE},
title = {{Reinforcement Learning and Its Relationship to Supervised Learning}},
url = {http://ieeexplore.ieee.org/search/srchabstract.jsp?arnumber=5273620},
year = {2004}
}
@article{Brown2013,
abstract = {Active inference provides a simple and neurobiologically plausible account of how action and perception are coupled in producing (Bayes) optimal behaviour. This can be seen most easily as minimising prediction error: we can either change our predictions to explain sensory input through perception. Alternatively, we can actively change sensory input to fulfil our predictions. In active inference, this action is mediated by classical reflex arcs that minimise proprioceptive prediction error created by descending proprioceptive predictions. However, this creates a conflict between action and perception; in that, self-generated movements require predictions to override the sensory evidence that one is not actually moving. However, ignoring sensory evidence means that externally generated sensations will not be perceived. Conversely, attending to (proprioceptive and somatosensory) sensations enables the detection of externally generated events but precludes generation of actions. This conflict can be resolved by attenuating the precision of sensory evidence during movement or, equivalently, attending away from the consequences of self-made acts. We propose that this Bayes optimal withdrawal of precise sensory evidence during movement is the cause of psychophysical sensory attenuation. Furthermore, it explains the force-matching illusion and reproduces empirical results almost exactly. Finally, if attenuation is removed, the force-matching illusion disappears and false (delusional) inferences about agency emerge. This is important, given the negative correlation between sensory attenuation and delusional beliefs in normal subjects - and the reduction in the magnitude of the illusion in schizophrenia. Active inference therefore links the neuromodulatory optimisation of precision to sensory attenuation and illusory phenomena during the attribution of agency in normal subjects. It also provides a functional account of deficits in syndromes characterised by false inference and impaired movement - like schizophrenia and Parkinsonism - syndromes that implicate abnormal modulatory neurotransmission. {\textcopyright} 2013 The Author(s).},
author = {Brown, Harriet and Adams, Rick A. and Parees, Isabel and Edwards, Mark and Friston, Karl J.},
doi = {10.1007/s10339-013-0571-3},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Brown et al.{\_}2013{\_}Active inference, sensory attenuation and illusions.pdf:pdf},
isbn = {1033901305713},
issn = {16124782},
journal = {Cognitive Processing},
keywords = {Active inference,Attention,Free energy,Illusion,Schizophrenia,Sensory attenuation},
number = {4},
pages = {411--427},
pmid = {23744445},
title = {{Active inference, sensory attenuation and illusions}},
volume = {14},
year = {2013}
}
@article{Barto2003,
author = {Barto, Andrew and Mahadevan, Sridhar},
doi = {10.1023/A:1025696116075},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Barto, Mahadevan{\_}2002{\_}Recent Advances in Hierarchical Reinforcement Learning.pdf:pdf},
journal = {Discrete Event Dynamic Systems: Theory and Applications},
title = {{Recent Advances in Hierarchical Reinforcement Learning}},
volume = {13},
year = {2002}
}
@article{Kiebel2011a,
abstract = {In this paper, we pursue recent observations that, through selective dendritic filtering, single neurons respond to specific sequences of presynaptic inputs. We try to provide a principled and mechanistic account of this selectivity by applying a recent free-energy principle to a dendrite that is immersed in its neuropil or environment. We assume that neurons self-organize to minimize a variational free-energy bound on the self-information or surprise of presynaptic inputs that are sampled. We model this as a selective pruning of dendritic spines that are expressed on a dendritic branch. This pruning occurs when post-synaptic gain falls below a threshold. Crucially, postsynaptic gain is itself optimized with respect to free energy. Pruning suppresses free energy as the dendrite selects presynaptic signals that conform to its expectations, specified by a generative model implicit in its intracellular kinetics. Not only does this provide a principled account of how neurons organize and selectively sample the myriad of potential presynaptic inputs they are exposed to, but it also connects the optimization of elemental neuronal (dendritic) processing to generic (surprise or evidence-based) schemes in statistics and machine learning, such as Bayesian model selection and automatic relevance determination. {\textcopyright} 2011 Kiebel and Friston.},
author = {Kiebel, Stefan J. and Friston, Karl J.},
doi = {10.3389/fnsys.2011.00080},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Kiebel, Friston{\_}2011{\_}Free energy and dendritic self-organization(2).pdf:pdf;:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Kiebel, Friston{\_}2011{\_}Free energy and dendritic self-organization.pdf:pdf},
issn = {16625137},
journal = {Frontiers in Systems Neuroscience},
keywords = {Bayesian inference,Dendrite,Dendritic computation,Free energy,Multi-scale,Non-linear dynamical system,Single neuron,Synaptic reconfiguration},
number = {OCTOBER 2011},
pages = {1--13},
title = {{Free energy and dendritic self-organization}},
volume = {5},
year = {2011}
}
@article{Core1995a,
author = {Hopfield, John J.},
doi = {10.1038/376033a0},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Hopfield{\_}1995{\_}Pattern recognition computation using action potential timing for stimulus representation.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
month = {jul},
number = {6535},
pages = {33--36},
title = {{Pattern recognition computation using action potential timing for stimulus representation}},
url = {http://www.nature.com/articles/376033a0},
volume = {376},
year = {1995}
}
@article{Im2017,
abstract = {Denoising autoencoders (DAE) are trained to reconstruct their clean inputs with noise injected at the input level, while variational autoencoders (VAE) are trained with noise injected in their stochastic hidden layer, with a regularizer that encourages this noise injection. In this paper, we show that injecting noise both in input and in the stochastic hidden layer can be advantageous and we propose a modified variational lower bound as an improved objective function in this setup. When input is corrupted, then the standard VAE lower bound involves marginalizing the encoder conditional distribution over the input noise, which makes the training criterion intractable. Instead, we propose a modified training criterion which corresponds to a tractable bound when input is corrupted. Experimentally, we find that the proposed denoising variational autoencoder (DVAE) yields better average log-likelihood than the VAE and the importance weighted autoencoder on the MNIST and Frey Face datasets.},
archivePrefix = {arXiv},
arxivId = {1511.06406},
author = {Im, Daniel Jiwoong and Ahn, Sungjin and Memisevic, Roland and Bengio, Yoshua},
eprint = {1511.06406},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Im et al.{\_}2017{\_}Denoising criterion for variational auto-encoding framework.pdf:pdf},
journal = {31st AAAI Conference on Artificial Intelligence, AAAI 2017},
pages = {2059--2065},
title = {{Denoising criterion for variational auto-encoding framework}},
year = {2017}
}
@article{Kraus2013,
abstract = {Recent studies have reported the existence of hippocampal "time cells," neurons that fire at particular moments during periods when behavior and location are relatively constant. However, an alternative explanation of apparent time coding is that hippocampal neurons "path integrate" to encode the distance an animal has traveled. Here, we examined hippocampal neuronal firing patterns as rats ran in place on a treadmill, thus "clamping" behavior and location, while we varied the treadmill speed to distinguish time elapsed from distance traveled. Hippocampal neurons were strongly influenced by time and distance, and less so by minor variations in location. Furthermore, the activity of different neurons reflected integration over time and distance to varying extents, with most neurons strongly influenced by both factors and some significantly influenced by only time or distance. Thus, hippocampal neuronal networks captured both the organization of time and distance in a situation where these dimensions dominated an ongoing experience},
author = {Kraus, Benjamin J. and Robinson, Robert J. and White, John A. and Eichenbaum, Howard and Hasselmo, Michael E.},
doi = {10.1016/j.neuron.2013.04.015},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Kraus et al.{\_}2013{\_}Hippocampal “Time Cells” Time versus Path Integration.pdf:pdf},
issn = {08966273},
journal = {Neuron},
month = {jun},
number = {6},
pages = {1090--1101},
pmid = {23707613},
publisher = {Elsevier Inc.},
title = {{Hippocampal “Time Cells”: Time versus Path Integration}},
url = {http://dx.doi.org/10.1016/j.neuron.2013.04.015 https://linkinghub.elsevier.com/retrieve/pii/S0896627313003176},
volume = {78},
year = {2013}
}
@book{Fermi1956,
author = {Fermi, E},
isbn = {9780486603612},
publisher = {Dover Publications},
series = {Dover books in physics and mathematical physics},
title = {{Thermodynamics}},
url = {https://books.google.nl/books?id=VEZ1ljsT3IwC},
year = {1956}
}
@incollection{Goodfellow2016,
author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
booktitle = {Deep Learning},
pages = {201--220},
publisher = {MIT Press},
title = {{Deep Forward Networks}},
year = {2016}
}
@article{Palacios2020,
abstract = {Biological self-organisation can be regarded as a process of spontaneous pattern formation; namely, the emergence of structures that distinguish themselves from their environment. This process can occur at nested spatial scales: from the microscopic (e.g., the emergence of cells) to the macroscopic (e.g. the emergence of organisms). In this paper, we pursue the idea that Markov blankets – that separate the internal states of a structure from external states – can self-assemble at successively higher levels of organisation. Using simulations, based on the principle of variational free energy minimisation, we show that hierarchical self-organisation emerges when the microscopic elements of an ensemble have prior (e.g., genetic) beliefs that they participate in a macroscopic Markov blanket: i.e., they can only influence – or be influenced by – a subset of other elements. Furthermore, the emergent structures look very much like those found in nature (e.g., cells or organelles), when influences are mediated by short range signalling. These simulations are offered as a proof of concept that hierarchical self-organisation of Markov blankets (into Markov blankets) can explain the self-evidencing, autopoietic behaviour of biological systems.},
author = {Palacios, Ensor Rafael and Razi, Adeel and Parr, Thomas and Kirchhoff, Michael and Friston, Karl J.},
doi = {10.1016/j.jtbi.2019.110089},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Palacios et al.{\_}2020{\_}On Markov blankets and hierarchical self-organisation.pdf:pdf},
issn = {00225193},
journal = {Journal of Theoretical Biology},
keywords = {Active inference,Dynamical systems,Free energy,Markov blanket,Self-organisation},
month = {feb},
pages = {110089},
pmid = {31756340},
publisher = {Elsevier Ltd},
title = {{On Markov blankets and hierarchical self-organisation}},
url = {https://doi.org/10.1016/j.jtbi.2019.110089 https://linkinghub.elsevier.com/retrieve/pii/S0022519319304588},
volume = {486},
year = {2020}
}
@article{Hope1752,
abstract = {Intracellular pH, ratios of phosphocreatine (PCr) to ATP and PCr to inorganic phosphate (Pi) as well as isometric tension were measured during 1 Hz sciatic nerve stimulation and during recovery in the calf muscles of mdx (a model of Duchenne muscular dystrophy) and control mice. Tension did not decline significantly in either strain. The ratio of PCr/(PCr + Pi) was significantly reduced in mdx as against control muscle during exercise and recovery, but the ratio of PCr/ATP and the half-time for PCr recovery were similar in both strains. A reduction in the maximal activities of succinate dehydrogenase and succinate- cytochrome c reductase suggests that mitochondrial metabolism may be impaired. The similarity in PCr recovery times suggests that the muscle has adapted, making any impairment of oxidative metabolism negligible in the intact system. The rate of pH recovery is prolonged in mdx muscle and provides strong evidence for a decline in the capacity of dystrophic muscle to extrude proton equivalents. These data are compared with a previous study which used 10 Hz stimulation and also observed a slow pH recovery. The slow pH recovery could be explained by an elevation in intracellular sodium.},
author = {Hope, Thomas},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Hope{\_}1752{\_}The Royal Society is collaborating with JSTOR to digitize, preserve, and extend access to Proceedings Biological Sciences. {\textregistered}.pdf:pdf},
journal = {Philosophical Transactions of the Royal Society of London},
pages = {530 -- 533},
title = {{The Royal Society is collaborating with JSTOR to digitize, preserve, and extend access to Proceedings: Biological Sciences. {\textregistered} www.jstor.org}},
volume = {47},
year = {1752}
}
@article{Friston2015b,
abstract = {Understanding how organisms establish their form during embryogenesis and regeneration represents a major knowledge gap in biological pattern formation. It has been recently suggested that morphogenesis could be understood in terms of cellular information processing and the ability of cell groups to model shape. Here, we offer a proof of principle that self-assembly is an emergent property of cells that share a common (genetic and epigenetic) model of organismal form. This behaviour is formulated in terms of variational free-energy minimization - of the sort that has been used to explain action and perception in neuroscience. In brief, casting the minimization of thermodynamic free energy in terms of variational free energy allows one to interpret (the dynamics of) a system as inferring the causes of its inputs - and acting to resolve uncertainty about those causes. This novel perspective on the coordination of migration and differentiation of cells suggests an interpretation of genetic codes as parametrizing a generative model - predicting the signals sensed by cells in the target morphology - and epigenetic processes as the subsequent inversion of that model. This theoretical formulation may complement bottom-up strategies - that currently focus on molecular pathways - with (constructivist) top-down approaches that have proved themselves in neuroscience and cybernetics.},
author = {Friston, Karl J. and Levin, Michael and Sengupta, Biswa and Pezzulo, Giovanni},
doi = {10.1098/rsif.2014.1383},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston et al.{\_}2015{\_}Knowing one's place A free-energy approach to pattern regulation.pdf:pdf},
issn = {17425662},
journal = {Journal of the Royal Society Interface},
keywords = {Active inference,Free energy,Morphogenesis,Pattern formation,Random attractor,Self-assembly},
number = {105},
title = {{Knowing one's place: A free-energy approach to pattern regulation}},
volume = {12},
year = {2015}
}
@article{Ueltzhoffer2018,
abstract = {This work combines the free energy principle and the ensuing active inference dynamics with recent advances in variational inference in deep generative models, and evolution strategies to introduce the “deep active inference” agent. This agent minimises a variational free energy bound on the average surprise of its sensations, which is motivated by a homeostatic argument. It does so by optimising the parameters of a generative latent variable model of its sensory inputs, together with a variational density approximating the posterior distribution over the latent variables, given its observations, and by acting on its environment to actively sample input that is likely under this generative model. The internal dynamics of the agent are implemented using deep and recurrent neural networks, as used in machine learning, making the deep active inference agent a scalable and very flexible class of active inference agent. Using the mountain car problem, we show how goal-directed behaviour can be implemented by defining appropriate priors on the latent states in the agent's model. Furthermore, we show that the deep active inference agent can learn a generative model of the environment, which can be sampled from to understand the agent's beliefs about the environment and its interaction therewith.},
author = {Ueltzh{\"{o}}ffer, Kai},
doi = {10.1007/s00422-018-0785-7},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Ueltzh{\"{o}}ffer{\_}2018{\_}Deep active inference.pdf:pdf},
issn = {14320770},
journal = {Biological Cybernetics},
keywords = {Action,Cognition,Deep learning,Generative models,Perception,Variational inference},
number = {6},
pages = {547--573},
pmid = {30350226},
title = {{Deep active inference}},
volume = {112},
year = {2018}
}
@article{Kilner2007a,
abstract = {Is it possible to understand the intentions of other people by simply observing their actions? Many believe that this ability is made possible by the brain's mirror neuron system through its direct link between action and observation. However, precisely how intentions can be inferred through action observation has provoked much debate. Here we suggest that the function of the mirror system can be understood within a predictive coding framework that appeals to the statistical approach known as empirical Bayes. Within this scheme the most likely cause of an observed action can be inferred by minimizing the prediction error at all levels of the cortical hierarchy that are engaged during action observation. This account identifies a precise role for the mirror system in our ability to infer intentions from actions and provides the outline of the underlying computational mechanisms. {\textcopyright} 2007 Marta Olivetti Belardinelli and Springer-Verlag.},
author = {Kilner, James M. and Friston, Karl J. and Frith, Christopher D.},
doi = {10.1007/s10339-007-0170-2},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Kilner, Friston, Frith{\_}2007{\_}Predictive coding An account of the mirror neuron system.pdf:pdf},
issn = {16124782},
journal = {Cognitive Processing},
keywords = {Action observation,Bayesian inference,Mirror neurons,Predictive coding},
number = {3},
pages = {159--166},
title = {{Predictive coding: An account of the mirror neuron system}},
volume = {8},
year = {2007}
}
@article{Hopfield2010,
abstract = {Thinking allows an animal to take an effective action in a novel situation based on a mental exploration of possibilities and previous knowledge. We describe a model animal, with a neural system based loosely on the rodent hippocampus, which performs mental exploration to find a useful route in a spatial world it has previously learned. It then mentally recapitulates the chosen route, and this intent is converted to motor acts that move the animal physically along the route. The modeling is based on spiking neurons with spike-frequency adaptation. Adaptation causes the continuing evolution in the pattern of neural activity that is essential to mental exploration. A successful mental exploration is remembered through spike-timing-dependent synaptic plasticity. The system is also an episodic memory for an animal chiefly concerned with locations.},
author = {Hopfield, John J.},
doi = {10.1073/pnas.0913991107},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Hopfield{\_}2010{\_}Neurodynamics of mental exploration.pdf:pdf},
issn = {00278424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Hippocampus,Memory,Planning,Thought},
number = {4},
pages = {1648--1653},
title = {{Neurodynamics of mental exploration}},
volume = {107},
year = {2010}
}
@article{Shi2019,
abstract = {Learning generative models that span multiple data modalities, such as vision and language, is often motivated by the desire to learn more useful, generalisable representations that faithfully capture common underlying factors between the modalities. In this work, we characterise successful learning of such models as the fulfillment of four criteria: i) implicit latent decomposition into shared and private subspaces, ii) coherent joint generation over all modalities, iii) coherent cross-generation across individual modalities, and iv) improved model learning for individual modalities through multi-modal integration. Here, we propose a mixture-of-experts multimodal variational autoencoder (MMVAE) to learn generative models on different sets of modalities, including a challenging image-language dataset, and demonstrate its ability to satisfy all four criteria, both qualitatively and quantitatively.},
archivePrefix = {arXiv},
arxivId = {1911.03393},
author = {Shi, Yuge and Siddharth, N. and Paige, Brooks and Torr, Philip H S},
eprint = {1911.03393},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Shi et al.{\_}2019{\_}Variational Mixture-of-Experts Autoencoders for Multi-Modal Deep Generative Models.pdf:pdf},
month = {nov},
number = {NeurIPS},
title = {{Variational Mixture-of-Experts Autoencoders for Multi-Modal Deep Generative Models}},
url = {http://arxiv.org/abs/1911.03393},
year = {2019}
}
@article{Kass1989,
author = {Kass, Robert E. and Steffey, Duane},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Kass, Steffey{\_}1989{\_}Approximate Bayesian Inference in Conditionally Independent Hierarchical Models (Parametric Empirical Bayes Models).pdf:pdf},
journal = {Journal of the American Statistical Association},
number = {407},
pages = {717--726},
title = {{Approximate Bayesian Inference in Conditionally Independent Hierarchical Models (Parametric Empirical Bayes Models)}},
volume = {84},
year = {1989}
}
@article{Eigen1971,
author = {Eigen, Manfred},
doi = {10.1007/BF00623322},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Eigen{\_}1971{\_}Selforganization of matter and the evolution of biological macromolecules.pdf:pdf},
issn = {0028-1042},
journal = {Die Naturwissenschaften},
month = {oct},
number = {10},
pages = {465--523},
title = {{Selforganization of matter and the evolution of biological macromolecules}},
volume = {58},
year = {1971}
}
@article{Dharani2015,
abstract = {Where exactly in the perceptual neurons are thoughts generated? A neuron has three prominent parts – dendrites, soma and axon. All are electrically active, and in this chapter we will study the electrical properties of each of these structures and see how the dendrites particularly stand out. It is shown that axodendritic synapses are very common in the central nervous system, and ascertain that most of the time the axons are the senders and dendrites are the receivers. Several outstanding features of dendrites are presented, which show that dendrites generate primary thoughts. Next, we will see where exactly in the dendrites thoughts are generated. All cells (including neurons) consist of three fundamental portions – membrane, cytoplasm and nucleus. It is categorically demonstrated that primary thoughts are generated by molecular gadgets situated in the dendritic membrane. These molecular gadgets are called molecular grids.},
author = {Dharani, Krishnagopal},
doi = {10.1016/b978-0-12-800900-0.00006-3},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Dharani{\_}2015{\_}Dendrites and Primary Thoughts.pdf:pdf},
isbn = {9780128009000},
journal = {The Biology of Thought},
pages = {109--122},
title = {{Dendrites and Primary Thoughts}},
year = {2015}
}
@incollection{Churchland1994,
author = {Churchland, Patricia S. and Ramachandran, V.S. and Sejnowski, Terrence J},
booktitle = {Large-Scale Neuronal Theories of the Brain},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Churchland, Ramachandran, Sejnowski{\_}1994{\_}A Critique of Pure Vision.pdf:pdf},
isbn = {9780262111836},
publisher = {The MIT Press},
title = {{A Critique of Pure Vision}},
year = {1994}
}
@book{Mitchell1997,
author = {Mitchell, Tom M.},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Mitchell{\_}1997{\_}Machine Learning.pdf:pdf},
isbn = {0070428077},
publisher = {McGraw-Hill Science/Engineering/Math},
title = {{Machine Learning}},
year = {1997}
}
@article{Badcock2019,
abstract = {The purpose of this review was to integrate leading paradigms in psychology and neuroscience with a theory of the embodied, situated human brain, called the Hierarchically Mechanistic Mind (HMM). The HMM describes the brain as a complex adaptive system that functions to minimize the entropy of our sensory and physical states via action-perception cycles generated by hierarchical neural dynamics. First, we review the extant literature on the hierarchical structure of the brain. Next, we derive the HMM from a broader evolutionary systems theory that explains neural structure and function in terms of dynamic interactions across four nested levels of biological causation (i.e., adaptation, phylogeny, ontogeny, and mechanism). We then describe how the HMM aligns with a global brain theory in neuroscience called the free-energy principle, leveraging this theory to mathematically formulate neural dynamics across hierarchical spatiotemporal scales. We conclude by exploring the implications of the HMM for psychological inquiry.},
author = {Badcock, Paul and Friston, Karl J. and Ramstead, Maxwell J.D. and Ploeger, Annemie and Hohwy, Jakob},
doi = {10.3758/s13415-019-00721-3},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Badcock et al.{\_}2019{\_}The hierarchically mechanistic mind an evolutionary systems theory of the human brain, cognition, and behavior.pdf:pdf},
issn = {15307026},
journal = {Cognitive, Affective and Behavioral Neuroscience},
keywords = {Active inference,Adaptive prior,Developmental psychology,Evolutionary Systems Theory,Evolutionary psychology,Free-Energy Principle,Hierarchically Mechanistic Mind},
number = {6},
pages = {1319--1351},
pmid = {31115833},
publisher = {Cognitive, Affective, {\&} Behavioral Neuroscience},
title = {{The hierarchically mechanistic mind: an evolutionary systems theory of the human brain, cognition, and behavior}},
volume = {19},
year = {2019}
}
@article{Hesselmann2010,
abstract = {Perceptual decisions can be made when sensory input affords an inference about what generated that input. Here, we report findings from two independent perceptual experiments conducted during functional magnetic resonance imaging (fMRI) with a sparse event-related design. The first experiment, in the visual modality, involved forced-choice discrimination of coherence in random dot kinematograms that contained either subliminal or periliminal motion coherence. The second experiment, in the auditory domain, involved free response detection of (non-semantic) near-threshold acoustic stimuli. We analysed fluctuations in ongoing neural activity, as indexed by fMRI, and found that neuronal activity in sensory areas (extrastriate visual and early auditory cortex) biases perceptual decisions towards correct inference and not towards a specific percept. Hits (detection of near-threshold stimuli) were preceded by significantly higher activity than both misses of identical stimuli or false alarms, in which percepts arise in the absence of appropriate sensory input. In accord with predictive coding models and the free-energy principle, this observation suggests that cortical activity in sensory brain areas reflects the precision of prediction errors and not just the sensory evidence or prediction errors per se. {\textcopyright} 2010 Hesselmann et al.},
author = {Hesselmann, Guido and Sadaghiani, Sepideh and Friston, Karl J. and Kleinschmidt, Andreas},
doi = {10.1371/journal.pone.0009926},
editor = {Lauwereyns, Jan},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Hesselmann et al.{\_}2010{\_}Predictive Coding or Evidence Accumulation False Inference and Neuronal Fluctuations.pdf:pdf},
issn = {1932-6203},
journal = {PLoS ONE},
month = {mar},
number = {3},
pages = {e9926},
pmid = {20369004},
title = {{Predictive Coding or Evidence Accumulation? False Inference and Neuronal Fluctuations}},
url = {https://dx.plos.org/10.1371/journal.pone.0009926},
volume = {5},
year = {2010}
}
@article{Zhao2017,
abstract = {A key advance in learning generative models is the use of amortized inference distributions that are jointly trained with the models. We find that existing training objectives for variational autoencoders can lead to inaccurate amortized inference distributions and, in some cases, improving the objective provably degrades the inference quality. In addition, it has been observed that variational autoencoders tend to ignore the latent variables when combined with a decoding distribution that is too flexible. We again identify the cause in existing training criteria and propose a new class of objectives (InfoVAE) that mitigate these problems. We show that our model can significantly improve the quality of the variational posterior and can make effective use of the latent features regardless of the flexibility of the decoding distribution. Through extensive qualitative and quantitative analyses, we demonstrate that our models outperform competing approaches on multiple performance metrics.},
archivePrefix = {arXiv},
arxivId = {1706.02262},
author = {Zhao, Shengjia and Song, Jiaming and Ermon, Stefano},
eprint = {1706.02262},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Zhao, Song, Ermon{\_}2017{\_}InfoVAE Information Maximizing Variational Autoencoders.pdf:pdf},
title = {{InfoVAE: Information Maximizing Variational Autoencoders}},
url = {http://arxiv.org/abs/1706.02262},
year = {2017}
}
@article{Grebogi1987,
author = {Grebogi, C. and Ott, E. and Yorke, J. A.},
doi = {10.1126/science.238.4827.632},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Grebogi, Ott, Yorke{\_}1987{\_}Chaos, Strange Attractors, and Fractal Basin Boundaries in Nonlinear Dynamics.pdf:pdf},
issn = {0036-8075},
journal = {Science},
month = {oct},
number = {4827},
pages = {632--638},
title = {{Chaos, Strange Attractors, and Fractal Basin Boundaries in Nonlinear Dynamics}},
volume = {238},
year = {1987}
}
@incollection{Ganong2012a,
author = {Barrett, Kim E and Boitano, Scott and Barman, Susan M and Brooks, Heddwen L},
booktitle = {Ganong's Review of Medical Physiology},
chapter = {6},
edition = {24th},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Barrett et al.{\_}2012{\_}Synaptic {\&} Junctional Transmission.pdf:pdf},
isbn = {978-0-07-160568-7},
pages = {125},
publisher = {Mc Graw Hill},
title = {{Synaptic {\&} Junctional Transmission}},
url = {http://mhmedical.com/content.aspx?aid=56261004},
year = {2012}
}
@article{Ramstead2018,
author = {Ramstead, Maxwell James D{\'{e}}sormeau and Badcock, Paul Benjamin and Friston, Karl John},
doi = {10.1016/j.plrev.2017.09.001},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Ramstead, Badcock, Friston{\_}2018{\_}Answering Schr{\"{o}}dinger's question A free-energy formulation.pdf:pdf},
issn = {15710645},
journal = {Physics of Life Reviews},
keywords = {complex adaptive systems,evolutionary systems theory,free energy principle,hierarchically mechanistic mind,physics of the mind,variational neuroethology},
month = {mar},
pages = {1--16},
publisher = {Elsevier B.V.},
title = {{Answering Schr{\"{o}}dinger's question: A free-energy formulation}},
url = {http://dx.doi.org/10.1016/j.plrev.2017.09.001 https://linkinghub.elsevier.com/retrieve/pii/S1571064517301409},
volume = {24},
year = {2018}
}
@article{Schwartz2017,
abstract = {Despite their great success, there is still no comprehensive theoretical understanding of learning with Deep Neural Networks (DNNs) or their inner organization. Previous work [Tishby and Zaslavsky (2015)] proposed to analyze DNNs in the Information Plane; i.e., the plane of the Mutual Information values that each layer preserves on the input and output variables. They suggested that the goal of the network is to optimize the Information Bottleneck (IB) tradeoff between compression and prediction, successively, for each layer. In this work we follow up on this idea and demonstrate the effectiveness of the Information- Plane visualization of DNNs. Our main results are: (i) most of the training epochs in standard DL are spent on compression of the input to efficient representation and not on fitting the training labels. (ii) The representation compression phase begins when the training errors becomes small and the Stochastic Gradient Decent (SGD) epochs change from a fast drift to smaller training error into a stochastic relaxation, or random diffusion, constrained by the training error value. (iii) The converged layers lie on or very close to the Information Bottleneck (IB) theoretical bound, and the maps from the input to any hidden layer and from this hidden layer to the output satisfy the IB self-consistent equations. This generalization through noise mechanism is unique to Deep Neural Networks and absent in one layer networks. (iv) The training time is dramatically reduced when adding more hidden layers. Thus the main advantage of the hidden layers is computational. This can be explained by the reduced relaxation time, as this it scales super-linearly (exponentially for simple diffusion) with the information compression from the previous layer. (v) As we expect critical slowing down of the stochastic relaxation near phase transitions on the IB curve, we expect the hidden layers to converge to such critical points.1.},
archivePrefix = {arXiv},
arxivId = {1703.00810},
author = {Schwartz-Ziv, Ravid and Tishby, Naftali},
eprint = {1703.00810},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Schwartz-Ziv, Tishby{\_}2017{\_}Opening the black box of deep neural networks via information.pdf:pdf},
journal = {arXiv},
keywords = {Deep learning,Deep neural networks,Information bottleneck,Representation learning},
pages = {1--19},
title = {{Opening the black box of deep neural networks via information}},
year = {2017}
}
@article{Pinto2008,
abstract = {Progress in understanding the brain mechanisms underlying vision requires the construction of computational models that not only emulate the brain's anatomy and physiology, but ultimately match its performance on visual tasks. In recent years, "natural" images have become popular in the study of vision and have been used to show apparently impressive progress in building such models. Here, we challenge the use of uncontrolled "natural" images in guiding that progress. In particular, we show that a simple V1-like model - a neuroscientist's "null" model, which should perform poorly at real-world visual object recognition tasks - outperforms state-of-the-art object recognition systems (biologically inspired and otherwise) on a standard, ostensibly natural image recognition test. As a counterpoint, we designed a "simpler" recognition test to better span the real-world variation in object pose, position, and scale, and we show that this test correctly exposes the inadequacy of the V1-like model. Taken together, these results demonstrate that tests based on uncontrolled natural images can be seriously misleading, potentially guiding progress in the wrong direction. Instead, we reexamine what it means for images to be natural and argue for a renewed focus on the core problem of object recognition - real-world image variation. {\textcopyright} 2008 Pinto et al.},
author = {Pinto, Nicolas and Cox, David D. and DiCarlo, James J.},
doi = {10.1371/journal.pcbi.0040027},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Pinto, Cox, DiCarlo{\_}2008{\_}Why is real-world visual object recognition hard.pdf:pdf},
issn = {1553734X},
journal = {PLoS Computational Biology},
number = {1},
pages = {0151--0156},
pmid = {18225950},
title = {{Why is real-world visual object recognition hard?}},
volume = {4},
year = {2008}
}
@article{Yoshida2008,
abstract = {This paper introduces a model of 'theory of mind', namely, how we represent the intentions and goals of others to optimise our mutual interactions. We draw on ideas from optimum control and game theory to provide a 'game theory of mind'. First, we consider the representations of goals in terms of value functions that are prescribed by utility or rewards. Critically, the joint value functions and ensuing behaviour are optimised recursively, under the assumption that I represent your value function, your representation of mine, your representation of my representation of yours, and so on ad infinitum. However, if we assume that the degree of recursion is bounded, then players need to estimate the opponent's degree of recursion (i.e., sophistication) to respond optimally. This induces a problem of inferring the opponent's sophistication, given behavioural exchanges. We show it is possible to deduce whether players make inferences about each other and quantify their sophistication on the basis of choices in sequential games. This rests on comparing generative models of choices with, and without, inference. Model comparison is demonstrated using simulated and real data from a 'stag-hunt'. Finally, we note that exactly the same sophisticated behaviour can be achieved by optimising the utility function itself (through prosocial utility), producing unsophisticated but apparently altruistic agents. This may be relevant ethologically in hierarchal game theory and coevolution. {\textcopyright} 2008 Yoshida et al.},
author = {Yoshida, Wako and Dolan, Raymond J. and Friston, Karl J.},
doi = {10.1371/journal.pcbi.1000254},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Yoshida, Dolan, Friston{\_}2008{\_}Game theory of mind.pdf:pdf},
issn = {1553734X},
journal = {PLoS Computational Biology},
number = {12},
title = {{Game theory of mind}},
volume = {4},
year = {2008}
}
@inproceedings{Furmston2010,
abstract = {We consider reinforcement learning as solving a Markov decision process with unknown transition distribution. Based on interaction with the environment, an estimate of the transition matrix is obtained from which the optimal decision policy is formed. The classical maximum likelihood point estimate of the transition model does not reflect the uncertainty in the estimate of the transition model and the resulting policies may consequently lack a sufficient degree of exploration. We consider a Bayesian alternative that maintains a distribution over the transition so that the resulting policy takes into account the limited experience of the environment. The resulting algorithm is formally intractable and we discuss two approximate solution methods, Variational Bayes and Expectation Propagation. Copyright 2010 by the authors.},
author = {Furmston, Thomas; and Barber, David},
booktitle = {Journal of Machine Learning Research},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Furmston, Barber{\_}2010{\_}Variational methods for reinforcement learning.pdf:pdf},
issn = {15324435},
pages = {241--248},
title = {{Variational methods for reinforcement learning}},
volume = {9},
year = {2010}
}
@article{Tao2001,
abstract = {Transcellular retrograde signaling from the postsynaptic target cell to the presynaptic neuron plays critical roles in the formation, maturation, and plasticity of synaptic connections. We here review recent progress in our understanding of the retrograde signaling at developing central synapses. Three forms of potential retrograde signals - membrane-permeant factors, membrane-bound factors, and secreted factors - have been implicated at both developing and mature synapses. Although many of these signals may be active constitutively, retrograde factors produced in association with activity-dependent synaptic plasticity, e.g., long-term potentiation and long-term depression, are of particular interest, because they may induce modification of neuronal excitability and synaptic transmission, functions directly related to the processing and storage of information in the nervous system.},
author = {Tao, H. W. and Poo, M.},
doi = {10.1073/pnas.191351698},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Tao, Poo{\_}2001{\_}Retrograde signaling at central synapses.pdf:pdf},
issn = {00278424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
number = {20},
pages = {11009--11015},
pmid = {11572961},
title = {{Retrograde signaling at central synapses}},
volume = {98},
year = {2001}
}
@article{Marreiros2009,
author = {Marreiros, Andr{\'{e}} C. and Kiebel, Stefan J. and Daunizeau, Jean and Harrison, Lee M. and Friston, Karl J.},
doi = {10.1016/j.neuroimage.2008.10.008},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Marreiros et al.{\_}2009{\_}Population dynamics under the Laplace assumption.pdf:pdf},
issn = {10538119},
journal = {NeuroImage},
month = {feb},
number = {3},
pages = {701--714},
title = {{Population dynamics under the Laplace assumption}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811908011063},
volume = {44},
year = {2009}
}
@article{Ahmadi2018,
abstract = {This study introduces PV-RNN, a novel variational RNN inspired by the predictivecoding ideas. The model learns to extract the probabilistic structures hidden in fluctuating temporal patterns by dynamically changing the stochasticity of its latent states. Its architecture attempts to address two major concerns of variational Bayes RNNs: How can latent variables learn meaningful representations and how can the inference model transfer future observations to the latent variables. PV-RNN does both by introducing adaptive vectors mirroring the training data, whose values can then be adapted differently during evaluation. Moreover, prediction errors during backpropagation-rather than external inputs during the forward computation-are used to convey information to the network about the external data. For testing, we introduce error regression for predicting unseen sequences as inspired by predictive coding that leverages those mechanisms. As in other Variational Bayes RNNs, our model learns by maximizing a lower bound on the marginal likelihood of the sequential data, which is composed of two terms: The negative of the expectation of prediction errors; and the negative of the Kullback-Leibler divergence between the prior and the approximate posterior distributions. The model introduces a weighting parameter, the meta-prior, to balance the optimization pressure placed on those two terms. We test the model on two datasets with probabilistic structures and show that with high values of the meta-prior the network develops deterministic chaos through which the data's randomness is imitated. For low values, the model behaves as a random process. The network performs best on intermediate values, and is able to capture the latent probabilistic structure with good generalization. Analyzing the meta-prior's impact on the network allows to precisely study the theoretical value and practical benefits of incorporating stochastic dynamics in our model. We demonstrate better prediction performance on a robot imitation task with our model using error regression compared to a standard variational Bayes model lacking such a procedure.},
author = {Ahmadi, Ahmadreza and Tani, Jun},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Ahmadi, Tani{\_}2018{\_}A Novel Predictive-Coding-Inspired Variational RNN Model for Online Prediction and Recognition.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {Generative model,Inference model,Predictive coding,Recurrent neural network,Variational bayes},
pages = {2025--2074},
title = {{A Novel Predictive-Coding-Inspired Variational RNN Model for Online Prediction and Recognition}},
volume = {2074},
year = {2018}
}
@article{Scott2004,
abstract = {Skilled motor behaviour, from the graceful leap of a ballerina to a precise pitch by a baseball player, appears effortless but reflects an intimate interaction between the complex mechanical properties of the body and control by a highly distributed circuit in the CNS. An important challenge for understanding motor function is to connect these three levels of the motor system - motor behaviour, limb mechanics and neural control. Optimal feedback control theory might provide the important link across these levels of the motor system and help to unravel how the primary motor cortex and other regions of the brain plan and control movement.},
author = {Scott, Stephen H.},
doi = {10.1038/nrn1427},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Scott{\_}2004{\_}Optimal feedback control and the neural basis of volitional motor control.pdf:pdf},
issn = {1471003X},
journal = {Nature Reviews Neuroscience},
number = {7},
pages = {532--544},
pmid = {15208695},
title = {{Optimal feedback control and the neural basis of volitional motor control}},
volume = {5},
year = {2004}
}
@article{Todorov2002,
abstract = {A central problem in motor control is understanding how the many biomechanical degrees of freedom are coordinated to achieve a common goal. An especially puzzling aspect of coordination is that behavioral goals are achieved reliably and repeatedly with movements rarely reproducible in their detail. Existing theoretical frameworks emphasize either goal achievement or the richness of motor variability, but fail to reconcile the two. Here we propose an alternative theory based on stochastic optimal feedback control. We show that the optimal strategy in the face of uncertainty is to allow variability in redundant (task-irrelevant) dimensions. This strategy does not enforce a desired trajectory, but uses feedback more intelligently, correcting only those deviations that interfere with task goals. From this framework, task-constrained variability, goal-directed corrections, motor synergies, controlled parameters, simplifying rules and discrete coordination modes emerge naturally. We present experimental results from a range of motor tasks to support this theory.},
author = {Todorov, Emanuel and Jordan, Michael I.},
doi = {10.1038/nn963},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Todorov, Jordan{\_}2002{\_}Optimal feedback control as a theory of motor coordination.pdf:pdf},
issn = {10976256},
journal = {Nature Neuroscience},
number = {11},
pages = {1226--1235},
pmid = {12404008},
title = {{Optimal feedback control as a theory of motor coordination}},
volume = {5},
year = {2002}
}
@article{Berseth2019a,
abstract = {All living organisms struggle against the forces of nature to carve out a maintainable niche. We propose that such a search for order amidst chaos might offer a unifying principle for the emergence of useful behaviors in artificial agents. We formalize this idea into an unsupervised reinforcement learning method called surprise minimizing reinforcement learning (SMiRL). SMiRL alternates between learning a density model to evaluate the surprise of a stimulus, and improving the policy to seek more predictable stimuli. This process maximizes a lower-bound on the negative entropy of the states, which can be seen as maximizing the agent's ability to maintain order in the environment. The policy seeks out stable and repeatable situations that counteract the environment's prevailing sources of entropy. This might include avoiding other hostile agents, or finding a stable, balanced pose for a bipedal robot in the face of disturbance forces. We demonstrate that our surprise minimizing agents can successfully play Tetris, Doom, control a humanoid to avoid falls, and navigate to escape enemies in a maze without any task-specific reward supervision. We further show that SMiRL can be used together with standard task rewards to accelerate reward-driven learning.},
archivePrefix = {arXiv},
arxivId = {1912.05510},
author = {Berseth, Glen and Geng, Daniel and Devin, Coline and Rhinehart, Nicholas and Finn, Chelsea and Jayaraman, Dinesh and Levine, Sergey},
eprint = {1912.05510},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Berseth et al.{\_}2019{\_}SMiRL Surprise Minimizing Reinforcement Learning in Dynamic Environments.pdf:pdf},
pages = {1--15},
title = {{SMiRL: Surprise Minimizing Reinforcement Learning in Dynamic Environments}},
url = {http://arxiv.org/abs/1912.05510},
year = {2019}
}
@article{Tishby2000,
abstract = {We define the relevant information in a signal {\$}x\backslashin X{\$} as being the information that this signal provides about another signal {\$}y\backslashin \backslashY{\$}. Examples include the information that face images provide about the names of the people portrayed, or the information that speech sounds provide about the words spoken. Understanding the signal {\$}x{\$} requires more than just predicting {\$}y{\$}, it also requires specifying which features of {\$}\backslashX{\$} play a role in the prediction. We formalize this problem as that of finding a short code for {\$}\backslashX{\$} that preserves the maximum information about {\$}\backslashY{\$}. That is, we squeeze the information that {\$}\backslashX{\$} provides about {\$}\backslashY{\$} through a `bottleneck' formed by a limited set of codewords {\$}\backslashtX{\$}. This constrained optimization problem can be seen as a generalization of rate distortion theory in which the distortion measure {\$}d(x,\backslashx){\$} emerges from the joint statistics of {\$}\backslashX{\$} and {\$}\backslashY{\$}. This approach yields an exact set of self consistent equations for the coding rules {\$}X \backslashto \backslashtX{\$} and {\$}\backslashtX \backslashto \backslashY{\$}. Solutions to these equations can be found by a convergent re-estimation method that generalizes the Blahut-Arimoto algorithm. Our variational principle provides a surprisingly rich framework for discussing a variety of problems in signal processing and learning, as will be described in detail elsewhere.},
archivePrefix = {arXiv},
arxivId = {physics/0004057},
author = {Tishby, Naftali and Pereira, Fernando C. and Bialek, William},
eprint = {0004057},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Tishby, Pereira, Bialek{\_}2000{\_}The information bottleneck method.pdf:pdf},
month = {apr},
pages = {1--16},
primaryClass = {physics},
title = {{The information bottleneck method}},
year = {2000}
}
@article{Feldman2010,
abstract = {We suggested recently that attention can be understood as inferring the level of uncertainty or precision during hierarchical perception. In this paper, we try to substantiate this claim using neuronal simulations of directed spatial attention and biased competition. These simulations assume that neuronal activity encodes a probabilistic representation of the world that optimizes free-energy in a Bayesian fashion. Because free-energy bounds surprise or the (negative) log-evidence for internal models of the world, this optimization can be regarded as evidence accumulation or (generalized) predictive coding. Crucially, both predictions about the state of the world generating sensory data and the precision of those data have to be optimized. Here, we show that if the precision depends on the states, one can explain many aspects of attention. We illustrate this in the context of the Posner paradigm, using the simulations to generate both psychophysical and electrophysiological responses. These simulated responses are consistent with attentional bias or gating, competition for attentional resources, attentional capture and associated speed-accuracy trade-offs. Furthermore, if we present both attended and nonattended stimuli simultaneously, biased competition for neuronal representation emerges as a principled and straightforward property of Bayes-optimal perception. {\textcopyright} 2010 Feldman and Friston.},
author = {Feldman, Harriet and Friston, Karl J.},
doi = {10.3389/fnhum.2010.00215},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Feldman, Friston{\_}2010{\_}Attention, uncertainty, and free-energy.pdf:pdf},
issn = {16625161},
journal = {Frontiers in Human Neuroscience},
keywords = {Attention,Biased competition,Free-energy,Generative models,Perception,Precision,Predictive coding},
number = {December},
pages = {1--23},
title = {{Attention, uncertainty, and free-energy}},
volume = {4},
year = {2010}
}
@article{Hebb1949,
abstract = {Since its publication in 1949, D.O. Hebb's, The Organization of Behavior has been one of the most influential books in the fields of psychology and neuroscience. However, the original edition has been unavailable since 1966, ensuring that Hebb's comment that a classic normally means "cited but not read" is true in his case. This new edition rectifies a long-standing problem for behavioral neuroscientists--the inability to obtain one of the most cited publications in the field. The Organization of Behavior played a significant part in stimulating the investigation of the neural foundations of behavior and continues to be inspiring because it provides a general framework for relating behavior to synaptic organization through the dynamics of neural networks. D.O. Hebb was also the first to examine the mechanisms by which environment and experience can influence brain structure and function, and his ideas formed the basis for work on enriched environments as stimulants for behavioral development. References to Hebb, the Hebbian cell assembly, the Hebb synapse, and the Hebb rule increase each year. These forceful ideas of 1949 are now applied in engineering, robotics, and computer science, as well as neurophysiology, neuroscience, and psychology--a tribute to Hebb's foresight in developing a foundational neuropsychological theory of the organization of behavior.},
annote = {The original work by Hebb became unavailable from 1966 onwards. Nonetheless, it has been on of the most cited entries in the cognitive sciences, machine learning, and robotics, which shows how common is citing without reading. This is a republished version.},
author = {Hebb, D.O.},
doi = {10.4324/9781410612403},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Hebb{\_}1949{\_}The Organization of Behavior.pdf:pdf},
journal = {The Organization of Behavior},
title = {{The Organization of Behavior}},
year = {1949}
}
@article{Friston2016b,
abstract = {This Opinion article considers the implications for functional anatomy of how we represent temporal structure in our exchanges with the world. It offers a theoretical treatment that tries to make sense of the architectural principles seen in mammalian brains. Specifically, it considers a factorisation between representations of temporal succession and representations of content or, heuristically, a segregation into when and what. This segregation may explain the central role of the hippocampus in neuronal hierarchies while providing a tentative explanation for recent observations of how ordinal sequences are encoded. The implications for neuroanatomy and physiology may have something important to say about how self-organised cell assembly sequences enable the brain to exhibit purposeful behaviour that transcends the here and now.},
author = {Friston, Karl and Buzs{\'{a}}ki, Gyorgy},
doi = {10.1016/j.tics.2016.05.001},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston, Buzs{\'{a}}ki{\_}2016{\_}The Functional Anatomy of Time What and When in the Brain.pdf:pdf},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
keywords = {Bayesian,Hippocampus,Inference,Ordinal,Sequences,Spatiotemporal},
month = {jul},
number = {7},
pages = {500--511},
pmid = {27261057},
title = {{The Functional Anatomy of Time: What and When in the Brain}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661316300407},
volume = {20},
year = {2016}
}
@article{Hopfield2001a,
abstract = {A previous paper described a network of simple integrate-and-fire neurons that contained output neurons selective for specific spatiotemporal patterns of inputs: only experimental results were described. We now present the principles behind the operation of this network and discuss how these principles point to a general class of computational operations that can be carried out easily and naturally by networks of spiking neurons. Transient synchrony of the action potentials of a group of neurons is used to signal "recognition" of a space-time pattern across the inputs of those neurons. Appropriate synaptic coupling produces synchrony when the inputs to these neurons are nearly equal, leaving the neurons unsynchronized or only weakly synchronized for other input circumstances. When the input to this system comes from timed past events represented by decaying delay activity, the pattern of synaptic connections can be set such that synchronization occurs only for selected spatiotemporal patterns. We show how the recognition is invariant to uniform time warp and uniform intensity change of the input events. The fundamental recognition event is a transient collective synchronization, representing "many neurons now agree," an event that is then detected easily by a cell with a small time constant. If such synchronization is used in neurobiological computation, its hallmark will be a brief burst of gamma-band electroencephalogram noise when and where such a recognition event or decision occurs.},
author = {Hopfield, John J. and Brody, Carlos D.},
doi = {10.1073/pnas.98.3.1282},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Hopfield, Brody{\_}2001{\_}What is a moment Trasient synchrony as a collective mechanism for spatiotemporal integration.pdf:pdf},
issn = {00278424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
number = {3},
pages = {1282--1287},
title = {{What is a moment? Trasient synchrony as a collective mechanism for spatiotemporal integration}},
volume = {98},
year = {2001}
}
@article{Vahdat2020,
abstract = {Normalizing flows, autoregressive models, variational autoencoders (VAEs), and deep energy-based models are among competing likelihood-based frameworks for deep generative learning. Among them, VAEs have the advantage of fast and tractable sampling and easy-to-access encoding networks. However, they are currently outperformed by other models such as normalizing flows and autoregressive models. While the majority of the research in VAEs is focused on the statistical challenges, we explore the orthogonal direction of carefully designing neural architectures for hierarchical VAEs. We propose Nouveau VAE (NVAE), a deep hierarchical VAE built for image generation using depth-wise separable convolutions and batch normalization. NVAE is equipped with a residual parameterization of Normal distributions and its training is stabilized by spectral regularization. We show that NVAE achieves state-of-the-art results among non-autoregressive likelihood-based models on the MNIST, CIFAR-10, and CelebA HQ datasets and it provides a strong baseline on FFHQ. For example, on CIFAR-10, NVAE pushes the state-of-the-art from 2.98 to 2.91 bits per dimension, and it produces high-quality images on CelebA HQ as shown in Fig. 1. To the best of our knowledge, NVAE is the first successful VAE applied to natural images as large as 256×256 pixels.},
archivePrefix = {arXiv},
arxivId = {2007.03898},
author = {Vahdat, Arash and Kautz, Jan},
eprint = {2007.03898},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Vahdat, Kautz{\_}2020{\_}NVAE A Deep Hierarchical Variational Autoencoder.pdf:pdf},
journal = {arXiv},
number = {NeurIPS},
pages = {1--21},
title = {{NVAE: A Deep Hierarchical Variational Autoencoder}},
year = {2020}
}
@article{Hill1987,
abstract = {Although tick-borne rickettsiosis is endemic in Greece, until recently, human samples arriving at the National Reference Centre under suspicion of rickettsial infection were routinely tested only for Rickettsia typhi and R. conorii. However, identification of additional rickettsia species in ticks prompted revision of the protocol in 2010. Until that year, all human samples received by the laboratory were tested for antibodies against R. conorii and R. typhi only. Now, tests for R. slovaca, R. felis,and R. mongolotimonae are all included in routine analysis. The current description of a human R. slovaca case is possible as a result of these changes in routine testing.Copyright {\textcopyright} 2016, National Institute of Health. All rights reserved.},
author = {Hill, Murray},
doi = {http://dx.doi.org/10.7883/yoken.JJID.2015.194},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Hill{\_}1987{\_}Computation Concentrating.pdf:pdf},
issn = {1344-6304},
number = {April},
pages = {1896--1900},
pmid = {26370429},
title = {{Computation Concentrating}},
volume = {84},
year = {1987}
}
@article{Friston2015c,
abstract = {This review surveys recent trends in the use of local field potentials-and their non-invasive counterparts-to address the principles of functional brain architectures. In particular, we treat oscillations as the (observable) signature of context-sensitive changes in synaptic efficacy that underlie coordinated dynamics and message-passing in the brain. This rich source of information is now being exploited by various procedures-like dynamic causal modelling-to test hypotheses about neuronal circuits in health and disease. Furthermore, the roles played by neuromodulatory mechanisms can be addressed directly through their effects on oscillatory phenomena. These neuromodulatory or gain control processes are central to many theories of normal brain function (e.g. attention) and the pathophysiology of several neuropsychiatric conditions (e.g. Parkinson's disease). {\textcopyright} 2014.},
annote = {This is a review on findings of different frequencies in feedforwards and feedback signaling in relation to predictive coding.

Tags: [PAI][PIV][HPS]},
author = {Friston, Karl J. and Bastos, Andr{\'{e}} M. and Pinotsis, Dimitris and Litvak, Vladimir},
doi = {10.1016/j.conb.2014.05.004},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston et al.{\_}2015{\_}LFP and oscillations-what do they tell us.pdf:pdf},
issn = {18736882},
journal = {Current Opinion in Neurobiology},
pages = {1--6},
pmid = {25079053},
title = {{LFP and oscillations-what do they tell us?}},
volume = {31},
year = {2015}
}
@article{Tank1987a,
abstract = {Electronic circuits based on neurobiological models are able to solve complex problems rapidly. Their computational properties emerge from the collective interaction of many parts linked together in a network. The fact that biological computation is so effective suggests that it may be possible to attain similar capabilities in artificial devices based on the design principles of neural systems. The authors have studied a number of 'neural network' electronic circuits that can carry out significant computations.},
author = {Tank, David W. and Hopfield, John J.},
doi = {10.1038/scientificamerican1287-104},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Tank, Hopfield{\_}1987{\_}COLLECTIVE COMPUTATION IN NEURONLIKE CIRCUITS.pdf:pdf},
issn = {0036-8733},
journal = {Scientific American},
month = {dec},
number = {6},
pages = {104--114},
title = {{Collective Computation in Neuronlike Circuits}},
url = {http://www.nature.com/doifinder/10.1038/scientificamerican1287-104},
volume = {257},
year = {1987}
}
@article{Friston2010,
abstract = {We describe a Bayesian filtering scheme for nonlinear state-space models in continuous time. This scheme is called Generalised Filtering and furnishes posterior (conditional) densities on hidden states and unknown parameters generating observed data. Crucially, the scheme operates online, assimilating data to optimize the conditional density on time-varying states and time-invariant parameters. In contrast to Kalman and Particle smoothing, Generalised Filtering does not require a backwards pass. In contrast to variational schemes, it does not assume conditional independence between the states and parameters. Generalised Filtering optimises the conditional density with respect to a free-energy bound on the model's log-evidence. This optimisation uses the generalised motion of hidden states and parameters, under the prior assumption that the motion of the parameters is small. We describe the scheme, present comparative evaluations with a fixed-form variational version, and conclude with an illustrative application to a nonlinear state-space model of brain imaging time-series. {\textcopyright} 2010 Karl Friston et al.},
author = {Friston, Karl J. and Stephan, Klaas E. and Li, Baojuan and Daunizeau, Jean},
doi = {10.1155/2010/621670},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston et al.{\_}2010{\_}Generalised filtering.pdf:pdf},
issn = {1024123X},
journal = {Mathematical Problems in Engineering},
title = {{Generalised filtering}},
volume = {2010},
year = {2010}
}
@article{Sutton1988,
abstract = {We present a method for learning higher-order polynomial functions from examples using linear regression and feature construction. Regression is used on a set of training instances to produce a weight vector for a linear function over the feature set. If this hypothesis is imperfect, a new feature is constructed by forming the product of the two features that most effectively predict the squared error of the current hypothesis. This algorithm is then repeated. In an extension to this method, the specific pair of features to combine is selected by measuring their joint ability to predict the hypothesis' error.},
author = {Sutton, Richard S.},
doi = {10.1007/BF00115009},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Sutton{\_}1988{\_}Learning to predict by the methods of temporal differences.pdf:pdf},
issn = {0885-6125},
journal = {Machine Learning},
month = {aug},
number = {1},
pages = {9--44},
title = {{Learning to predict by the methods of temporal differences}},
url = {http://link.springer.com/10.1007/BF00115009},
volume = {3},
year = {1988}
}
@article{Friston2013,
abstract = {This paper presents a heuristic proof (and simulations of a primordial soup) suggesting that life-or biological self-organization-is an inevitable and emergent property of any (ergodic) random dynamical system that possesses a Markov blanket. This conclusion is based on the following arguments: if the coupling among an ensemble of dynamical systems is mediated by short-range forces, then the states of remote systems must be conditionally independent. These independencies induce a Markov blanket that separates internal and external states in a statistical sense. The existence of a Markov blanket means that internal states will appear to minimize a free energy functional of the states of their Markov blanket. Crucially, this is the same quantity that is optimized in Bayesian inference. Therefore, the internal states (and their blanket) will appear to engage in active Bayesian inference. In other words, they will appear to model-and act on-their world to preserve their functional and structural integrity, leading to homoeostasis and a simple form of autopoiesis. {\textcopyright} 2013 The Author(s).},
author = {Friston, Karl J.},
doi = {10.1098/rsif.2013.0475},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston{\_}2013{\_}Life as we know it.pdf:pdf},
issn = {17425662},
journal = {Journal of the Royal Society Interface},
keywords = {Active inference,Autopoiesis,Ergodicity,Free energy,Random attractor,Self-organization},
number = {86},
pmid = {23825119},
title = {{Life as we know it}},
volume = {10},
year = {2013}
}
@book{Sutton2018a,
author = {Sutton, Richard S. and Barto, Andrew G.},
edition = {2},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop//Sutton, Barto{\_}2018{\_}Frontiers (in reinforcement learning).pdf:pdf},
publisher = {The MIT Press},
title = {{Reinforcement Learning: an Introduction}},
year = {2018}
}
@article{Hopfield1995a,
abstract = {The collective behavior of interconnected spiking nerve cells is investigated. It is shown that a variety of model systems exhibit the same short-time behavior and rapidly converge to (approximately) periodic firing patterns with locally synchronized action potentials. The dynamics of one model can be described by a downhill motion on an energy landscape. Since an energy landscape makes it possible to understand and program computation done by an attractor network, the results will extend our understanding of collective computation from models based on a firing-rate description to biologically more realistic systems with integrate-and-fire neurons.},
author = {Hopfield, John J. and Herz, Andreas V. M.},
doi = {10.1073/pnas.92.15.6655},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Hopfield, Herz{\_}1995{\_}Rapid local synchronization of action potentials Toward computation with coupled integrate-and-fire neurons.pdf:pdf},
issn = {00278424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Lyapunov function,neurobiology,phase locking,pulse-coupled oscillators},
number = {15},
pages = {6655--6662},
pmid = {7624307},
title = {{Rapid local synchronization of action potentials: Toward computation with coupled integrate-and-fire neurons}},
volume = {92},
year = {1995}
}
@article{Blei2017,
abstract = {One of the core problems of modern statistics is to approximate difficult-to-compute probability densities. This problem is especially important in Bayesian statistics, which frames all inference about unknown quantities as a calculation involving the posterior density. In this article, we review variational inference (VI), a method from machine learning that approximates probability densities through optimization. VI has been used in many applications and tends to be faster than classical methods, such as Markov chain Monte Carlo sampling. The idea behind VI is to first posit a family of densities and then to find a member of that family which is close to the target density. Closeness is measured by Kullback–Leibler divergence. We review the ideas behind mean-field variational inference, discuss the special case of VI applied to exponential family models, present a full example with a Bayesian mixture of Gaussians, and derive a variant that uses stochastic optimization to scale up to massive data. We discuss modern research in VI and highlight important open problems. VI is powerful, but it is not yet well understood. Our hope in writing this article is to catalyze statistical research on this class of algorithms. Supplementary materials for this article are available online.},
archivePrefix = {arXiv},
arxivId = {1601.00670},
author = {Blei, David M. and Kucukelbir, Alp and McAuliffe, Jon D.},
doi = {10.1080/01621459.2017.1285773},
eprint = {1601.00670},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Blei, Kucukelbir, McAuliffe{\_}2017{\_}Variational Inference A Review for Statisticians.pdf:pdf},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Algorithms,Computationally intensive methods,Statistical computing},
number = {518},
pages = {859--877},
title = {{Variational Inference: A Review for Statisticians}},
volume = {112},
year = {2017}
}
@book{Schrodinger1944,
author = {Schr{\"{o}}dinger, Erwin},
edition = {1st},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Schr{\"{o}}dinger{\_}1944{\_}What is Life.pdf:pdf},
isbn = {0-521-42708-8},
publisher = {Cambridge University Press},
title = {{What is Life?}},
year = {1944}
}
@article{Friston2012a,
abstract = {The role of dopamine in behaviour and decision-making is often cast in terms of reinforcement learning and optimal decision theory. Here, we present an alternative view that frames the physiology of dopamine in terms of Bayes-optimal behaviour. In this account, dopamine controls the precision or salience of (external or internal) cues that engender action. In other words, dopamine balances bottom-up sensory information and top-down prior beliefs when making hierarchical inferences (predictions) about cues that have affordance. In this paper, we focus on the consequences of changing tonic levels of dopamine firing using simulations of cued sequential movements. Crucially, the predictions driving movements are based upon a hierarchical generative model that infers the context in which movements are made. This means that we can confuse agents by changing the context (order) in which cues are presented. These simulations provide a (Bayes-optimal) model of contextual uncertainty and set switching that can be quantified in terms of behavioural and electrophysiological responses. Furthermore, one can simulate dopaminergic lesions (by changing the precision of prediction errors) to produce pathological behaviours that are reminiscent of those seen in neurological disorders such as Parkinson's disease. We use these simulations to demonstrate how a single functional role for dopamine at the synaptic level can manifest in different ways at the behavioural level. {\textcopyright} 2012 Friston et al.},
author = {Friston, Karl J. and Shiner, Tamara and FitzGerald, Thomas and Galea, Joseph M. and Adams, Rick A. and Brown, Harriet and Dolan, Raymond J. and Moran, R. J. and Stephan, Klaas E. and Bestmann, Sven},
doi = {10.1371/journal.pcbi.1002327},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston et al.{\_}2012{\_}Dopamine, affordance and active inference.pdf:pdf},
issn = {1553734X},
journal = {PLoS Computational Biology},
number = {1},
pmid = {22241972},
title = {{Dopamine, affordance and active inference}},
volume = {8},
year = {2012}
}
@article{Hipolito2020,
abstract = {Recent characterisations of self-organising systems depend upon the presence of a ‘Markov blanket': a statistical boundary that mediates the interactions between what is inside of and outside of a system. We leverage this idea to provide an analysis of partitions in neuronal systems. This is applicable to brain architectures at multiple scales, enabling partitions into single neurons, brain regions, and brain-wide networks. This treatment is based upon the canonical micro-circuitry used in empirical studies of effective connectivity, so as to speak directly to practical applications. This depends upon the dynamic coupling between functional units, whose form recapitulates that of a Markov blanket at each level. The nuance afforded by partitioning neural systems in this way highlights certain limitations of ‘modular' perspectives of brain function that only consider a single level of description.},
author = {Hip{\'{o}}lito, In{\^{e}}s and Ramstead, Maxwell J.D. and Convertino, Laura and Bhat, Anjali and Friston, Karl and Parr, Thomas},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Hip{\'{o}}lito et al.{\_}2020{\_}Markov blankets in the brain.pdf:pdf},
journal = {arXiv},
keywords = {Boundaries,Canonical microcircuit,Dynamic causal modelling,Markov blankets},
pages = {1--25},
title = {{Markov blankets in the brain}},
year = {2020}
}
@article{Botvinick2012,
abstract = {Recent developments in decision-making research are bringing the topic of planning back to center stage in cognitive science. This renewed interest reopens an old, but still unanswered question: how exactly does planning happen? What are the underlying information processing operations and how are they implemented in the brain? Although a range of interesting possibilities exists, recent work has introduced a potentially transformative new idea, according to which planning is accomplished through probabilistic inference. {\textcopyright} 2012.},
author = {Botvinick, Matthew and Toussaint, Marc},
doi = {10.1016/j.tics.2012.08.006},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Botvinick, Toussaint{\_}2012{\_}Planning as inference.pdf:pdf},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
number = {10},
pages = {485--488},
pmid = {22940577},
title = {{Planning as inference}},
volume = {16},
year = {2012}
}
@article{Hopfield1994a,
author = {Hopfield, John J.},
doi = {10.1126/science.263.5147.696},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Hopfield{\_}1994{\_}An Envisioning of Consciousness.pdf:pdf},
issn = {0036-8075},
journal = {Science},
month = {feb},
number = {5147},
pages = {696--696},
title = {{An Envisioning of Consciousness}},
url = {https://www.sciencemag.org/lookup/doi/10.1126/science.263.5147.696},
volume = {263},
year = {1994}
}
@article{FitzGerald2014,
abstract = {Postulating that the brain performs approximate Bayesian inference generates principled and empirically testable models of neuronal function-the subject of much current interest in neuroscience and related disciplines. Current formulations address inference and learning under some assumed and particular model. In reality, organisms are often faced with an additional challenge-that of determining which model or models of their environment are the best for guiding behavior. Bayesian model averaging-which says that an agent should weight the predictions of different models according to their evidence-provides a principled way to solve this problem. Importantly, because model evidence is determined by both the accuracy and complexity of the model, optimal inference requires that these be traded off against one another. This means an agent's behavior should show an equivalent balance. We hypothesize that Bayesian model averaging plays an important role in cognition, given that it is both optimal and realizable within a plausible neuronal architecture. We outline model averaging and how it might be implemented, and then explore a number of implications for brain and behavior. In particular, we propose that model averaging can explain a number of apparently suboptimal phenomena within the framework of approximate (bounded) Bayesian inference, focusing particularly upon the relationship between goal-directed and habitual behavior. {\textcopyright} 2014 FitzGerald, Dolan and Friston.},
author = {FitzGerald, Thomas and Dolan, Raymond J. and Friston, Karl J.},
doi = {10.3389/fnhum.2014.00457},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/FitzGerald, Dolan, Friston{\_}2014{\_}Model averaging, optimal inference, and habit formation.pdf:pdf},
issn = {16625161},
journal = {Frontiers in Human Neuroscience},
keywords = {Active inference,Bayesian inference,Habit,Interference effect,Predictive coding},
number = {JUNE},
pages = {1--11},
title = {{Model averaging, optimal inference, and habit formation}},
volume = {8},
year = {2014}
}
@article{Heins2020,
author = {Heins, R. Conor and Mirza, M. Berk and Parr, Thomas and Friston, Karl and Kagan, Igor and Pooresmaeili, Arezoo},
doi = {10.3389/frai.2020.509354},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Heins et al.{\_}2020{\_}Deep Active Inference and Scene Construction.pdf:pdf},
issn = {2624-8212},
journal = {Frontiers in Artificial Intelligence},
keywords = {Bayesian brain,active inference,bayesian brain,epistemic value,free energy,hierarchical inference,random dot motion,visual foraging},
month = {oct},
number = {October},
title = {{Deep Active Inference and Scene Construction}},
url = {https://www.frontiersin.org/articles/10.3389/frai.2020.509354/full},
volume = {3},
year = {2020}
}
@article{Bastos2012,
abstract = {This review considers the influential notion of a canonical (cortical) microcircuit in light of recent theories about neuronal processing. Specifically, we conciliate quantitative studies of microcircuitry and the functional logic of neuronal computations. We revisit the established idea that message passing among hierarchical cortical areas implements a form of Bayesian inference – paying careful attention to the implications for intrinsic connections among neuronal populations. By deriving canonical forms for these computations, one can associate specific neuronal populations with specific computational roles. This analysis discloses a remarkable correspondence between the microcircuitry of the cortical column and the connectivity implied by predictive coding. Furthermore, it provides some intuitive insights into the functional asymmetries between feedforward and feedback connections and the characteristic frequencies over which they operate.},
author = {Bastos, Andr{\'{e}} M. and Usrey, W. Martin and Adams, Rick A. and Mangun, George R. and Fries, Pascal and Friston, Karl J.},
doi = {10.1016/j.neuron.2012.10.038},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Bastos et al.{\_}2012{\_}Canonical Microcircuits for Predictive Coding.pdf:pdf;:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Bastos et al.{\_}2012{\_}Canonical Microcircuits for Predictive Coding(2).pdf:pdf},
issn = {08966273},
journal = {Neuron},
keywords = {beta oscillations,computation,connectivity,cortical,free energy,gamma oscillations,microcircuit,neuronal,predictive coding,principle},
month = {nov},
number = {4},
pages = {695--711},
pmid = {23177956},
publisher = {Elsevier Inc.},
title = {{Canonical Microcircuits for Predictive Coding}},
url = {http://dx.doi.org/10.1016/j.neuron.2012.10.038 http://www.ncbi.nlm.nih.gov/pubmed/23177956 https://linkinghub.elsevier.com/retrieve/pii/S0896627312009592},
volume = {76},
year = {2012}
}
@article{Fraccaro2017,
abstract = {This paper takes a step towards temporal reasoning in a dynamically changing video, not in the pixel space that constitutes its frames, but in a latent space that describes the non-linear dynamics of the objects in its world. We introduce the Kalman variational auto-encoder, a framework for unsupervised learning of sequential data that disentangles two latent representations: an object's representation, coming from a recognition model, and a latent state describing its dynamics. As a result, the evolution of the world can be imagined and missing data imputed, both without the need to generate high dimensional frames at each time step. The model is trained end-to-end on videos of a variety of simulated physical systems, and outperforms competing methods in generative and missing data imputation tasks.},
archivePrefix = {arXiv},
arxivId = {1710.05741},
author = {Fraccaro, Marco and Kamronn, Simon and Paquet, Ulrich and Winther, Ole},
eprint = {1710.05741},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Fraccaro et al.{\_}2017{\_}A Disentangled Recognition and Nonlinear Dynamics Model for Unsupervised Learning.pdf:pdf},
month = {oct},
number = {section 5},
title = {{A Disentangled Recognition and Nonlinear Dynamics Model for Unsupervised Learning}},
url = {http://arxiv.org/abs/1710.05741},
year = {2017}
}
@article{Hope1752a,
abstract = {Intracellular pH, ratios of phosphocreatine (PCr) to ATP and PCr to inorganic phosphate (Pi) as well as isometric tension were measured during 1 Hz sciatic nerve stimulation and during recovery in the calf muscles of mdx (a model of Duchenne muscular dystrophy) and control mice. Tension did not decline significantly in either strain. The ratio of PCr/(PCr + Pi) was significantly reduced in mdx as against control muscle during exercise and recovery, but the ratio of PCr/ATP and the half-time for PCr recovery were similar in both strains. A reduction in the maximal activities of succinate dehydrogenase and succinate- cytochrome c reductase suggests that mitochondrial metabolism may be impaired. The similarity in PCr recovery times suggests that the muscle has adapted, making any impairment of oxidative metabolism negligible in the intact system. The rate of pH recovery is prolonged in mdx muscle and provides strong evidence for a decline in the capacity of dystrophic muscle to extrude proton equivalents. These data are compared with a previous study which used 10 Hz stimulation and also observed a slow pH recovery. The slow pH recovery could be explained by an elevation in intracellular sodium.},
author = {Hope, Thomas},
doi = {10.1098/rspb.1993.0125},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Hope{\_}1993{\_}Principal component analysis learning algorithms a neurobiological analysis.pdf:pdf},
issn = {0962-8452},
journal = {Proceedings of the Royal Society of London. Series B: Biological Sciences},
month = {oct},
number = {1339},
pages = {47--54},
title = {{Principal component analysis learning algorithms: a neurobiological analysis}},
url = {https://royalsocietypublishing.org/doi/10.1098/rspb.1993.0125},
volume = {254},
year = {1993}
}
@article{Catal2019,
abstract = {Learning to take actions based on observations is a core requirement for artificial agents to be able to be successful and robust at their task. Reinforcement Learning (RL) is a well-known technique for learning such policies. However, current RL algorithms often have to deal with reward shaping, have difficulties generalizing to other environments and are most often sample inefficient. In this paper, we explore active inference and the free energy principle, a normative theory from neuroscience that explains how self-organizing biological systems operate by maintaining a model of the world and casting action selection as an inference problem. We apply this concept to a typical problem known to the RL community, the mountain car problem, and show how active inference encompasses both RL and learning from demonstrations.},
archivePrefix = {arXiv},
arxivId = {1904.08149},
author = {{\c{C}}atal, Ozan and Nauta, Johannes and Verbelen, Tim and Simoens, Pieter and Dhoedt, Bart},
eprint = {1904.08149},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/{\c{C}}atal et al.{\_}2019{\_}Bayesian policy selection Using active inference.pdf:pdf},
issn = {23318422},
journal = {arXiv},
pages = {1--9},
title = {{Bayesian policy selection Using active inference}},
year = {2019}
}
@article{Slonim2000,
abstract = {We introduce a novel distributional clustering algorithm that maximizes the mutual information per cluster between data and given categories. This algorithm can be considered as a bottom up hard version of the recently introduced "Information Bottleneck Method ". The algorithm is compared with the top-down soft version of the information bottleneck method and a relationship between the hard and soft results is established. We demonstrate the algorithm on the 20 Newsgroups data set. For a subset of two newsgroups we achieve compression by 3 orders of magnitudes loosing only 10{\%} of the original mutual information.},
author = {Slonim, Noam and Tishby, Naftali},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Slonim, Tishby{\_}2000{\_}Agglomerative information bottleneck.pdf:pdf},
isbn = {0262194503},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
pages = {617--623},
title = {{Agglomerative information bottleneck}},
year = {2000}
}
@article{Efron1973a,
author = {Efron, Bradley and Morris, Carl},
doi = {10.1080/01621459.1973.10481350},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Efron, Morris{\_}1973{\_}Stein's Estimation Rule and its Competitors—An Empirical Bayes Approach.pdf:pdf},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
month = {mar},
number = {341},
pages = {117--130},
title = {{Stein's Estimation Rule and its Competitors—An Empirical Bayes Approach}},
url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1973.10481350},
volume = {68},
year = {1973}
}
@article{Friston2006a,
abstract = {This note derives the variational free energy under the Laplace approximation, with a focus on accounting for additional model complexity induced by increasing the number of model parameters. This is relevant when using the free energy as an approximation to the log-evidence in Bayesian model averaging and selection. By setting restricted maximum likelihood (ReML) in the larger context of variational learning and expectation maximisation (EM), we show how the ReML objective function can be adjusted to provide an approximation to the log-evidence for a particular model. This means ReML can be used for model selection, specifically to select or compare models with different covariance components. This is useful in the context of hierarchical models because it enables a principled selection of priors that, under simple hyperpriors, can be used for automatic model selection and relevance determination (ARD). Deriving the ReML objective function, from basic variational principles, discloses the simple relationships among Variational Bayes, EM and ReML. Furthermore, we show that EM is formally identical to a full variational treatment when the precisions are linear in the hyperparameters. Finally, we also consider, briefly, dynamic models and how these inform the regularisation of free energy ascent schemes, like EM and ReML. {\textcopyright} 2006 Elsevier Inc. All rights reserved.},
author = {Friston, Karl J. and Mattout, J{\'{e}}r{\'{e}}mie and Trujillo-Barreto, Nelson and Ashburner, John and Penny, W. D.},
doi = {10.1016/j.neuroimage.2006.08.035},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston et al.{\_}2006{\_}Variational free energy and the Laplace approximation.pdf:pdf},
issn = {10538119},
journal = {NeuroImage},
keywords = {Automatic relevance determination,Expectation maximisation,Free energy,Model selection,Relevance vector machines,Restricted maximum likelihood,Variational Bayes},
number = {1},
pages = {220--234},
pmid = {17055746},
title = {{Variational free energy and the Laplace approximation}},
volume = {34},
year = {2006}
}
@article{Friston2010b,
abstract = {We have previously tried to explain perceptual inference and learning under a free-energy principle that pursues Helmholtz's agenda to understand the brain in terms of energy minimization. It is fairly easy to show that making inferences about the causes of sensory data can be cast as the minimization of a free-energy bound on the likelihood of sensory inputs, given an internal model of how they were caused. In this article, we consider what would happen if the data themselves were sampled to minimize this bound. It transpires that the ensuing active sampling or inference is mandated by ergodic arguments based on the very existence of adaptive agents. Furthermore, it accounts for many aspects of motor behavior; from retinal stabilization to goal-seeking. In particular, it suggests that motor control can be understood as fulfilling prior expectations about proprioceptive sensations. This formulation can explain why adaptive behavior emerges in biological agents and suggests a simple alternative to optimal control theory. We illustrate these points using simulations of oculomotor control and then apply to same principles to cued and goal-directed movements. In short, the free-energy formulation may provide an alternative perspective on the motor control that places it in an intimate relationship with perception. {\textcopyright} 2010 Springer-Verlag.},
author = {Friston, Karl J and Daunizeau, Jean and Kilner, James and Kiebel, Stefan J},
doi = {10.1007/s00422-010-0364-z},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston et al.{\_}2010{\_}Action and behavior A free-energy formulation(2).pdf:pdf},
issn = {03401200},
journal = {Biological Cybernetics},
keywords = {Bayesian,Computational,Control,Hierarchical,Motor,Priors},
number = {3},
pages = {227--260},
pmid = {20148260},
title = {{Action and behavior: A free-energy formulation}},
volume = {102},
year = {2010}
}
@article{Gagliano2015,
abstract = {Language is often considered a key feature of being human, and human linguistic behavior has been adopted as the universal template for studying the nature of language and its evolution. Yet it is not always clear what "language" actually is, and the lack of definition calls into question the notion that human language is unique because it has no equivalent in any nonhuman species. We ask whether the use of language is truly an activity, a form of behavior, which makes us so unique and unlike other species. We tackle this question by examining language from an ecological perspective and then considering language from a wider biological viewpoint, one that enables us to explore language as a meaning-making activity at the core of every form of life, including plants. We examine how innovative philosophical thinking and scientific research similarly call into question the current limits of language in describing the botanical world and human-plant dynamics. By providing an overview of the most recent empirically grounded advances in our understanding of the "language" of others, and particularly plants, we propose that the nonhuman world is not lacking in language the way we think it is. Ultimately, the overall aim is to invite the emergence of a new truly interdisciplinary dialogue to inspire novel approaches in further philosophical and scientific investigations, where language and its power are re-focused toward conceptualizing a more integrated perception of the world.},
author = {Gagliano, Monica and Grimonprez, Mavra},
doi = {10.1089/eco.2015.0023},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Gagliano, Grimonprez{\_}2015{\_}Breaking the Silence - Language and the Making of Meaning in Plants.pdf:pdf},
issn = {19429347},
journal = {Ecopsychology},
keywords = {Adaptive behavior,Communication,Embodied cognition,Plant thinking},
number = {3},
pages = {145--152},
title = {{Breaking the Silence - Language and the Making of Meaning in Plants}},
volume = {7},
year = {2015}
}
@article{Gregor2015,
abstract = {This paper introduces the Deep Recurrent Attentive Writer (DRAW) neural network architecture for image generation. DRAW networks combine a novel spatial attention mechanism that mimics the foveation of the human eye, with a sequential variational auto-encoding framework that allows for the iterative construction of complex images. The system substantially improves on the state of the art for generative models on MNIST, and, when trained on the Street View House Numbers dataset, it generates images that cannot be distinguished from real data with the naked eye.},
archivePrefix = {arXiv},
arxivId = {1502.04623},
author = {Gregor, Karol and Danihelka, Ivo and Graves, Alex and Rezende, Danilo Jimenez and Wierstra, Daan},
eprint = {1502.04623},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Gregor et al.{\_}2015{\_}DRAW A recurrent neural network for image generation.pdf:pdf},
isbn = {9781510810587},
journal = {32nd International Conference on Machine Learning, ICML 2015},
pages = {1462--1471},
title = {{DRAW: A recurrent neural network for image generation}},
volume = {2},
year = {2015}
}
@article{Friston1997b,
abstract = {This paper is about neuronal dynamics and how their special complexity can be understood in terms of nonlinear dynamics. There are many aspects of neuronal interactions and connectivity that engender the complexity of brain dynamics. In this paper we consider (i) the nature of this complexity and (ii) how it depends on connections between neuronal systems (e.g., neuronal populations or cortical areas). The main conclusion is that simulated neural systems show complex behaviors, reminiscent of neuronal dynamics, when these extrinsic connections are sparse. The patterns of activity that obtain, under these conditions, show a rich form of intermittency with the recurrent and self-limiting expression of stereotyped transient-like dynamics. Despite the fact that these dynamics conform to a single (complex) attractor this metastability gives the illusion of a dynamically changing attractor manifold (i.e., a changing surface upon which the dynamics unfold). This metastability is characterized using a measure that is based on the entropy of the time series' spectral density.},
author = {Friston, Karl J.},
doi = {10.1006/nimg.1997.0259},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston{\_}1997{\_}Transients, metastability, and neuronal dynamics.pdf:pdf},
issn = {10538119},
journal = {NeuroImage},
number = {2},
pages = {164--171},
pmid = {9345546},
title = {{Transients, metastability, and neuronal dynamics}},
volume = {5},
year = {1997}
}
@incollection{Pritchard2014,
abstract = {Justification theory in epistemology specifies the conditions under which a belief is justified. Epistemic realism as applied to justification theory is the view that our actual epistemic practices yield justified beliefs about the world. By appealing to cross-Cultural research by psychologists and others, I argue for a version of realism. Once we endorse a version of realism, We see the necessity to naturalize epistemology.},
author = {Pritchard, Duncan},
booktitle = {Virtue Epistemology Naturalized},
doi = {10.1007/978-3-319-04672-3},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Pritchard{\_}2014{\_}Knowledge and Understanding.pdf:pdf},
isbn = {9783319046716},
pages = {315--328},
title = {{Knowledge and Understanding}},
year = {2014}
}
@misc{Ozaki1992,
abstract = {In the present paper we point out a close relationship between nonlinear time series models and nonlinear stochastic dynamical systems. We introduce a time discretization method of stochastic dynamical systems, which brings us a nonlinear time series model from a nonlinear stochastic dynamical system. Then a maximum likelihood method for the estimation of the time series model is given. We also give an identification procedure of the original continuous time dynamical system. The effectiveness of the procedure is numerically checked using simulated data. Implications of the present method in non-Gaussian time series analysis are discussed.},
author = {Ozaki, Tohru},
booktitle = {Statistica Sinica},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Ozaki{\_}1992{\_}A bridge between nonlinear time series models and nonlinear stochastic dynamical systems A local linearization approach.pdf:pdf},
pages = {113--135},
title = {{A bridge between nonlinear time series models and nonlinear stochastic dynamical systems: A local linearization approach}},
volume = {2},
year = {1992}
}
@article{odena2016,
author = {Odena, Augustus and Dumoulin, Vincent and Olah, Chris},
doi = {10.23915/distill.00003},
journal = {Distill},
title = {{Deconvolution and Checkerboard Artifacts}},
url = {http://distill.pub/2016/deconv-checkerboard},
year = {2016}
}
@article{DaCosta2020,
abstract = {Active inference is a normative principle underwriting perception, action, planning, decision-making and learning in biological or artificial agents. From its inception, its associated process theory has grown to incorporate complex generative models, enabling simulation of a wide range of complex behaviours. Due to successive developments in active inference, it is often difficult to see how its underlying principle relates to process theories and practical implementation. In this paper, we try to bridge this gap by providing a complete mathematical synthesis of active inference on discrete state-space models. This technical summary provides an overview of the theory, derives neuronal dynamics from first principles and relates this dynamics to biological processes. Furthermore, this paper provides a fundamental building block needed to understand active inference for mixed generative models; allowing continuous sensations to inform discrete representations. This paper may be used as follows: to guide research towards outstanding challenges, a practical guide on how to implement active inference to simulate experimental behaviour, or a pointer towards various in-silico neurophysiological responses that may be used to make empirical predictions.},
archivePrefix = {arXiv},
arxivId = {2001.07203},
author = {{Da Costa}, Lancelot and Parr, Thomas and Sajid, Noor and Veselic, Sebastijan and Neacsu, Victorita and Friston, Karl},
doi = {10.1016/j.jmp.2020.102447},
eprint = {2001.07203},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Da Costa et al.{\_}2020{\_}Active inference on discrete state-spaces A synthesis.pdf:pdf},
issn = {10960880},
journal = {Journal of Mathematical Psychology},
keywords = {Active inference,Free energy principle,Markov decision process,Mathematical review,Process theory,Variational Bayesian inference},
pages = {102447},
publisher = {Elsevier Inc.},
title = {{Active inference on discrete state-spaces: A synthesis}},
url = {https://doi.org/10.1016/j.jmp.2020.102447},
volume = {99},
year = {2020}
}
@article{Simpson2015,
abstract = {Inspired by the brain, deep neural networks (DNN) are thought to learn abstract representations through their hierarchical architecture. However, at present, how this happens is not well understood. Here, we demonstrate that DNN learn abstract representations by a process of demodulation. We introduce a biased sigmoid activation function and use it to show that DNN learn and perform better when optimized for demodulation. Our findings constitute the first unambiguous evidence that DNN perform abstract learning in practical use. Our findings may also explain abstract learning in the human brain.},
archivePrefix = {arXiv},
arxivId = {1502.04042},
author = {Simpson, Andrew J. R.},
eprint = {1502.04042},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Simpson{\_}2015{\_}Abstract Learning via Demodulation in a Deep Neural Network.pdf:pdf},
month = {feb},
number = {3},
pages = {1--3},
title = {{Abstract Learning via Demodulation in a Deep Neural Network}},
url = {http://arxiv.org/abs/1502.03648 http://arxiv.org/abs/1502.04042},
volume = {10},
year = {2015}
}
@article{Meyer1991,
author = {Meyer, Tobias},
doi = {10.1016/0092-8674(91)90496-L},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Meyer{\_}1991{\_}Cell signalling by second messenger waves.pdf:pdf},
issn = {00928674},
journal = {Cell},
number = {4},
pages = {675--678},
title = {{Cell signalling by second messenger waves}},
volume = {64},
year = {1991}
}
@article{Srivastava2015,
abstract = {We use Long Short Term Memory (LSTM) networks to learn representations of video sequences. Our model uses an encoder LSTM to map an input sequence into a fixed length representation. This representation is decoded using single or multiple decoder LSTMs to perform different tasks, such as reconstructing the input sequence, or predicting the future sequence. We experiment with two kinds of input sequences-patches of image pixels and high-level representations ("percepts") of video frames extracted using a pretrained convolutional net. We explore different design choices such as whether the decoder LSTMs should condition on the generated output. We analyze the outputs of the model qualitatively to see how well the model can extrapolate the learned video representation into the future and into the past. We further evaluate the representations by finetuning them for a supervised learning problem-human action recognition on the UCF-101 and HMDB-51 datasets. We show that the representations help improve classification accuracy, especially when there are only few training examples. Even models pretrained on unrelated datasets (300 hours of YouTube videos) can help action recognition performance.},
archivePrefix = {arXiv},
arxivId = {1502.04681},
author = {Srivastava, Nitish and Mansimov, Elman and Salakhutdinov, Ruslan},
eprint = {1502.04681},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Srivastava, Mansimov, Salakhutdinov{\_}2015{\_}Unsupervised learning of video representations using LSTMs.pdf:pdf},
isbn = {9781510810587},
journal = {32nd International Conference on Machine Learning, ICML 2015},
pages = {843--852},
title = {{Unsupervised learning of video representations using LSTMs}},
volume = {1},
year = {2015}
}
@article{Szostak2016,
author = {Szostak, Natalia and Wasik, Szymon and Blazewicz, Jacek},
doi = {10.1371/journal.pcbi.1004853},
editor = {Wodak, Shoshana},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Szostak, Wasik, Blazewicz{\_}2016{\_}Hypercycle.PDF:PDF},
issn = {1553-7358},
journal = {PLOS Computational Biology},
month = {apr},
number = {4},
pages = {e1004853},
pmid = {27054759},
title = {{Hypercycle}},
url = {https://dx.plos.org/10.1371/journal.pcbi.1004853},
volume = {12},
year = {2016}
}
@article{Friston2008b,
abstract = {This note presents a simple Bayesian filtering scheme, using variational calculus, for inference on the hidden states of dynamic systems. Variational filtering is a stochastic scheme that propagates particles over a changing variational energy landscape, such that their sample density approximates the conditional density of hidden and states and inputs. The key innovation, on which variational filtering rests, is a formulation in generalised coordinates of motion. This renders the scheme much simpler and more versatile than existing approaches, such as those based on particle filtering. We demonstrate variational filtering using simulated and real data from hemodynamic systems studied in neuroimaging and provide comparative evaluations using particle filtering and the fixed-form homologue of variational filtering, namely dynamic expectation maximisation. {\textcopyright} 2008 Elsevier Inc. All rights reserved.},
author = {Friston, Karl J.},
doi = {10.1016/j.neuroimage.2008.03.017},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston{\_}2008{\_}Variational filtering.pdf:pdf},
issn = {10538119},
journal = {NeuroImage},
keywords = {Action,Bayesian filtering,Dynamic expectation maximisation,Dynamical systems,Free-energy,Generalised coordinates,Nonlinear,Variational Bayes,Variational filtering},
number = {3},
pages = {747--766},
pmid = {18450479},
title = {{Variational filtering}},
volume = {41},
year = {2008}
}
@article{Salimans2017,
abstract = {PixelCNNs are a recently proposed class of powerful generative models with tractable likelihood. Here we discuss our implementation of PixelCNNs which we make available at https://github.com/openai/pixel-cnn. Our implementation contains a number of modifications to the original model that both simplify its structure and improve its performance. 1) We use a discretized logistic mixture likelihood on the pixels, rather than a 256-way softmax, which we find to speed up training. 2) We condition on whole pixels, rather than R/G/B sub-pixels, simplifying the model structure. 3) We use downsampling to efficiently capture structure at multiple resolutions. 4) We introduce additional short-cut connections to further speed up optimization. 5) We regularize the model using dropout. Finally, we present state-of-the-art log likelihood results on CIFAR-10 to demonstrate the usefulness of these modifications.},
archivePrefix = {arXiv},
arxivId = {1701.05517},
author = {Salimans, Tim and Karpathy, Andrej and Chen, Xi and Kingma, Diederik P.},
eprint = {1701.05517},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Salimans et al.{\_}2017{\_}Pixelcnn Improving the pixelcnn with discretized logistic mixture likelihood and other modifications.pdf:pdf},
journal = {arXiv},
pages = {1--10},
title = {{Pixelcnn++: Improving the pixelcnn with discretized logistic mixture likelihood and other modifications}},
year = {2017}
}
@article{Dayan1995,
abstract = {Discovering the structure inherent in a set of patterns is a fundamental aim of statistical inference or learning. One fruitful approach is to build a parameterized stochastic generative model, independent draws from which are likely to produce the patterns. For all but the simplest generative models, each pattern can be generated in exponentially many ways. It is thus intractable to adjust the parameters to maximize the probability of the observed patterns. We describe a way of finessing this combinatorial explosion by maximizing an easily computed lower bound on the probability of the observations. Our method can be viewed as a form of hierarchical self-supervised learning that may relate to the function of bottom-up and top-down cortical processing pathways.},
author = {Dayan, Peter and Hinton, Geoffrey E and Neal, Radford M and Zemel, Richard S},
doi = {10.1162/neco.1995.7.5.889},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Dayan et al.{\_}1995{\_}The Helmholtz machine.pdf:pdf},
issn = {08997667},
journal = {Neural computation},
number = {5},
pages = {889--904},
pmid = {7584891},
title = {{The Helmholtz machine}},
volume = {7},
year = {1995}
}
@article{Chen2014,
abstract = {Dendritic spines are ubiquitous postsynaptic sites of most excitatory synapses in the mammalian brain, and thus may serve as structural indicators of functional synapses. Recent works have suggested that neuronal coding of memories may be associated with rapid alterations in spine formation and elimination. Technological advances have enabled researchers to study spine dynamics in vivo during development as well as under various physiological and pathological conditions. We believe that better understanding of the spatiotemporal patterns of spine dynamics will help elucidate the principles of experience-dependent circuit modification and information processing in the living brain. {\textcopyright} 2014 Chen, Lu and Zuo.},
author = {Chen, Chia Chien and Lu, Ju and Zuo, Yi},
doi = {10.3389/fnana.2014.00028},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Chen, Lu, Zuo{\_}2014{\_}Spatiotemporal dynamics of dendritic spines in the living brain.pdf:pdf},
issn = {16625129},
journal = {Frontiers in Neuroanatomy},
keywords = {Cerebral cortex,Dendritic spine,Experience-dependent plasticity,In vivo,Neural circuit,Two-photon imaging},
number = {MAY},
pages = {1--7},
title = {{Spatiotemporal dynamics of dendritic spines in the living brain}},
volume = {8},
year = {2014}
}
@incollection{Russel2010,
abstract = {In this third edition, the authors have updated the treatment of all major areas. A new organizing principle--the representational dimension of atomic, factored, and structured models--has been added. Significant new material has been provided in areas such as partially observable search, contingency planning, hierarchical planning, relational and first-order probability models, regularization and loss functions in machine learning, kernel methods, Web search engines, information extraction, and learning in vision and robotics. The book also includes hundreds of new exercises.},
author = {Russel, Stuart and Norvig, Peter},
booktitle = {Artificial Intelligence: a Modern Approach},
chapter = {2},
edition = {3rd},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Russel, Norvig{\_}2010{\_}Intelligent Agents.pdf:pdf},
isbn = {9780136042594},
number = {1},
pages = {34--63},
publisher = {Upper Saddle River, NJ : Prentice Hall},
title = {{Intelligent Agents}},
volume = {4},
year = {2010}
}
@article{Sajid2019,
abstract = {Active inference is a first principle account of how autonomous agents operate in dynamic, non-stationary environments. This problem is also considered in reinforcement learning, but limited work exists on comparing the two approaches on the same discrete-state environments. In this paper, we provide: 1) an accessible overview of the discrete-state formulation of active inference, highlighting natural behaviors in active inference that are generally engineered in reinforcement learning; 2) to our knowledge, the first explicit discrete-state comparison between active inference and reinforcement learning on an OpenAI gym baseline. We begin by providing a condensed overview of the active inference literature, in particular viewing the various natural behaviors of active inference agents through the lens of reinforcement learning. We show that by operating in a pure belief-based setting, active inference agents can carry out epistemic exploration - and account for uncertainty about their environment - in a Bayes optimal fashion. We make these properties explicit by showing that the active inference agent's ability to carry out online planning, in a pure-belief setting, enables it to act optimally, given the non-stationary dynamics of an environment when compared to both Q-learning and Bayesian model-based reinforcement learning agents. We conclude by noting that this formalism can be applied to more complex settings; e.g., robotic arm movement, Atari games, etc., if appropriate generative models can be formulated. In short, we aim to demystify the behavior of active inference agents by presenting an accessible discrete state-space and time formulation, and demonstrate these behaviors in a OpenAI gym environment, alongside reinforcement learning agents.},
archivePrefix = {arXiv},
arxivId = {1909.10863},
author = {Sajid, Noor and Ball, Philip J. and Friston, Karl J.},
eprint = {1909.10863},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Sajid, Ball, Friston{\_}2019{\_}Active inference demystified and compared.pdf:pdf},
number = {0},
pages = {1--69},
title = {{Active inference: demystified and compared}},
volume = {44},
year = {2019}
}
@article{Friston2009c,
abstract = {This paper summarizes our recent attempts to integrate action and perception within a single optimization framework. We start with a statistical formulation of Helmholtz's ideas about neural energy to furnish a model of perceptual inference and learning that can explain a remarkable range of neurobiological facts. Using constructs from statistical physics it can be shown that the problems of inferring the causes of our sensory inputs and learning regularities in the sensorium can be resolved using exactly the same principles. Furthermore, inference and learning can proceed in a biologically plausible fashion. The ensuing scheme rests on Empirical Bayes and hierarchical models of how sensory information is generated. The use of hierarchical models enables the brain to construct prior expectations in a dynamic and context-sensitive fashion. This scheme provides a principled way to understand many aspects of the brain's organization and responses. We will demonstrate the brain-like dynamics that this scheme entails by using models of birdsongs that are based on chaotic attractors with autonomous dynamics. This provides a nice example of how non-linear dynamics can be exploited by the brain to represent and predict dynamics in the environment.},
author = {Friston, Karl J. and Kiebel, Stefan J.},
doi = {10.1142/s1793005709001209},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston, Kiebel{\_}2009{\_}Attractors in Song.pdf:pdf},
issn = {1793-0057},
journal = {New Mathematics and Natural Computation},
keywords = {birdsong,dynamic,generative models,hierarchical,nonlinear,predictive coding,variational},
number = {01},
pages = {83--114},
title = {{Attractors in Song}},
volume = {05},
year = {2009}
}
@article{Friston2015a,
abstract = {Hermeneutics refers to interpretation and translation of text (typically ancient scriptures) but also applies to verbal and non-verbal communication. In a psychological setting it nicely frames the problem of inferring the intended content of a communication. In this paper, we offer a solution to the problem of neural hermeneutics based upon active inference. In active inference, action fulfils predictions about how we will behave (e.g., predicting we will speak). Crucially, these predictions can be used to predict both self and others - during speaking and listening respectively. Active inference mandates the suppression of prediction errors by updating an internal model that generates predictions - both at fast timescales (through perceptual inference) and slower timescales (through perceptual learning). If two agents adopt the same model, then - in principle - they can predict each other and minimise their mutual prediction errors. Heuristically, this ensures they are singing from the same hymn sheet. This paper builds upon recent work on active inference and communication to illustrate perceptual learning using simulated birdsongs. Our focus here is the neural hermeneutics implicit in learning, where communication facilitates long-term changes in generative models that are trying to predict each other. In other words, communication induces perceptual learning and enables others to (literally) change our minds and vice versa.},
author = {Friston, Karl J. and Frith, Christopher D.},
doi = {10.1016/j.cortex.2015.03.025},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston, Frith{\_}2015{\_}Active inference, Communication and hermeneutics.pdf:pdf},
issn = {19738102},
journal = {Cortex},
keywords = {Active inference,Bayesian,Communication,Hermeneutics,Neuronal,Predictive coding,Synchronisation of chaos,Theory of mind},
number = {Kelso 2012},
pages = {129--143},
pmid = {25957007},
publisher = {Elsevier Ltd},
title = {{Active inference, Communication and hermeneutics}},
url = {http://dx.doi.org/10.1016/j.cortex.2015.03.025},
volume = {68},
year = {2015}
}
@article{Hopfield2003,
abstract = {This article demonstrates how that the effectiveness of nervous system in doing the computations essential to an organism can be based on using algorithms that are readily implemented by nervous system 'device biophysics'. Collective effects and collective algorithms that exploit their dynamics provide powerful potential for useful neuronal computations. {\textcopyright} 2003 Acad{\'{e}}mie des sciences/{\'{E}}ditions scientifiques et m{\'{e}}dicales Elsevier SAS. All rights reserved.},
author = {Hopfield, John J. and Brody, Carlos D.},
doi = {10.1016/S1631-0691(03)00017-9},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Hopfield, Brody{\_}2003{\_}Separating objects and 'neural' computation.pdf:pdf},
issn = {16310691},
journal = {Comptes Rendus - Biologies},
keywords = {Neural computation,Object definition},
number = {2},
pages = {219--222},
title = {{Separating objects and 'neural' computation}},
volume = {326},
year = {2003}
}
@article{Friston2017a,
abstract = {This article describes a process theory based on active inference and belief propagation. Starting from the premise that all neuronal processing (and action selection) can be explained by maximizing Bayesian model evidence—or minimizing variational free energy—we ask whether neuronal responses can be described as a gradient descent on variational free energy. Using a standard (Markov decision process) generative model, we derive the neuronal dynamics implicit in this description and reproduce a remarkable range of well-characterized neuronal phenomena. These include repetition suppression, mismatch negativity, violation responses, place-cell activity, phase precession, theta sequences, theta-gamma coupling, evidence accumulation, race-to-bound dynamics, and transfer of dopamine responses. Furthermore, the (approximately Bayes' optimal) behavior prescribed by these dynamics has a degree of face validity, providing a formal explanation for reward seeking, context learning, and epistemic foraging. Technically, the fact that a gradient descent appears to be a valid description of neuronal activity means that variational free energy is a Lyapunov function for neuronal dynamics, which therefore conform to Hamilton's principle of least action.},
archivePrefix = {arXiv},
arxivId = {1803.01446},
author = {Friston, Karl and FitzGerald, Thomas and Rigoli, Francesco and Schwartenbeck, Philipp and Pezzulo, Giovanni},
doi = {10.1162/NECO_a_00912},
eprint = {1803.01446},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston et al.{\_}2017{\_}Active Inference A Process Theory.pdf:pdf},
issn = {0899-7667},
journal = {Neural Computation},
month = {jan},
number = {1},
pages = {1--49},
title = {{Active Inference: A Process Theory}},
url = {http://arxiv.org/abs/1803.01446 https://www.mitpressjournals.org/doi/abs/10.1162/NECO{\_}a{\_}00912},
volume = {29},
year = {2017}
}
@article{Friston2012c,
abstract = {This paper describes a variational free-energy formulation of (partially observable) Markov decision problems in decision making under uncertainty. We show that optimal control can be cast as active inference. In active inference, both action and posterior beliefs about hidden states minimise a free energy bound on the negative log-likelihood of observed states, under a generative model. In this setting, reward or cost functions are absorbed into prior beliefs about state transitions and terminal states. Effectively, this converts optimal control into a pure inference problem, enabling the application of standard Bayesian filtering techniques.We then consider optimal trajectories that rest on posterior beliefs about hidden states in the future. Crucially, this entails modelling control as a hidden state that endows the generative model with a representation of agency. This leads to a distinction between models with and without inference on hidden control states; namely, agency-free and agency-based models, respectively. {\textcopyright} Springer-Verlag 2012.},
author = {Friston, Karl J. and Samothrakis, Spyridon and Montague, Read},
doi = {10.1007/s00422-012-0512-8},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston, Samothrakis, Montague{\_}2012{\_}Active inference and agency Optimal control without cost functions.pdf:pdf},
issn = {03401200},
journal = {Biological Cybernetics},
keywords = {Action,Agency,Bayesian,Free energy,Inference,Optimal control,Partially observable Markov decision processes},
number = {8-9},
pages = {523--541},
pmid = {22864468},
title = {{Active inference and agency: Optimal control without cost functions}},
volume = {106},
year = {2012}
}
@article{Dempster1977,
abstract = {A series solution of the general three-dimensional equations of linear elasticity is used to find accurate natural frequencies and mode shapes for the flexural vibrations of thick free circular plates. The approximate solution for thick plates, which includes shear and rotary inertia effects, is compared with the accurate series solution. It is found that the approximate solution yields frequencies of sufficient accuracy for most engineering applications within the range of applicability of the approximate theory. {\textcopyright} 1979 by ASME.},
author = {Dempster, A. P. and Laird, N. M. and Rubin, D. B.},
doi = {10.1111/j.2517-6161.1977.tb01600.x},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Dempster, Laird, Rubin{\_}1977{\_}Maximum Likelihood from Incomplete Data Via the EM Algorithm.pdf:pdf},
issn = {00359246},
journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
month = {sep},
number = {1},
pages = {1--22},
title = {{Maximum Likelihood from Incomplete Data Via the EM Algorithm}},
url = {www.jstor.org/stable/2984875 http://doi.wiley.com/10.1111/j.2517-6161.1977.tb01600.x},
volume = {39},
year = {1977}
}
@article{Hopfield1983a,
author = {Hopfield, John J. and Feinstein, D. I. and Palmer, R. G.},
doi = {10.1038/304158a0},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Hopfield, Feinstein, Palmer{\_}1983{\_}' Unlearning ' has a stabilizing effect in collective memories A language-specific comprehension strate.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
month = {jul},
number = {5922},
pages = {158--159},
title = {{‘Unlearning' has a stabilizing effect in collective memories}},
url = {http://www.nature.com/articles/304158a0},
volume = {304},
year = {1983}
}
@inproceedings{Ziebart2008,
abstract = {Recent research has shown the benefit of framing problems of imitation learning as solutions to Markov Decision Problems. This approach reduces learning to the problem of recovering a utility function that makes the behavior induced by a near-optimal policy closely mimic demonstrated behavior. In this work, we develop a probabilistic approach based on the principle of maximum entropy. Our approach provides a well-defined, globally normalized distribution over decision sequences, while providing the same performance guarantees as existing methods.We develop our technique in the context of modeling real-world navigation and driving behaviors where collected data is inherently noisy and imperfect. Our probabilistic approach enables modeling of route preferences as well as a powerful new approach to inferring destinations and routes based on partial trajectories.},
author = {Ziebart, Brian D and Maas, Andrew and Bagnell, J Andrew and Dey, Anind K},
booktitle = {Proceedings of the 23rd National Conference on Artificial Intelligence - Volume 3},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop//Thanh, An, Chien{\_}2016{\_}Maximum Entropy Inverse Reinforcement Learning.pdf:pdf},
isbn = {9781577353683},
pages = {1433--1438},
publisher = {AAAI Press},
series = {AAAI'08},
title = {{Maximum Entropy Inverse Reinforcement Learning}},
year = {2008}
}
@article{Friston2006,
abstract = {By formulating Helmholtz's ideas about perception, in terms of modern-day theories, one arrives at a model of perceptual inference and learning that can explain a remarkable range of neurobiological facts: using constructs from statistical physics, the problems of inferring the causes of sensory input and learning the causal structure of their generation can be resolved using exactly the same principles. Furthermore, inference and learning can proceed in a biologically plausible fashion. The ensuing scheme rests on Empirical Bayes and hierarchical models of how sensory input is caused. The use of hierarchical models enables the brain to construct prior expectations in a dynamic and context-sensitive fashion. This scheme provides a principled way to understand many aspects of cortical organisation and responses. In this paper, we show these perceptual processes are just one aspect of emergent behaviours of systems that conform to a free energy principle. The free energy considered here measures the difference between the probability distribution of environmental quantities that act on the system and an arbitrary distribution encoded by its configuration. The system can minimise free energy by changing its configuration to affect the way it samples the environment or change the distribution it encodes. These changes correspond to action and perception respectively and lead to an adaptive exchange with the environment that is characteristic of biological systems. This treatment assumes that the system's state and structure encode an implicit and probabilistic model of the environment. We will look at the models entailed by the brain and how minimisation of its free energy can explain its dynamics and structure. {\textcopyright} 2006.},
annote = {This paper proposes the idea that perception emerges in processes that minimise free energy, which corroborates the predictive coding principle.

Tags: [PEB][FEE][NME][FEQ][HYF][PRE]},
author = {Friston, Karl and Kilner, James and Harrison, Lee},
doi = {10.1016/j.jphysparis.2006.10.001},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston, Kilner, Harrison{\_}2006{\_}A free energy principle for the brain.pdf:pdf},
issn = {09284257},
journal = {Journal of Physiology Paris},
keywords = {Action,Attention,Free energy,Hierarchical,Inference,Learning,Perception,Selection,Variational Bayes,in-obsidian},
mendeley-tags = {in-obsidian},
number = {1-3},
pages = {70--87},
pmid = {17097864},
title = {{A free energy principle for the brain}},
volume = {100},
year = {2006}
}
@article{Friston2015e,
abstract = {Understanding how organisms establish their form during embryogenesis and regeneration represents a major knowledge gap in biological pattern formation. It has been recently suggested that morphogenesis could be understood in terms of cellular information processing and the ability of cell groups to model shape. Here, we offer a proof of principle that self-assembly is an emergent property of cells that share a common (genetic and epigenetic) model of organismal form. This behaviour is formulated in terms of variational free-energy minimization - of the sort that has been used to explain action and perception in neuroscience. In brief, casting the minimization of thermodynamic free energy in terms of variational free energy allows one to interpret (the dynamics of) a system as inferring the causes of its inputs - and acting to resolve uncertainty about those causes. This novel perspective on the coordination of migration and differentiation of cells suggests an interpretation of genetic codes as parametrizing a generative model - predicting the signals sensed by cells in the target morphology - and epigenetic processes as the subsequent inversion of that model. This theoretical formulation may complement bottom-up strategies - that currently focus on molecular pathways - with (constructivist) top-down approaches that have proved themselves in neuroscience and cybernetics.},
author = {Friston, Karl and Levin, Michael and Sengupta, Biswa and Pezzulo, Giovanni},
doi = {10.1098/rsif.2014.1383},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston et al.{\_}2015{\_}Knowing one's place A free-energy approach to pattern regulation(2).pdf:pdf},
issn = {17425662},
journal = {Journal of the Royal Society Interface},
keywords = {Active inference,Free energy,Morphogenesis,Pattern formation,Random attractor,Self-assembly},
number = {105},
pmid = {25788538},
title = {{Knowing one's place: A free-energy approach to pattern regulation}},
volume = {12},
year = {2015}
}
@article{Friston2007,
abstract = {If one formulates Helmholtz's ideas about perception in terms of modern-day theories one arrives at a model of perceptual inference and learning that can explain a remarkable range of neurobiological facts. Using constructs from statistical physics it can be shown that the problems of inferring what cause our sensory inputs and learning causal regularities in the sensorium can be resolved using exactly the same principles. Furthermore, inference and learning can proceed in a biologically plausible fashion. The ensuing scheme rests on Empirical Bayes and hierarchical models of how sensory information is generated. The use of hierarchical models enables the brain to construct prior expectations in a dynamic and context-sensitive fashion. This scheme provides a principled way to understand many aspects of the brain's organisation and responses. In this paper, we suggest that these perceptual processes are just one emergent property of systems that conform to a free-energy principle. The free-energy considered here represents a bound on the surprise inherent in any exchange with the environment, under expectations encoded by its state or configuration. A system can minimise free-energy by changing its configuration to change the way it samples the environment, or to change its expectations. These changes correspond to action and perception, respectively, and lead to an adaptive exchange with the environment that is characteristic of biological systems. This treatment implies that the system's state and structure encode an implicit and probabilistic model of the environment. We will look at models entailed by the brain and how minimisation of free-energy can explain its dynamics and structure. {\textcopyright} 2007 Springer Science+Business Media B.V.},
author = {Friston, Karl J. and Stephan, Klaas E.},
doi = {10.1007/s11229-007-9237-y},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston, Stephan{\_}2007{\_}Free-energy and the brain.pdf:pdf},
issn = {00397857},
journal = {Synthese},
keywords = {Action,Attention,Free-energy,Hierarchical,Inference,Learning,Perception,Selection,Value,Variational Bayes},
number = {3},
pages = {417--458},
title = {{Free-energy and the brain}},
volume = {159},
year = {2007}
}
@article{Titensky2018,
abstract = {Extended Kalman Filtering (EKF) can be used to propagate and quantify input uncertainty through a Deep Neural Network (DNN) assuming mild hypotheses on the input distribution. This methodology yields results comparable to existing methods of uncertainty propagation for DNNs while lowering the computational overhead considerably. Additionally, EKF allows model error to be naturally incorporated into the output uncertainty.},
archivePrefix = {arXiv},
arxivId = {1809.06009},
author = {Titensky, Jessica S. and Jananthan, Hayden and Kepner, Jeremy},
eprint = {1809.06009},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Titensky, Jananthan, Kepner{\_}2018{\_}Uncertainty propagation in deep neural networks using extended kalman filtering.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {Error propagation,Kalman filtering,Machine learning,Uncertainty quantification},
title = {{Uncertainty propagation in deep neural networks using extended kalman filtering}},
year = {2018}
}
@article{Friston2016a,
abstract = {This paper offers an active inference account of choice behaviour and learning. It focuses on the distinction between goal-directed and habitual behaviour and how they contextualise each other. We show that habits emerge naturally (and autodidactically) from sequential policy optimisation when agents are equipped with state-action policies. In active inference, behaviour has explorative (epistemic) and exploitative (pragmatic) aspects that are sensitive to ambiguity and risk respectively, where epistemic (ambiguity-resolving) behaviour enables pragmatic (reward-seeking) behaviour and the subsequent emergence of habits. Although goal-directed and habitual policies are usually associated with model-based and model-free schemes, we find the more important distinction is between belief-free and belief-based schemes. The underlying (variational) belief updating provides a comprehensive (if metaphorical) process theory for several phenomena, including the transfer of dopamine responses, reversal learning, habit formation and devaluation. Finally, we show that active inference reduces to a classical (Bellman) scheme, in the absence of ambiguity.},
author = {Friston, Karl and FitzGerald, Thomas and Rigoli, Francesco and Schwartenbeck, Philipp and O'Doherty, John and Pezzulo, Giovanni},
doi = {10.1016/j.neubiorev.2016.06.022},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston et al.{\_}2016{\_}Active inference and learning(2).pdf:pdf},
issn = {01497634},
journal = {Neuroscience {\&} Biobehavioral Reviews},
keywords = {Active inference,Bayesian inference,Bayesian surprise,Epistemic value,Exploitation,Exploration,Free energy,Goal-directed,Habit learning,Information gain},
month = {sep},
pages = {862--879},
pmid = {27375276},
publisher = {Elsevier Ltd},
title = {{Active inference and learning}},
volume = {68},
year = {2016}
}
@article{Friston2013a,
abstract = {This paper considers agency in the setting of embodied or active inference. In brief, we associate a sense of agency with prior beliefs about action and ask what sorts of beliefs underlie optimal behavior. In particular, we consider prior beliefs that action minimizes the Kullback-Leibler (KL) divergence between desired states and attainable states in the future. This allows one to formulate bounded rationality as approximate Bayesian inference that optimizes a free energy bound on model evidence. We show that constructs like expected utility, exploration bonuses, soft max choice rules and optimism bias emerge as natural consequences of this formulation. Previous accounts of active inference have focused on predictive coding and Bayesian filtering schemes for minimizing free energy. Here, we consider variational Bayes as an alternative scheme that provides formal constraints on the computational anatomy of inference and action-constraints that are remarkably consistent with neuroanatomy. Furthermore, this scheme contextualizes optimal decision theory and economic (utilitarian) formulations as pure inference problems. For example, expected utility theory emerges as a special case of free energy minimization, where the sensitivity or inverse temperature (of soft max functions and quantal response equilibria) has a unique and Bayes-optimal solution-that minimizes free energy. This sensitivity corresponds to the precision of beliefs about behavior, such that attainable goals are afforded a higher precision or confidence. In turn, this means that optimal behavior entails a representation of confidence about outcomes that are under an agent's control. {\textcopyright} 2013 Friston, Schwartenbeck, FitzGerald, Moutoussis, Behrens and Dolan.},
author = {Friston, Karl J. and Schwartenbeck, Philipp and FitzGerald, Thomas and Moutoussis, Michael and Behrens, Timothy and Dolan, Raymond J.},
doi = {10.3389/fnhum.2013.00598},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston et al.{\_}2013{\_}The anatomy of choice Active inference and agency.pdf:pdf},
issn = {16625161},
journal = {Frontiers in Human Neuroscience},
keywords = {Active inference,Agency,Bayesian,Bounded rationality,Embodied cognition,Free energy,Inference,Utility theory},
number = {SEP},
pages = {1--18},
title = {{The anatomy of choice: Active inference and agency}},
volume = {7},
year = {2013}
}
@article{Herz1994,
abstract = {A simple model with a novel type of dynamics is introduced in order to investigate the emergence of self-ordered motion in systems of particles with biologically motivated interaction. In our model particles are driven with a constant absolute velocity and at each time step assume the average direction of motion of the particles in their neighborhood with some random perturbation (g) added. We present numerical evidence that this model results in a kinetic phase transition from no transport (zero average velocity, {\~{}}v, ( = 0) to finite net transport through spontaneous symmetry breaking of the rotational symmetry. The transition is continuous, since {\~{}}v, {\~{}} is found to scale as (71, —g)t with p = 0.45},
author = {Herz, Andreas V. M. and Hopfield, John J.},
doi = {10.1103/PhysRevLett.75.1222},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Herz, Hopfield{\_}1995{\_}Earthquake Cycles and Neural Reverberations Collective Oscillations in Systems with Pulse-Coupled Threshold Elements.pdf:pdf},
issn = {0031-9007},
journal = {Physical Review Letters},
month = {aug},
number = {6},
pages = {1222--1225},
title = {{Earthquake Cycles and Neural Reverberations: Collective Oscillations in Systems with Pulse-Coupled Threshold Elements}},
url = {https://link.aps.org/doi/10.1103/PhysRevLett.75.1222},
volume = {75},
year = {1995}
}
@article{Salman2018,
abstract = {Recent literature in the robot learning community has focused on learning robot skills that abstract out lower-level details of robot control, such as Dynamic Movement Primitives (DMPs), the options framework in hierarchical RL, and subtask policies. To fully leverage the efficacy of these macro actions, it is necessary to then sequence these primitives to achieve a given task. Our objective is to jointly learn a set of robot skills and a sequence of these learnt skills to accomplish a given task. We consider the task of navigating a robot across various environments using visual input, maximizing the distance traveled through the environment while avoiding static obstacles. Traditional planning methods to solve this problem rely on hand-crafted state representations and heuristics for planning, and often fail to generalize. In contrast, deep neural networks have proved to be powerful function approximators, successfully modeling complex control policies. In addition, the ability of such networks to learn good representations of high-dimensional sensory inputs makes them a valuable tool when dealing with visual inputs. In this project, we explore the capability of deep neural networks to learn and sequence robot skills for navigation, directly using visual input.},
archivePrefix = {arXiv},
arxivId = {1803.01446},
author = {Salman, Hadi and Grover, Jaskaran and Shankar, Tanmay},
doi = {10.1162/NECO},
eprint = {1803.01446},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Salman, Grover, Shankar{\_}2018{\_}Hierarchical Reinforcement Learning for Sequencing Behaviors(2).pdf:pdf;:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Salman, Grover, Shankar{\_}2018{\_}Hierarchical Reinforcement Learning for Sequencing Behaviors.pdf:pdf},
pages = {2709--2733},
title = {{Hierarchical Reinforcement Learning for Sequencing Behaviors}},
url = {http://arxiv.org/abs/1803.01446},
volume = {2733},
year = {2018}
}
@article{Broyd2009,
abstract = {In this review we are concerned specifically with the putative role of the default-mode network (DMN) in the pathophysiology of mental disorders. First, we define the DMN concept with regard to its neuro-anatomy, its functional organisation through low frequency neuronal oscillations, its relation to other recently discovered low frequency resting state networks, and the cognitive functions it is thought to serve. Second, we introduce methodological and analytical issues and challenges. Third, we describe putative mechanisms proposed to link DMN abnormalities and mental disorders. These include interference by network activity during task performance, altered patterns of antagonism between task specific and non-specific elements, altered connectively and integrity of the DMN, and altered psychological functions served by the network DMN. Fourth, we review the empirical literature systematically. We relate DMN dysfunction to dementia, schizophrenia, epilepsy, anxiety and depression, autism and attention deficit/hyperactivity disorder drawing out common and unique elements of the disorders. Finally, we provide an integrative overview and highlight important challenges and tasks for future research. {\textcopyright} 2008 Elsevier Ltd. All rights reserved.},
author = {Broyd, Samantha J. and Demanuele, Charmaine and Debener, Stefan and Helps, Suzannah K. and James, Christopher J. and Sonuga-Barke, Edmund J.S.},
doi = {10.1016/j.neubiorev.2008.09.002},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Broyd et al.{\_}2009{\_}Default-mode brain dysfunction in mental disorders A systematic review.pdf:pdf},
issn = {01497634},
journal = {Neuroscience {\&} Biobehavioral Reviews},
keywords = {Alzheimer's disease,Anxiety,Attention deficit hyperactivity disorder,Autism,Default-mode network,Depression,EEG,Epilepsy,Functional connectivity,Low frequency oscillations,MEG,Resting state,Schizophrenia,fMRI},
month = {mar},
number = {3},
pages = {279--296},
pmid = {18824195},
title = {{Default-mode brain dysfunction in mental disorders: A systematic review}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0149763408001504},
volume = {33},
year = {2009}
}
@incollection{Prigogine1985,
abstract = {Complex behaviour made its appearance in the physical sciences in a modest, low-key fashion. For a long time, in the mind of most physicists and chemists, complexity was associated with biological order and its multiple manifestations, for example at the level of evolution, embryogenesis and population dynamics. Physical sciences on the other side were aiming at a description of nature in terms of laws of universal validity. And to this end they were utilising simple models to which, hopefully, the description of more complicated systems could be reduced. This feeling has been repreatedly expressed by some of the greatest scientists of our century. Thus, for Einstein “the physicist must content himself with describing the most simple events which can be brought within the domain of our experience; all events of a more complex order are beyond the power of the human intellect to reconstruct with the subtle accuracy and logical perfection which the theoretical physicist demands {\ldots}. The general laws on which the structure of theoretical physics is based claim to be valid for any natural phenomenon whatsoever.},
address = {Dordrecht},
author = {Prigogine, I and Nicolis, G},
booktitle = {Bifurcation Analysis},
doi = {10.1007/978-94-009-6239-2_1},
editor = {Hazewinkel, M and Jurkovich, R and Paelinck, J H P},
isbn = {978-94-009-6239-2},
pages = {3--12},
publisher = {Springer Netherlands},
title = {{Self-Organisation in Nonequilibrium Systems: Towards A Dynamics of Complexity}},
year = {1985}
}
@article{Kingma2016,
abstract = {The framework of normalizing flows provides a general strategy for flexible variational inference of posteriors over latent variables. We propose a new type of normalizing flow, inverse autoregressive flow (IAF), that, in contrast to earlier published flows, scales well to high-dimensional latent spaces. The proposed flow consists of a chain of invertible transformations, where each transformation is based on an autoregressive neural network. In experiments, we show that IAF significantly improves upon diagonal Gaussian approximate posteriors. In addition, we demonstrate that a novel type of variational autoencoder, coupled with IAF, is competitive with neural autoregressive models in terms of attained log-likelihood on natural images, while allowing significantly faster synthesis.},
archivePrefix = {arXiv},
arxivId = {1606.04934},
author = {Kingma, Diederik P. and Salimans, Tim and Jozefowicz, Rafal and Chen, Xi and Sutskever, Ilya and Welling, Max},
eprint = {1606.04934},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Kingma et al.{\_}2016{\_}Improved variational inference with inverse autoregressive flow.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
number = {Nips},
pages = {4743--4751},
title = {{Improved variational inference with inverse autoregressive flow}},
year = {2016}
}
@article{Baltieri2019,
abstract = {In the past few decades, probabilistic interpretations of brain functions have become widespread in cognitive science and neuroscience. In particular, the free energy principle and active inference are increasingly popular theories of cognitive functions that claim to offer a unified understanding of life and cognition within a general mathematical framework derived from information and control theory, and statistical mechanics. However, we argue that if the active inference proposal is to be taken as a general process theory for biological systems, it is necessary to understand how it relates to existing control theoretical approaches routinely used to study and explain biological systems. For example, recently, PID (Proportional-Integral-Derivative) control has been shown to be implemented in simple molecular systems and is becoming a popular mechanistic explanation of behaviours such as chemotaxis in bacteria and amoebae, and robust adaptation in biochemical networks. In this work, we will show how PID controllers can fit a more general theory of life and cognition under the principle of (variational) free energy minimisation when using approximate linear generative models of the world. This more general interpretation also provides a new perspective on traditional problems of PID controllers such as parameter tuning as well as the need to balance performances and robustness conditions of a controller. Specifically, we then show how these problems can be understood in terms of the optimisation of the precisions (inverse variances) modulating different prediction errors in the free energy functional.},
author = {Baltieri, Manuel and Buckley, Christopher},
doi = {10.3390/e21030257},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Baltieri, Buckley{\_}2019{\_}PID Control as a Process of Active Inference with Linear Generative Models.pdf:pdf},
issn = {1099-4300},
journal = {Entropy},
keywords = {Active inference,Control theory,Generalised state-space models,Information theory,PID control,Sensorimotor loops,approximate Bayesian inference},
month = {mar},
number = {3},
pages = {257},
title = {{PID Control as a Process of Active Inference with Linear Generative Models}},
url = {https://www.mdpi.com/1099-4300/21/3/257},
volume = {21},
year = {2019}
}
@article{Jaderberg2017a,
abstract = {Training directed neural networks typically requires forward-propagating data through a computation graph, followed by backpropagaling error signal, to produce weight updates. All layers, or more generally, modules, of the network are therefore locked, in the sense that they must wait for the remainder of the network to execute forwards and propagate error backwards before they can be updated. In this work we break this constraint by decoupling modules by introducing a model of the future computation of the network graph. These models predict what the result of the modelled subgraph will produce using only local information. In particular we focus on modelling error gradients: by using the modelled synthetic gradient in place of true backpropa-gated error gradients we decouple subgraphs, and can update them independently and asynchronously i.e. we realise decoupled neural interfaces. We show results for feed-forward models, where every layer is trained asynchronously, recurrent neural networks (RNNs) where predicting one's future gradient extends the time over which the RNN can effectively model, and also a hierarchical RNN system with ticking at different timescales. Finally, we demonstrate that in addition to predicting gradients, the same framework can be used to predict inputs, resulting in models which arc decoupled in both the forward and backwards pass - amounting to independent networks which co-learn such that they can be composed into a single functioning corporation.},
archivePrefix = {arXiv},
arxivId = {1608.05343},
author = {Jaderberg, Max and Czarnecki, Wojciech Marian and Osindero, Simon and Vinyals, Oriol and Graves, Alex and Silver, David and Kavukcuoglu, Koray},
eprint = {1608.05343},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Jaderberg et al.{\_}2017{\_}Decoupled neural interfaces using synthetic gradients.pdf:pdf},
isbn = {9781510855144},
journal = {34th International Conference on Machine Learning, ICML 2017},
pages = {2558--2577},
title = {{Decoupled neural interfaces using synthetic gradients}},
volume = {4},
year = {2017}
}
@article{Friston1997,
abstract = {This work represents an attempt to bring together two important themes in neuronal dynamics. The first is the characterization of dynamic correlations in multiunit recordings of spike activity using joint-peri- stimulus time histograms (J-PSTHs) [Aertsen and Preissl, 1991: Non Linear Dynamics and Neural Networks]. The second is transient phase-locking at high (gamma) frequencies, either in terms of spiking in separable spike trains [e.g., Eckhorn et al., 1988: Biol Cybern 60:121-130, Gray and Singer, 1989 Proc Natl Acad Sci USA 86:1698-1702], or using continuous electrical or biomagnetic signals [e.g., Desmedt and Tomberg, 1994 Neurosci Lett 168:126- 129]. In this paper we suggest that transient phase-locking is necessary for frequency-specific, dynamic event-related correlations. This point is demonstrated using the gamma-frequency (36 Hz) component of neuromagnetic signals measured in the prefrontal and partial regions of a subject during self-paced movements. A J-PSTH analysis revealed dynamic changes in prefronto-parietal correlations in relation to movement onset. These frequency-specific dynamic correlations were associated with changes in the degree of phase-locking, of the sort reported by Desmedt and Tomberg [1994 Neurosci Lett 168:126-129].},
author = {Friston, Karl J. and Stephan, Klaas E. and Frackowiak, R. S.J.},
doi = {10.1002/(SICI)1097-0193(1997)5:1<48::AID-HBM5>3.0.CO;2-N},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston, Stephan, Frackowiak{\_}1997{\_}Transient phase-locking and dynamic correlations Are they the same thing.pdf:pdf},
issn = {10659471},
journal = {Human Brain Mapping},
keywords = {MEG,dynamic correlations,joint-PSTH,neural dynamics,phase-locking,self-paced movement},
number = {1},
pages = {48--57},
title = {{Transient phase-locking and dynamic correlations: Are they the same thing?}},
volume = {5},
year = {1997}
}
@article{Ponulak2013a,
abstract = {Efficient path planning and navigation is critical for animals, robotics, logistics and transportation. We study a model in which spatial navigation problems can rapidly be solved in the brain by parallel mental exploration of alternative routes using propagating waves of neural activity. A wave of spiking activity propagates through a hippocampuslike network, altering the synaptic connectivity. The resulting vector field of synaptic change then guides a simulated animal to the appropriate selected target locations. We demonstrate that the navigation problem can be solved using realistic, local synaptic plasticity rules during a single passage of a wavefront. Our model can find optimal solutions for competing possible targets or learn and navigate in multiple environments. The model provides a hypothesis on the possible computational mechanisms for optimal path planning in the brain, at the same time it is useful for neuromorphic implementations, where the parallelism of information processing proposed here can fully be harnessed in hardware. {\textcopyright} 2013 Ponulak and Hopfield.},
author = {Ponulak, Filip and Hopfield, John J.},
doi = {10.3389/fncom.2013.00098},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Ponulak, Hopfield{\_}2013{\_}Rapid, parallel path planning by propagating wavefronts of spiking neural activity.pdf:pdf},
issn = {16625188},
journal = {Frontiers in Computational Neuroscience},
keywords = {Hippocampus,Mental exploration,Navigation,Neuromorphic systems,Parallel processing,Path planning,Spike timing dependent plasticity,Spiking neurons,Wave propagation},
number = {JUN},
pages = {1--14},
title = {{Rapid, parallel path planning by propagating wavefronts of spiking neural activity}},
volume = {7},
year = {2013}
}
@article{Millidge2020c,
abstract = {The Expected Free Energy (EFE) is a central quantity in the theory of active inference. It is the quantity that all active inference agents are mandated to minimize through action, and its decomposition into extrinsic and intrinsic value terms is key to the balance of exploration and exploitation that active inference agents evince. Despite its importance, the mathematical origins of this quantity and its relation to the Variational Free Energy (VFE) remain unclear. In this paper, we investigate the origins of the EFE in detail and show that it is not simply "the free energy in the future". We present a functional that we argue is the natural extension of the VFE, but which actively discourages exploratory behaviour, thus demonstrating that exploration does not directly follow from free energy minimization into the future. We then develop a novel objective, the Free-Energy of the Expected Future (FEEF), which possesses both the epistemic component of the EFE as well as an intuitive mathematical grounding as the divergence between predicted and desired futures.},
archivePrefix = {arXiv},
arxivId = {2004.08128},
author = {Millidge, Beren and Tschantz, Alexander and Buckley, Christopher L.},
doi = {10.1162/neco_a_01354},
eprint = {2004.08128},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Millidge, Tschantz, Buckley{\_}2020{\_}Whence the Expected Free Energy.pdf:pdf},
issn = {23318422},
journal = {arXiv},
title = {{Whence the Expected Free Energy?}},
year = {2020}
}
@article{Tschantz2020a,
abstract = {The central tenet of reinforcement learning (RL) is that agents seek to maximize the sum of cumulative rewards. In contrast, active inference, an emerging framework within cognitive and computational neuroscience, proposes that agents act to maximize the evidence for a biased generative model. Here, we illustrate how ideas from active inference can augment traditional RL approaches by (i) furnishing an inherent balance of exploration and exploitation, and (ii) providing a more flexible conceptualization of reward. Inspired by active inference, we develop and implement a novel objective for decision making, which we term the free energy of the expected future. We demonstrate that the resulting algorithm successfully balances exploration and exploitation, simultaneously achieving robust performance on several challenging RL benchmarks with sparse, well-shaped, and no rewards.},
archivePrefix = {arXiv},
arxivId = {2002.12636},
author = {Tschantz, Alexander and Millidge, Beren and Seth, Anil K. and Buckley, Christopher L.},
eprint = {2002.12636},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Tschantz et al.{\_}2020{\_}Reinforcement learning through active inference(2).pdf:pdf},
issn = {23318422},
journal = {arXiv},
number = {Iclr},
pages = {1--16},
title = {{Reinforcement learning through active inference}},
year = {2020}
}
@inproceedings{Tschantz2020,
abstract = {The central tenet of reinforcement learning (RL) is that agents seek to maximize the sum of cumulative rewards. In contrast, active inference, an emerging framework within cognitive and computational neuroscience, proposes that agents act to maximize the evidence for a biased generative model. Here, we illustrate how ideas from active inference can augment traditional RL approaches by (i) furnishing an inherent balance of exploration and exploitation, and (ii) providing a more flexible conceptualization of reward. Inspired by active inference, we develop and implement a novel objective for decision making, which we term the free energy of the expected future. We demonstrate that the resulting algorithm successfully balances exploration and exploitation, simultaneously achieving robust performance on several challenging RL benchmarks with sparse, well-shaped, and no rewards.},
archivePrefix = {arXiv},
arxivId = {2002.12636},
author = {Tschantz, Alexander and Millidge, Beren and Seth, Anil K. and Buckley, Christopher L.},
booktitle = {ICLR},
eprint = {2002.12636},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Tschantz et al.{\_}2020{\_}Reinforcement Learning through Active Inference.pdf:pdf},
month = {feb},
pages = {1--14},
title = {{Reinforcement Learning through Active Inference}},
url = {http://arxiv.org/abs/2002.12636},
year = {2020}
}
@article{Stringer2019,
abstract = {Neuronal populations in sensory cortex produce variable responses to sensory stimuli and exhibit intricate spontaneous activity even without external sensory input. Cortical variability and spontaneous activity have been variously proposed to represent random noise, recall of prior experience, or encoding of ongoing behavioral and cognitive variables. Recording more than 10,000 neurons in mouse visual cortex, we observed that spontaneous activity reliably encoded a high-dimensional latent state, which was partially related to the mouse's ongoing behavior and was represented not just in visual cortex but also across the forebrain. Sensory inputs did not interrupt this ongoing signal but added onto it a representation of external stimuli in orthogonal dimensions. Thus, visual cortical population activity, despite its apparently noisy structure, reliably encodes an orthogonal fusion of sensory and multidimensional behavioral information.},
author = {Stringer, Carsen and Pachitariu, Marius and Steinmetz, Nicholas and Reddy, Charu Bai and Carandini, Matteo and Harris, Kenneth D.},
doi = {10.1126/science.aav7893},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Stringer et al.{\_}2019{\_}Spontaneous behaviors drive multidimensional, brainwide activity.pdf:pdf},
issn = {0036-8075},
journal = {Science},
month = {apr},
number = {6437},
pmid = {31000656},
title = {{Spontaneous behaviors drive multidimensional, brainwide activity}},
url = {https://www.sciencemag.org/lookup/doi/10.1126/science.aav7893},
volume = {364},
year = {2019}
}
@article{Friston1997a,
abstract = {This paper presents the conjecture that functional integration may be mediated by the mutual induction and maintenance of stereotyped spatiotemporal patterns of activity (i.e., transients) in different neuronal populations. In contradistinction to temporal and rate coding models of neuronal interactions, transient coding considers that transactions among neuronal systems use transient dynamics that are distributed in a structured way over both space and time. In contrast to synchronization models, transient coding does not depend on interactions at the same frequencies, in different parts of the brain, but involves covariations among different frequencies and can therefore be considered a more general form of coding. Using an analysis of the correlations among the spectral density of neuromagnetic signals, measured at different cortical regions, this hypothesis was confirmed. For example high (gamma)-frequency oscillations in the prefrontal cortex are associated with low (20 Hz)-frequency oscillations in the parietal cortex. The results are consistent with transient coding and suggest that transient dynamics endure for at least 40-200 ms. Transient coding means that correlations (rate coding) and coherence (synchrony) are neither complete nor sufficient characterizations of neuronal interactions. Although temporal coding, rate coding, and synchrony are important aspects of neuronal interactions, the results speak to further integrative neuronal mechanisms of a more general nature.},
author = {Friston, Karl J.},
doi = {10.1006/nimg.1997.0260},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston{\_}1997{\_}Another neural code.pdf:pdf},
issn = {10538119},
journal = {NeuroImage},
number = {3},
pages = {213--220},
pmid = {9345550},
title = {{Another neural code?}},
volume = {5},
year = {1997}
}
@article{Preller2019,
abstract = {Psychedelics exert unique effects on human consciousness. The thalamic filter model suggests that core effects of psychedelics may result from gating deficits, based on a disintegration of information processing within cortico–striato–thalamo-cortical (CSTC) feedback loops. To test this hypothesis, we characterized changes in directed (effective) connectivity between selected CTSC regions after acute administration of lysergic acid diethylamide (LSD), and after pretreatment with Ketanserin (a selective serotonin 2A receptor antagonist) plus LSD in a double-blind, randomized, placebo-controlled, cross-over study in 25 healthy participants. We used spectral dynamic causal modeling (DCM) for resting-state fMRI data. Fully connected DCM models were specified for each treatment condition to investigate the connectivity between the following areas: thalamus, ventral striatum, posterior cingulate cortex, and temporal cortex. Our results confirm major predictions proposed in the CSTC model and provide evidence that LSD alters effective connectivity within CSTC pathways that have been implicated in the gating of sensory and sensorimotor information to the cortex. In particular, LSD increased effective connectivity from the thalamus to the posterior cingulate cortex in a way that depended on serotonin 2A receptor activation, and decreased effective connectivity from the ventral striatum to the thalamus independently of serotonin 2A receptor activation. Together, these results advance our mechanistic understanding of the action of psychedelics in health and disease. This is important for the development of new pharmacological therapeutics and also increases our understanding of the mechanisms underlying the potential clinical efficacy of psychedelics.},
author = {Preller, Katrin H. and Razi, Adeel and Zeidman, Peter and St{\"{a}}mpfli, Philipp and Friston, Karl J. and Vollenweider, Franz X.},
doi = {10.1073/pnas.1815129116},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Preller et al.{\_}2019{\_}Effective connectivity changes in LSD-induced altered states of consciousness in humans.pdf:pdf},
issn = {10916490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Effective connectivity,FMRI,LSD,Serotonin,Spectral dynamic causal modeling},
number = {7},
pages = {2743--2748},
title = {{Effective connectivity changes in LSD-induced altered states of consciousness in humans}},
volume = {116},
year = {2019}
}
@article{Bayer2014,
abstract = {Leveraging advances in variational inference, we propose to enhance recurrent neural networks with latent variables, resulting in Stochastic Recurrent Networks (STORNs). The model i) can be trained with stochastic gradient methods, ii) allows structured and multi-modal conditionals at each time step, iii) features a reliable estimator of the marginal likelihood and iv) is a generalisation of deterministic recurrent neural networks. We evaluate the method on four polyphonic musical data sets and motion capture data.},
archivePrefix = {arXiv},
arxivId = {1411.7610},
author = {Bayer, Justin and Osendorfer, Christian},
eprint = {1411.7610},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Bayer, Osendorfer{\_}2014{\_}Learning Stochastic Recurrent Networks.pdf:pdf},
pages = {1--9},
title = {{Learning Stochastic Recurrent Networks}},
url = {http://arxiv.org/abs/1411.7610},
year = {2014}
}
@article{Held1963,
abstract = {Full and exact adaptation to sensory rearrangement in adult human Ss requires movement-produced sensory feedback. Riesen's work suggested that this factor also operates in the development of higher mammals but he proposed that sensory-sensory associations are the proposed that sensory-sensory associations are the prerequisite. To test these alternatives, visual stimulation of the active member (A) of each of 10 pairs of neonatal kittens was allowed to vary with its locomotor movements while equivalent stimulation of the second member (P) resulted from passive motion. Subsequent tests of visually guided paw placement, discrimination on a visual cliff, and the blink response were normal for A but failing in P. When other alternative explanations are excluded, this result extends the conclusions of studies of adult rearrangement to neonatal development. (18 ref.) (PsycINFO Database Record (c) 2006 APA, all rights reserved). {\textcopyright} 1963 American Psychological Association.},
author = {Held, Richard and Hein, Alan},
doi = {10.1037/h0040546},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Held, Hein{\_}1963{\_}Movement-produced stimulation in the development of visually guided behavior.pdf:pdf},
issn = {00219940},
journal = {Journal of Comparative and Physiological Psychology},
keywords = {ANIMAL PSYCHOLOGY,CAT, SENSORY REARRANGEMENT IN, {\&},FEEDBACK, MOVEMENT-SENSORY, {\&},MOVEMENT SENSORY FEEDBACK,MOVEMENT-SENSORY FEEDBACK,SENSE, REARRANGEMENT, {\&},SENSORY REARRANGEMENT},
number = {5},
pages = {872--876},
pmid = {14050177},
title = {{Movement-produced stimulation in the development of visually guided behavior}},
volume = {56},
year = {1963}
}
@article{Friston2017b,
abstract = {How do we navigate a deeply structured world? Why are you reading this sentence first – and did you actually look at the fifth word? This review offers some answers by appealing to active inference based on deep temporal models. It builds on previous formulations of active inference to simulate behavioural and electrophysiological responses under hierarchical generative models of state transitions. Inverting these models corresponds to sequential inference, such that the state at any hierarchical level entails a sequence of transitions in the level below. The deep temporal aspect of these models means that evidence is accumulated over nested time scales, enabling inferences about narratives (i.e., temporal scenes). We illustrate this behaviour with Bayesian belief updating – and neuronal process theories – to simulate the epistemic foraging seen in reading. These simulations reproduce perisaccadic delay period activity and local field potentials seen empirically. Finally, we exploit the deep structure of these models to simulate responses to local (e.g., font type) and global (e.g., semantic) violations; reproducing mismatch negativity and P300 responses respectively.},
author = {Friston, Karl J. and Rosch, Richard and Parr, Thomas and Price, Cathy and Bowman, Howard},
doi = {10.1016/j.neubiorev.2017.04.009},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston et al.{\_}2017{\_}Deep temporal models and active inference.pdf:pdf},
issn = {01497634},
journal = {Neuroscience {\&} Biobehavioral Reviews},
keywords = {Active inference,Bayesian,Free energy,Hierarchical,MMN,P300,Reading,Violation},
month = {jun},
number = {November 2016},
pages = {388--402},
pmid = {28416414},
publisher = {Elsevier},
title = {{Deep temporal models and active inference}},
volume = {77},
year = {2017}
}
@article{Bastos2015a,
annote = {This paper analyses the differences in the nature of feedforward and feedback connections in the biological visual cortex.


Tags: [SUS][FRQ][PEA]},
author = {Bastos, Andr{\'{e}} M. and Litvak, Vladimir and Moran, R. J. and Bosman, C.A. and Fries, Pascal and Friston, Karl J.},
doi = {10.1016/j.neuroimage.2014.12.081},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Bastos et al.{\_}2015{\_}A DCM study of spectral asymmetries in feedforward and feedback connections between visual areas V1 and V4 in the mon.pdf:pdf},
issn = {10538119},
journal = {NeuroImage},
month = {mar},
pages = {460--475},
title = {{A DCM study of spectral asymmetries in feedforward and feedback connections between visual areas V1 and V4 in the monkey}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811915000117},
volume = {108},
year = {2015}
}
@article{Friston2011,
abstract = {This paper is about inferring or discovering the functional architecture of distributed systems using Dynamic Causal Modelling (DCM). We describe a scheme that recovers the (dynamic) Bayesian dependency graph (connections in a network) using observed network activity. This network discovery uses Bayesian model selection to identify the sparsity structure (absence of edges or connections) in a graph that best explains observed time-series. The implicit adjacency matrix specifies the form of the network (e.g., cyclic or acyclic) and its graph-theoretical attributes (e.g., degree distribution). The scheme is illustrated using functional magnetic resonance imaging (fMRI) time series to discover functional brain networks. Crucially, it can be applied to experimentally evoked responses (activation studies) or endogenous activity in task-free (resting state) fMRI studies. Unlike conventional approaches to network discovery, DCM permits the analysis of directed and cyclic graphs. Furthermore, it eschews (implausible) Markovian assumptions about the serial independence of random fluctuations. The scheme furnishes a network description of distributed activity in the brain that is optimal in the sense of having the greatest conditional probability, relative to other networks. The networks are characterised in terms of their connectivity or adjacency matrices and conditional distributions over the directed (and reciprocal) effective connectivity between connected nodes or regions. We envisage that this approach will provide a useful complement to current analyses of functional connectivity for both activation and resting-state studies. {\textcopyright} 2011 Elsevier Inc.},
author = {Friston, Karl J. and Li, Baojuan and Daunizeau, Jean and Stephan, Klaas E.},
doi = {10.1016/j.neuroimage.2010.12.039},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston et al.{\_}2011{\_}Network discovery with DCM.pdf:pdf},
issn = {10538119},
journal = {NeuroImage},
keywords = {Bayesian,Connectivity,Dynamic Causal Modelling,FMRI,Generalised Filtering,Neuronal,Random differential equations,Resting-state,Stochastic},
number = {3},
pages = {1202--1221},
pmid = {21182971},
publisher = {Elsevier Inc.},
title = {{Network discovery with DCM}},
url = {http://dx.doi.org/10.1016/j.neuroimage.2010.12.039},
volume = {56},
year = {2011}
}
@incollection{Park2017,
abstract = {Regularizing neural networks is an important task to reduce overfitting. Dropout [1] has been a widely-used regularization trick for neural networks. In convolutional neural networks (CNNs), dropout is usually applied to the fully connected layers. Meanwhile, the regular-ization effect of dropout in the convolutional layers has not been thoroughly analyzed in the literature. In this paper, we analyze the effect of dropout in the convolutional layers, which is indeed proved as a powerful generalization method. We observed that dropout in CNNs regularizes the networks by adding noise to the output feature maps of each layer, yielding robustness to variations of images. Based on this observation, we propose a stochastic dropout whose drop ratio varies for each iteration. Furthermore, we propose a new regularization method which is inspired by behaviors of image filters. Rather than randomly drop the activation, we selectively drop the activations which have high values across the feature map or across the channels. Experimental results validate the regularization performance of selective max-drop and stochastic dropout is competitive to the dropout or spatial dropout [2].},
author = {Park, Sungheon and Kwak, Nojun},
doi = {10.1007/978-3-319-54184-6_12},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Park, Kwak{\_}2017{\_}Analysis on the Dropout Effect in Convolutional Neural Networks.pdf:pdf},
isbn = {9783319541846},
number = {March 2017},
pages = {189--204},
title = {{Analysis on the Dropout Effect in Convolutional Neural Networks}},
url = {http://link.springer.com/10.1007/978-3-319-54184-6{\_}12},
volume = {1},
year = {2017}
}
@article{Dayan2008,
abstract = {Reinforcement learning provides both qualitative and quantitative frameworks for understanding and modeling adaptive decision-making in the face of rewards and punishments. Here we review the latest dispatches from the forefront of this field, and map out some of the territories where lie monsters. {\textcopyright} 2008 Elsevier Ltd. All rights reserved.},
author = {Dayan, Peter and Niv, Yael},
doi = {10.1016/j.conb.2008.08.003},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Dayan, Niv{\_}2008{\_}Reinforcement learning The Good, The Bad and The Ugly.pdf:pdf},
issn = {09594388},
journal = {Current Opinion in Neurobiology},
number = {2},
pages = {185--196},
pmid = {18708140},
title = {{Reinforcement learning: The Good, The Bad and The Ugly}},
volume = {18},
year = {2008}
}
@book{Ganong2012,
author = {Barrett, Kim E and Boitano, Scott and Barman, Susan M and Brooks, Heddwen L},
doi = {10.7748/ns.24.20.30.s35},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Barrett et al.{\_}2012{\_}Ganong's Review of Medical Physiology – 23rd edition.pdf:pdf},
isbn = {9780071605687},
month = {jan},
pages = {125},
publisher = {Mc Graw Hill},
title = {{Ganong's Review of Medical Physiology – 23rd edition}},
year = {2012}
}
@article{Kozma2018,
abstract = {Deep learning neural networks produce excellent results in various pattern recognition tasks. It is of great practical importance to answer some open questions regarding model design and parameterization, and to understand how input data are converted into meaningful knowledge at the output. The layer-by-layer evolution of the abstraction level has been proposed previously as a quantitative measure to describe the emergence of knowledge in the network. In this work we systematically evaluate the abstraction level for a variety of image datasets. We observe that there is a general tendency of increasing abstraction from input to output with the exception of a drop of abstraction at some ReLu and Pooling layers. The abstraction level is relatively low and does not change significantly in the first few layers following the input, while it fluctuates around some high saturation value at the layers preceding the output. Finally, the layer-by-layer change in abstraction is not normally distributed, rather it approximates an exponential distribution. These results point to salient local features of deep layers impacting overall (global) classification performance. We compare the results extracted from deep learning neural networks performing image processing tasks with the results obtained by analyzing brain imaging data. Our conclusions may be helpful in future designs of more efficient, compact deep learning neural networks.},
author = {Kozma, Robert and Ilin, Roman and Siegelmann, Hava T.},
doi = {10.1016/j.procs.2018.10.520},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Kozma, Ilin, Siegelmann{\_}2018{\_}Evolution of Abstraction Across Layers in Deep Learning Neural Networks.pdf:pdf},
issn = {18770509},
journal = {Procedia Computer Science},
keywords = {Abstraction Level,Convolutional Neural Networks,Deep Learning,Image Processing,Knowledge},
pages = {203--213},
publisher = {Elsevier B.V.},
title = {{Evolution of Abstraction Across Layers in Deep Learning Neural Networks}},
url = {https://doi.org/10.1016/j.procs.2018.10.520 https://linkinghub.elsevier.com/retrieve/pii/S1877050918322294},
volume = {144},
year = {2018}
}
@article{MurraySherman2011,
abstract = {Essentially all cortical areas receive thalamic inputs and send outputs to lower motor centers. Cortical areas communicate with each other by means of direct corticocortical and corticothalamocortical pathways, often organized in parallel. We distinguish these functionally, stressing that the transthalamic pathways are class 1 (formerly known as "driver") pathways capable of transmitting information, whereas the direct pathways vary, being either class 2 (formerly known as "modulator") or class 1. The transthalamic pathways provide a thalamic gate that can be open or closed (and otherwise more subtly modulated), and these inputs to the thalamus are generally branches of axons with motor functions. Thus the transthalamic corticocortical pathways that can be gated carry information about the cortical processing in one cortical area and also about the motor instructions currently being issued from that area and copied to other cortical areas. {\textcopyright} 2011 the American Physiological Society.},
author = {{Murray Sherman}, S. and Guillery, R. W.},
doi = {10.1152/jn.00429.2011},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Murray Sherman, Guillery{\_}2011{\_}Distinct functions for direct and transthalamic corticocortical connections.pdf:pdf},
issn = {00223077},
journal = {Journal of Neurophysiology},
keywords = {Driver,First-order relay,Higher order relay,Modulator},
number = {3},
pages = {1068--1077},
pmid = {21676936},
title = {{Distinct functions for direct and transthalamic corticocortical connections}},
volume = {106},
year = {2011}
}
@article{Demekas2020,
abstract = {This paper offers a prospectus of what might be achievable in the development of emotional recognition devices. It provides a conceptual overview of the free energy principle; including Markov blankets, active inference, and—in particular—a discussion of selfhood and theory of mind, followed by a brief explanation of how these concepts can explain both neural and cultural models of emotional inference. The underlying hypothesis is that emotion recognition and inference devices will evolve from state-of-the-art deep learning models into active inference schemes that go beyond marketing applications and become adjunct to psychiatric practice. Specifically, this paper proposes that a second wave of emotion recognition devices will be equipped with an emotional lexicon (or the ability to epistemically search for one), allowing the device to resolve uncertainty about emotional states by actively eliciting responses from the user and learning from these responses. Following this, a third wave of emotional devices will converge upon the user's generative model, resulting in the machine and human engaging in a reciprocal, prosocial emotional interaction, i.e., sharing a generative model of emotional states.},
author = {Demekas, Daphne and Parr, Thomas and Friston, Karl J.},
doi = {10.3389/fncom.2020.00030},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Demekas, Parr, Friston{\_}2020{\_}An Investigation of the Free Energy Principle for Emotion Recognition.pdf:pdf},
issn = {16625188},
journal = {Frontiers in Computational Neuroscience},
keywords = {Markov blanket (MB),active inference,artificial intelligence,bayesian brain,emotion recognition (ER),free energy (Helmholtz energy)},
number = {April},
pages = {1--17},
title = {{An Investigation of the Free Energy Principle for Emotion Recognition}},
volume = {14},
year = {2020}
}
@article{Garrido2009,
abstract = {The suppression of neuronal responses to a repeated event is a ubiquitous phenomenon in neuroscience. However, the underlying mechanisms remain largely unexplored. The aim of this study was to examine the temporal evolution of experience-dependent changes in connectivity induced by repeated stimuli. We recorded event-related potentials (ERPs) during frequency changes of a repeating tone. Bayesian inversion of dynamic causal models (DCM) of ERPs revealed systematic repetition-dependent changes in both intrinsic and extrinsic connections, within a hierarchical cortical network. Critically, these changes occurred very quickly, over inter-stimulus intervals that implicate short-term synaptic plasticity. Furthermore, intrinsic (within-source) connections showed biphasic changes that were much faster than changes in extrinsic (between-source) connections, which decreased monotonically with repetition. This study shows that auditory perceptual learning is associated with repetition-dependent plasticity in the human brain. It is remarkable that distinct changes in intrinsic and extrinsic connections could be quantified so reliably and non-invasively using EEG. {\textcopyright} 2009 Elsevier Inc. All rights reserved.},
author = {Garrido, Marta I. and Kilner, James M. and Kiebel, Stefan J. and Stephan, Klaas E. and Baldeweg, Torsten and Friston, Karl J.},
doi = {10.1016/j.neuroimage.2009.06.034},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Garrido et al.{\_}2009{\_}Repetition suppression and plasticity in the human brain.pdf:pdf},
issn = {10538119},
journal = {NeuroImage},
keywords = {Connectivity,DCM,EEG,Network,Perceptual learning},
month = {oct},
number = {1},
pages = {269--279},
pmid = {19540921},
title = {{Repetition suppression and plasticity in the human brain}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811909006661},
volume = {48},
year = {2009}
}
@incollection{LeCun1999,
author = {LeCun, Yann and Haffner, Patrick and Bottou, L{\'{e}}on and Bengio, Yoshua},
booktitle = {Shape, Contour and Grouping in Computer Vision},
doi = {10.1007/3-540-46805-6_19},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/LeCun et al.{\_}1999{\_}Object Recognition with Gradient-Based Learning.pdf:pdf},
number = {0},
pages = {319--345},
publisher = {Springer},
title = {{Object Recognition with Gradient-Based Learning}},
url = {http://link.springer.com/10.1007/3-540-46805-6{\_}19},
year = {1999}
}
@article{Garrido2007,
abstract = {Neuronal responses to stimuli, measured electrophysiologically, unfold over several hundred milliseconds. Typically, they show characteristic waveforms with early and late components. It is thought that early or exogenous components reflect a perturbation of neuronal dynamics by sensory input bottom-up processing. Conversely, later, endogenous components have been ascribed to recurrent dynamics among hierarchically disposed cortical processing levels, top-down effects. Here, we show that evoked brain responses are generated by recurrent dynamics in cortical networks, and late components of event-related responses are mediated by backward connections. This evidence is furnished by dynamic causal modeling of mismatch responses, elicited in an oddball paradigm. We used the evidence for models with and without backward connections to assess their likelihood as a function of peristimulus time and show that backward connections are necessary to explain late components. Furthermore, we were able to quantify the contribution of backward connections to evoked responses and to source activity, again as a function of peristimulus time. These results link a generic feature of brain responses to changes in the sensorium and a key architectural component of functional anatomy; namely, backward connections are necessary for recurrent interactions among levels of cortical hierarchies. This is the theoretical cornerstone of most modern theories of perceptual inference and learning.},
author = {Garrido, Marta I. and Kilner, James M. and Kiebel, Stefan J. and Friston, Karl J.},
doi = {10.1073/pnas.0706274105},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Garrido et al.{\_}2007{\_}DCM{\_}feedback.pdf:pdf},
isbn = {0706274105},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
keywords = {Adult,Bayes Theorem,Brain,Brain Mapping,Brain: anatomy {\&} histology,Brain: physiology,Electroencephalography,Electroencephalography: methods,Evoked Potentials,Feedback,Female,Humans,Learning,Male,Models,Nerve Net,Neurological,Neurons,Neurons: metabolism,Physiological,Theoretical},
month = {dec},
number = {52},
pages = {20961--20966},
pmid = {18087046},
title = {{Evoked brain responses are generated by feedback loops}},
url = {http://www.pnas.org/cgi/doi/10.1073/pnas.0706274105},
volume = {104},
year = {2007}
}
@article{Chung2015,
abstract = {In this paper, we explore the inclusion of latent random variables into the hidden state of a recurrent neural network (RNN) by combining the elements of the variational autoencoder. We argue that through the use of high-level latent random variables, the variational RNN (VRNN)1 can model the kind of variability observed in highly structured sequential data such as natural speech. We empirically evaluate the proposed model against other related sequential models on four speech datasets and one handwriting dataset. Our results show the important roles that latent random variables can play in the RNN dynamics.},
archivePrefix = {arXiv},
arxivId = {1506.02216},
author = {Chung, Junyoung and Kastner, Kyle and Dinh, Laurent and Goel, Kratarth and Courville, Aaron and Bengio, Yoshua},
eprint = {1506.02216},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Chung et al.{\_}2015{\_}A recurrent latent variable model for sequential data.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
pages = {2980--2988},
title = {{A recurrent latent variable model for sequential data}},
volume = {2015-Janua},
year = {2015}
}
@article{Friston2017,
abstract = {This paper considers functional integration in the brain from a computational perspective. We ask what sort of neuronal message passing is mandated by active inference—and what implications this has for context-sensitive connectivity at microscopic and macroscopic levels. In particular, we formulate neuronal processing as belief propagation under deep generative models. Crucially, these models can entertain both discrete and continuous states, leading to distinct schemes for belief updating that play out on the same (neuronal) architecture. Technically, we use Forney (normal) factor graphs to elucidate the requisite message passing in terms of its form and scheduling. To accommodate mixed generative models (of discrete and continuous states), one also has to consider link nodes or factors that enable discrete and continuous representations to talk to each other. When mapping the implicit computational architecture onto neuronal connectivity, several interesting features emerge. For example, Bayesian model averaging and comparison, which link discrete and continuous states, may be implemented in thalamocortical loops. These and other considerations speak to a computational connectome that is inherently state dependent and self-organizing in ways that yield to a principled (variational) account. We conclude with simulations of reading that illustrate the implicit neuronal message passing, with a special focus on how discrete (semantic) representations inform, and are informed by, continuous (visual) sampling of the sensorium.},
author = {Friston, Karl J. and Parr, Thomas and de Vries, Bert},
doi = {10.1162/NETN_a_00018},
file = {:Users/alejandrodanielnoel1/Documents/Mendeley Desktop/Friston, Parr, de Vries{\_}2017{\_}The graphical brain Belief propagation and active inference.pdf:pdf},
issn = {2472-1751},
journal = {Network Neuroscience},
keywords = {"ADHD,Graph theor,Non-clinical,Symptom strength,adhd,brain networks,graph theory,modularity,nonclinical,symptom strength},
month = {dec},
number = {4},
pages = {381--414},
title = {{The graphical brain: Belief propagation and active inference}},
url = {http://dx.doi.org/10.1162/netn{\_}a{\_}00083 https://www.mitpressjournals.org/doi/abs/10.1162/NETN{\_}a{\_}00018},
volume = {1},
year = {2017}
}
