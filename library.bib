@article{Berner2007,
    abstract = {Range measurements are used to improve the trajectory models of spacecraft tracked by the deep space network. The unique challenge of deep-space ranging is that the two-way delay is long, typically many minutes, and the signal-to-noise ratio is small. Accurate measurements are made under these circumstances by means of long correlations that incorporate Doppler rate-aiding. This processing is done with commercial digital signal processors, providing a flexibility in signal design that can accommodate both the traditional sequential ranging signal and pseudonoise range codes. Accurate range determination requires the calibration of the delay within the tracking station. Measurements with a standard deviation of 1 m have been made. {\textcopyright} 2006 IEEE.},
    author = {Berner, Jeff B. and Bryant, Scott H. and Kinman, Peter W.},
    doi = {10.1109/JPROC.2007.905128},
    issn = {00189219},
    journal = {Proceedings of the IEEE},
    keywords = {Deep Space Network,Pseudonoise ranging,Range measurement,Sequential ranging},
    mendeley-groups = {Thesis Refactored},
    number = {11},
    pages = {2202--2214},
    title = {{Range measurement as practiced in the deep space network}},
    volume = {95},
    year = {2007}
}

% Izzo ellipsoidal gravitational potential 1
@article{Ivory1809,
    author = {J. Ivory.},
    journal = {Philosophical Transactions of the Royal Society of London},
    pages = {345--372},
    title = {{On the Attractions of homogeneous Ellipsoids}},
    volume = {99},
    year = {1809}
}

% Izzo ellipsoidal gravitational potential 2
@book{MacMillan1958,
    author = {W. D. MacMillan,},
    title = {{The Theory of the Potential}},
    year = {1958}
}

% Izzo ellipsoidal gravitational potential 3
@book{Danby1992,
    author = {J. Danby,},
    publisher = {Richmond: Willman-Bell},
    title = {{Fundamentals of Celestial Mechanics}},
    edition = {2},
    volume = {1},
    year = {1992}
}

%
@article{Geodesy1994,
    author = {Geodesy, Planetary},
    keywords = {gravitational potential,phobos,spherical harmonics,topography},
    mendeley-groups = {Thesis Refactored/Ellipsoidal Gravitational Potential},
    pages = {331--364},
    title = {{Balmino Gravitational Potential Harmonics from the Shape of an Homogenous Body (1994)}},
    year = {1994}
}

% MEE: THIS IS NOT THE CORRECT CITATION FOR THIS. IT IS A SUMMARY
@article{Equinoctial,
    abstract = {Modified equinoctial orbital elements},
    author = {Equinoctial, Modified and Elements, Orbital},
    pages = {1--8},
    title = {{Modified equinoctial orbital elements}},
    url = {http://www.cdeagle.com/pdf/mee.pdf}
}


%
@book{Montenbruck2000,
    abstract = {In most of the recent determinations of the geocentric gravitational coefficient (GM) of the earth, the laser ranging data to the Lageos satellite have had the greatest influence on the solution. These data, however, have generally been processed with a small but significant error in one of the range corrections. In a new determination of GM using the corrected center-of-mass offset, a value of 398600.4415 cu km/sq sec (including the mass of the atmosphere) has been obtained, with an estimated uncertainty (1 sigma of 0.0008 cu km/sq sec.},
    author = {Montenbruck, Oliver and Gill, Eberhard},
    booktitle = {Satellite Orbits},
    doi = {10.1007/978-3-642-58351-3},
    file = {:home/ggarrett/Downloads/Oliver Montenbruck, Eberhard Gill - Satellite Orbits_ Models, Methods and Applications-Springer (2005).pdf:pdf},
    isbn = {354067280X},
    mendeley-groups = {Thesis Refactored},
    title = {{Satellite Orbits}},
    year = {2000}
}

% Bellman and "Curse of dimensionality"
@book{bellman1957dynamic,
    title = {Dynamic Programming},
    author = {Bellman, R. and Rand Corporation and Karreman Mathematics Research Collection},
    isbn = {9780691079516},
    lccn = {57005444},
    series = {Rand Corporation research study},
    url = {https://books.google.co.za/books?id=wdtoPwAACAAJ},
    year = {1957},
    publisher = {Princeton University Press}
}

@book{moulton1970introduction,
    title = {An Introduction to Celestial Mechanics},
    author = {Moulton, F.R.},
    isbn = {9780486646879},
    lccn = {79103400},
    series = {Dover books in astronomy},
    url = {https://books.google.co.za/books?id=URPSrBntwdAC},
    year = {1970},
    publisher = {Dover Publications}
}

% WERTZ!
@book{wertz2002mission,
    title = {Mission Geometry; Orbit and Constellation Design and Management: Spacecraft Orbit and Attitude Systems},
    author = {Wertz, J.R.},
    isbn = {9780792371489},
    lccn = {2001054290},
    series = {Space Technology Library},
    url = {https://books.google.co.za/books?id=8VH6wAEACAAJ},
    year = {2002},
    publisher = {Springer Netherlands}
}

@book{bellman1961adaptive,
    title = {Adaptive Control Processes: A Guided Tour},
    author = {Bellman, R. and Bellman, R.E. and Karreman Mathematics Research Collection},
    isbn = {9780691079011},
    lccn = {lc60005740},
    series = {Princeton Legacy Library},
    url = {https://books.google.co.za/books?id=POAmAAAAMAAJ},
    year = {1961},
    publisher = {Princeton University Press}
}


% RL PSACECRAFT GUIDANCE CUBES
@article{Hovell2021,
    doi = {10.2514/1.a34838},
    url = {https://doi.org/10.2514/1.a34838},
    year = {2021},
    month = mar,
    publisher = {American Institute of Aeronautics and Astronautics ({AIAA})},
    volume = {58},
    number = {2},
    pages = {254--264},
    author = {Kirk Hovell and Steve Ulrich},
    title = {Deep Reinforcement Learning for Spacecraft Proximity Operations Guidance},
    journal = {Journal of Spacecraft and Rockets}
}

@book{Dirkx2015,
    abstract = {Measurements of the motion of natural (and artificial) bodies in the solar system provide key input on their interior structre and properties. Currently, the most accurate measurements of solar system dynamics are performed using radiometric tracking systems on planetary missions, providing range measurement with an accuracy in the order of 1 m. Laser ranging to Earth-orbiting satellites equipped with laser retroreflectors provides range data with (sub-)cm accuracy. Extending this technology to planetary missions, however, requires the use of an active space segment equipped with a laser detector and transmitter (for a two-way system). The feasibility of such measurements have been demonstrated at planetary distances, and used operationally (with a one-way system) for the Lunar Reconaissance Orbiter (LRO) mission. The topic of this dissertation is the analysis of the application of interplanetary laser ranging (ILR) to improve the science return from next-generation space missions, with a focus on planetary science objectives. We have simulated laser ranging data for a variety of mission and system architectures, analyzing the influence of both model and measurement uncertainties. Our simulations show that the single-shot measurement precision is relatively inconsequential compared to the systematic range errors, providing a strong rationale for the consistent use of single-photon signal-intensity operation. We find that great advances in planetary geodesy (tidal, rotational characteristics, etc.) could be achieved by ILR. However, the laser data should be accompanied by commensurate improvements in other measurements and data analysis models to maximize the system's science return. The science return from laser ranging data will be especially strong for planetary landers, with a radio system remaining the preferred choice for many orbiter missions. Furthermore, we conclude that the science case for a one-way laser ranging is relatively weak compared to next-generation radiometric tracking systems, requiring the development of much more accurate space-based clocks.},
    author = {Dirkx, D.},
    isbn = {9789462991927},
    mendeley-groups = {Thesis Refactored/Estimation},
    title = {{Interplanetary Laser Ranging}},
    url = {https://repository.tudelft.nl/islandora/object/uuid:bd728e02-f403-4cea-9e2b-65b04b47b3f7?collection=research},
    year = {2015}
}


% Izzo RL Spacecarft
@article{Willis2016,
    abstract = {We use neural reinforcement learning to control a spacecraft around a small celestial body whose gravity field is unknown. The small body is assumed to be a triaxial ellipsoid and its density and dimensions are left unknown within large bounds. We experiment with different proprioceptive capabilities of the spacecraft emphasising lightweight neuromorphic systems for optic flow detection. We find that even in such a highly uncertain environment and using limited perception capabilities, our approach is able to deliver a control strategy able to hover above the asteroid surface with small residual drift.},
    author = {Willis, Stefan and Izzo, Dario and Hennes, Daniel},
    file = {:home/ggarrett/Downloads/ACT-RPR-MAD-2016-NAPA-HoveringOnSmallBodies.pdf:pdf},
    isbn = {9780877036333},
    issn = {00653438},
    journal = {Advances in the Astronautical Sciences},
    mendeley-groups = {Master Thesis/Similar,Master Thesis/Izzo,Thesis Refactored},
    pages = {1351--1368},
    title = {{Reinforcement learning for spacecraft maneuvering near small bodies}},
    volume = {158},
    year = {2016}
}

% Numerical computation of ellipsoid integrals
@article{Johansson2019,
    abstract = {We describe algorithms to compute elliptic functions and their relatives (Jacobi theta functions, modular forms, elliptic integrals, and the arithmetic-geometric mean) numerically to arbitrary precision with rigorous error bounds for arbitrary complex variables. Implementations in ball arithmetic are available in the open source Arb library. We discuss the algorithms from a concrete implementation point of view, with focus on performance at tens to thousands of digits of precision.},
    archivePrefix = {arXiv},
    arxivId = {1806.06725},
    author = {Johansson, Fredrik},
    doi = {10.1007/978-3-030-04480-0_12},
    eprint = {1806.06725},
    file = {:home/ggarrett/Downloads/1806.06725.pdf:pdf},
    mendeley-groups = {Thesis Refactored/Ellipsoidal Gravitational Potential/Numerical Mathematics},
    pages = {269--293},
    title = {{Numerical Evaluation of Elliptic Functions, Elliptic Integrals and Modular Forms}},
    year = {2019}
}

% Computer vision vs DL.
@article{Mahony-et-al-2020,
    title = {Advances in Computer Vision},
    authors = {Niall O' Mahony, Sean Campbell, Anderson Carvalho, Suman
 Harapanahalli, Gustavo Velasco-Hernandez, Lenka Krpalkova, Daniel Riordan,
 Joseph Walsh },
    ISBN = {9783030177959},
    ISSN = {2194-5365},
    url = {http://dx.doi.org/10.1007/978-3-030-17795-9},
    DOI = {10.1007/978-3-030-17795-9},
    journal = {Advances in Intelligent Systems and Computing},
    publisher = {Springer International Publishing},
    year = {2020}
}


% machine learning: coin
@ARTICLE{5392560,

    author = {Samuel, A. L.},

    journal = {IBM Journal of Research and Development},

    title = {Some Studies in Machine Learning Using the Game of Checkers},

    year = {1959},

    volume = {3},

    number = {3},

    pages = {210-229},

    doi = {10.1147/rd.33.0210} }

% deep learning: coin
@inproceedings{Rina1986,
    author = {Dechter, Rina},
    year = {1986},
    month = {01},
    pages = {178-185},
    title = {Learning While Searching in Constraint-Satisfaction-Problems.},
    journal = {AAAI}
}

% ai boom
@misc{hardy_2016, title = {Reasons to Believe the A.I. Boom Is Real}, url = {https://www.nytimes.com/2016/07/19/technology/reasons-to-believe-the-ai-boom-is-real.html}, journal = {The New York Times}, publisher = {The New York Times}, author = {Hardy, Quentin}, year = {2016}, month = {Jul} }


% the explosion of DL
@INPROCEEDINGS{5206848,

    author = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},

    booktitle = {2009 IEEE Conference on Computer Vision and Pattern Recognition},

    title = {ImageNet: A large-scale hierarchical image database},

    year = {2009},

    %    volume = {},
    %
    %    number = {},

    pages = {248-255},

    doi = {10.1109/CVPR.2009.5206848} }


% Machine Learning
@book{Mitchell97,
    abstract = {This book covers the field of machine learning, which is the study of algorithms that allow computer programs to automatically improve through experience. This exciting addition to the McGraw-Hill Series in Computer Science focuses on the concepts and techniques that contribute to the rapidly changing field of machine learning---including probability and statistics, artificial intelligence, and neural networks---unifying them all in a logical and coherent manner.},
    added-at = {2017-05-08T14:37:30.000+0200},
    address = {New York},
    author = {Mitchell, Tom M.},
    biburl = {https://www.bibsonomy.org/bibtex/23e79734ee1a6e49aee02ffd108224d1c/flint63},
    file = {eBook:1900-99/Mitchell97.pdf:PDF;McGraw-Hill Product page:http\://www.mhprofessional.com/product.php?isbn=0070428077:URL;Amazon Search inside:http\://www.amazon.de/gp/reader/0070428077/:URL},
    groups = {public},
    interhash = {479a66c32badb3a455fbdcf8e6633a5d},
    intrahash = {3e79734ee1a6e49aee02ffd108224d1c},
    isbn = {978-0-07-042807-2},
    keywords = {01624 105 book shelf ai learn algorithm},
    publisher = {McGraw-Hill},
    timestamp = {2017-07-13T17:10:10.000+0200},
    title = {Machine Learning},
    username = {flint63},
    year = 1997,
}

@book{Mitchell97LearningAlgorithm,
    abstract = {This book covers the field of machine learning, which is the study of algorithms that allow computer programs to automatically improve through experience. This exciting addition to the McGraw-Hill Series in Computer Science focuses on the concepts and techniques that contribute to the rapidly changing field of machine learning---including probability and statistics, artificial intelligence, and neural networks---unifying them all in a logical and coherent manner.},
    added-at = {2017-05-08T14:37:30.000+0200},
    address = {New York},
    author = {Mitchell, Tom M.},
    biburl = {https://www.bibsonomy.org/bibtex/23e79734ee1a6e49aee02ffd108224d1c/flint63},
    file = {eBook:1900-99/Mitchell97.pdf:PDF;McGraw-Hill Product page:http\://www.mhprofessional.com/product.php?isbn=0070428077:URL;Amazon Search inside:http\://www.amazon.de/gp/reader/0070428077/:URL},
    groups = {public},
    interhash = {479a66c32badb3a455fbdcf8e6633a5d},
    intrahash = {3e79734ee1a6e49aee02ffd108224d1c},
    isbn = {978-0-07-042807-2},
    keywords = {01624 105 book shelf ai learn algorithm},
    publisher = {McGraw-Hill},
    timestamp = {2017-07-13T17:10:10.000+0200},
    title = {Machine Learning},
    username = {flint63},
    year = 1997,
    pages = {97},
}

@book{Goodfellow-et-al-2016,
    title = {Deep Learning},
    author = {Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher = {MIT Press},
    note = {\url{http://www.deeplearningbook.org}},
    year = {2016}
}

@article{Taeihagh2019,
    abstract = {The benefits of autonomous vehicles (AVs) are widely acknowledged, but there are concerns about the extent of these benefits and AV risks and unintended consequences. In this article, we first examine AVs and different categories of the technological risks associated with them. We then explore strategies that can be adopted to address these risks, and explore emerging responses by governments for addressing AV risks. Our analyses reveal that, thus far, governments have in most instances avoided stringent measures in order to promote AV developments and the majority of responses are non-binding and focus on creating councils or working groups to better explore AV implications. The US has been active in introducing legislations to address issues related to privacy and cybersecurity. The UK and Germany, in particular, have enacted laws to address liability issues; other countries mostly acknowledge these issues, but have yet to implement specific strategies. To address privacy and cybersecurity risks strategies ranging from introduction or amendment of non-AV specific legislation to creating working groups have been adopted. Much less attention has been paid to issues such as environmental and employment risks, although a few governments have begun programmes to retrain workers who might be negatively affected.},
    author = {Taeihagh, Araz and Lim, Hazel Si Min},
    doi = {10.1080/01441647.2018.1494640},
    file = {:home/ggarrett/Downloads/1807.05720.pdf:pdf},
    issn = {14645327},
    journal = {Transport Reviews},
    keywords = {Autonomous vehicles,automated driving,cybersecurity,governance,incumbent industries,liability,policy,privacy,risks,safety},
    mendeley-groups = {Thesis Refactored/Machine Learning/Autonomous Vehicles},
    number = {1},
    pages = {103--128},
    title = {{Governing autonomous vehicles: emerging responses for safety, liability, privacy, cybersecurity, and industry risks}},
    volume = {39},
    year = {2019}
}


% perceptron origin
@Techreport{Rosenblatt_1957_6098,
    author = {Rosenblatt, F.},
    address = {Ithaca, New York},
    institution = {Cornell Aeronautical Laboratory},
    month = {January},
    number = {85-460-1},
    title = {The perceptron - A perceiving and recognizing automaton},
    year = {1957},
    title_with_no_special_chars = {The Perceptron A perceiving and recognizing automaton}
}

% origin of perceptron
@article{doi:10.1177/030631296026003005,
    author = {Mikel Olazaran},
    title = {A Sociological Study of the Official History of the Perceptrons Controversy},
    journal = {Social Studies of Science},
    volume = {26},
    number = {3},
    pages = {611-659},
    year = {1996},
    doi = {10.1177/030631296026003005},
    URL = {https://doi.org/10.1177/030631296026003005},
    eprint = {https://doi.org/10.1177/030631296026003005},
    abstract = { In this paper, I analyze the controversy within Artificial Intelligence (AI) which surrounded the `perceptron' project (and neural nets in general) in the late 1950s and early 1960s. I devote particular attention to the proofs and arguments of Minsky and Papert, which were interpreted as showing that further progress in neural nets was not possible, and that this approach to AI had to be abandoned. I maintain that this official interpretation of the debate was a result of the emergence, institutionalization and (importantly) legitimation of the symbolic AI approach (with its resource allocation system and authority structure). At the `research-area' level, there was considerable interpretative flexibility. This interpretative flexibility was further demonstrated by the revival of neural nets in the late 1980s, and subsequent rewriting of the official history of the debate. }
}

% criticism of perceptrons
@book{minsky69perceptrons,
    added-at = {2008-05-16T13:57:01.000+0200},
    address = {Cambridge, MA, USA},
    author = {Minsky, Marvin and Papert, Seymour},
}

% supervised: Dimensionality Reduction
@misc{vogelstein2021supervised,
    title = {Supervised Dimensionality Reduction for Big Data},
    author = {Joshua T. Vogelstein and Eric Bridgeford and Minh Tang and Da Zheng and Christopher Douville and Randal Burns and Mauro Maggioni},
    year = {2021},
    eprint = {1709.01233},
    archivePrefix = {arXiv},
    primaryClass = {stat.ML}
}

% unsupervised learning
@incollection{barlow1999ul,
    added-at = {2008-09-26T11:17:56.000+0200},
    author = {Barlow, H B},
    biburl = {https://www.bibsonomy.org/bibtex/22284e571c9a95e9e81776c58fc3b1dc9/yish},
    booktitle = {Unsupervised Learning: Foundations of Neural Computation},
    editor = {Hinton, Geoffrey E. and Sejnowski, Terrence Joseph},
    interhash = {5e64abe200a2085f210bc836aa8cc6b1},
    intrahash = {2284e571c9a95e9e81776c58fc3b1dc9},
    keywords = {algorithmic computational learning machine unsupervised wleformativeeassessment},
    pages = {1-17},
    publisher = {Bradford Company Scituate, MA, USA},
    timestamp = {2008-09-26T11:18:38.000+0200},
    title = {Unsupervised learning: introduction},
    url = {http://books.google.com/books?id=yj04Y0lje4cC},
    year = 1999
}




% semi-supervised
@book{books/mit/06/CSZ2006,
    added-at = {2019-07-22T00:00:00.000+0200},
    biburl = {https://www.bibsonomy.org/bibtex/265ac136f8b3a44d77fcf9ec42829296a/dblp},
    editor = {Chapelle, Olivier and Schölkopf, Bernhard and Zien, Alexander},
    ee = {https://doi.org/10.7551/mitpress/9780262033589.001.0001},
    interhash = {90eecf83da2790cac977f375160081fe},
    intrahash = {65ac136f8b3a44d77fcf9ec42829296a},
    isbn = {9780262033589},
    keywords = {dblp},
    publisher = {The MIT Press},
    timestamp = {2019-09-17T12:36:24.000+0200},
    title = {Semi-Supervised Learning},
    url = {http://dblp.uni-trier.de/db/books/collections/CSZ2006.html},
    year = 2006
}

% semi-supervised anomaly detection.
@article{DBLP:journals/corr/abs-1805-06725,
    author = {Samet Akcay and
 Amir Atapour Abarghouei and
 Toby P. Breckon},
    title = {GANomaly: Semi-Supervised Anomaly Detection via Adversarial Training},
    journal = {CoRR},
    volume = {abs/1805.06725},
    year = {2018},
    url = {http://arxiv.org/abs/1805.06725},
    eprinttype = {arXiv},
    eprint = {1805.06725},
    timestamp = {Mon, 13 Aug 2018 16:46:23 +0200},
    biburl = {https://dblp.org/rec/journals/corr/abs-1805-06725.bib},
    bibsource = {dblp computer science bibliography, https://dblp.org}
}

% semi-supervised clustering
@article{Bair2013,
    title = {Semi-supervised clustering methods},
    volume = {5},
    ISSN = {1939-5108},
    url = {http://dx.doi.org/10.1002/wics.1270},
    DOI = {10.1002/wics.1270},
    number = {5},
    journal = {Wiley Interdisciplinary Reviews: Computational Statistics},
    publisher = {Wiley},
    author = {Bair, Eric},
    year = {2013},
    month = {Jul},
    pages = {349–361}
}

% semi-supervised: dimensionality reduciton
@inproceedings{Zhang2007,
    author = {Zhang, Daoqiang and Zhou, Zhi-Hua and Chen, Songcan},
    year = {2007},
    month = {04},
    %    pages = {},
    title = {Semi-Supervised Dimensionality Reduction},
    journal = {SIAM Data Mining},
    doi = {10.1137/1.9781611972771.73}
}

% example of structures parsing task:
@InProceedings{pmlr-v15-collobert11a,
    title = {Deep Learning for Efficient Discriminative Parsing},
    author = {Collobert, Ronan},
    booktitle = {Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
    pages = {224--232},
    year = {2011},
    editor = {Gordon, Geoffrey and Dunson, David and Dudík, Miroslav},
    volume = {15},
    series = {Proceedings of Machine Learning Research},
    address = {Fort Lauderdale, FL, USA},
    month = {11--13 Apr},
    publisher = {PMLR},
    pdf = {http://proceedings.mlr.press/v15/collobert11a/collobert11a.pdf},
    url = {https://proceedings.mlr.press/v15/collobert11a.html},
    abstract = {We propose a new fast purely discriminative algorithm for natural language parsing, based on a “deep” recurrent convolutional graph transformer network (GTN). Assuming a decomposition of a parse tree into a stack of “levels”, the network predicts a level of the tree taking into account predictions of previous levels. Using only few basic text features, we show similar performance (in F1 score) to existing pure discriminative parsers and existing “benchmark” parsers (like Collins parser, probabilistic context-free grammars based), with a huge speed advantage. [pdf][supplementary]}
}

% aviation anomaly detection
@Article{Basora2019,
    AUTHOR = {Basora, Luis and Olive, Xavier and Dubot, Thomas},
    TITLE = {Recent Advances in Anomaly Detection Methods Applied to Aviation},
    JOURNAL = {Aerospace},
    VOLUME = {6},
    YEAR = {2019},
    NUMBER = {11},
    ARTICLE-NUMBER = {117},
    URL = {https://www.mdpi.com/2226-4310/6/11/117},
    ISSN = {2226-4310},
    ABSTRACT = {Anomaly detection is an active area of research with numerous methods and applications. This survey reviews the state-of-the-art of data-driven anomaly detection techniques and their application to the aviation domain. After a brief introduction to the main traditional data-driven methods for anomaly detection, we review the recent advances in the area of neural networks, deep learning and temporal-logic based learning. In particular, we cover unsupervised techniques applicable to time series data because of their relevance to the aviation domain, where the lack of labeled data is the most usual case, and the nature of flight trajectories and sensor data is sequential, or temporal. The advantages and disadvantages of each method are presented in terms of computational efficiency and detection efficacy. The second part of the survey explores the application of anomaly detection techniques to aviation and their contributions to the improvement of the safety and performance of flight operations and aviation systems. As far as we know, some of the presented methods have not yet found an application in the aviation domain. We review applications ranging from the identification of significant operational events in air traffic operations to the prediction of potential aviation system failures for predictive maintenance.},
    DOI = {10.3390/aerospace6110117}
}

@INPROCEEDINGS{Janakiraman2016,
    author = {Janakiraman, Vijay Manikandan and Nielsen, David},
    booktitle = {2016 International Joint Conference on Neural Networks (IJCNN)},
    title = {Anomaly detection in aviation data using extreme learning machines},
    year = {2016},
    volume = {},
    number = {},
    pages = {1993-2000},
    doi = {10.1109/IJCNN.2016.7727444} }

% GPT-3 synthesis examples
@article{DBLP:journals/corr/abs-2005-14165,
    author = {Tom B. Brown and
 Benjamin Mann and
 Nick Ryder and
 Melanie Subbiah and
 Jared Kaplan and
 Prafulla Dhariwal and
 Arvind Neelakantan and
 Pranav Shyam and
 Girish Sastry and
 Amanda Askell and
 Sandhini Agarwal and
 Ariel Herbert{-}Voss and
 Gretchen Krueger and
 Tom Henighan and
 Rewon Child and
 Aditya Ramesh and
 Daniel M. Ziegler and
 Jeffrey Wu and
 Clemens Winter and
 Christopher Hesse and
 Mark Chen and
 Eric Sigler and
 Mateusz Litwin and
 Scott Gray and
 Benjamin Chess and
 Jack Clark and
 Christopher Berner and
 Sam McCandlish and
 Alec Radford and
 Ilya Sutskever and
 Dario Amodei},
    title = {Language Models are Few-Shot Learners},
    journal = {CoRR},
    volume = {abs/2005.14165},
    year = {2020},
    url = {https://arxiv.org/abs/2005.14165},
    eprinttype = {arXiv},
    eprint = {2005.14165},
    timestamp = {Wed, 03 Jun 2020 11:36:54 +0200},
    biburl = {https://dblp.org/rec/journals/corr/abs-2005-14165.bib},
    bibsource = {dblp computer science bibliography, https://dblp.org}
}

% credit card fraud
@article{DBLP:journals/corr/abs-2108-10005,
    author = {Pooja Tiwari and
 Simran Mehta and
 Nishtha Sakhuja and
 Jitendra Kumar and
 Ashutosh Kumar Singh},
    title = {Credit Card Fraud Detection using Machine Learning: {A} Study},
    journal = {CoRR},
    volume = {abs/2108.10005},
    year = {2021},
    url = {https://arxiv.org/abs/2108.10005},
    eprinttype = {arXiv},
    eprint = {2108.10005},
    timestamp = {Fri, 27 Aug 2021 15:02:29 +0200},
    biburl = {https://dblp.org/rec/journals/corr/abs-2108-10005.bib},
    bibsource = {dblp computer science bibliography, https://dblp.org}
}
% imputation of missing values: machine learning
@Article{Emmanuel2021,
    author = {Emmanuel, Tlamelo
 and Maupong, Thabiso
 and Mpoeleng, Dimane
 and Semong, Thabo
 and Mphago, Banyatsang
 and Tabona, Oteng},
    title = {A survey on missing data in machine learning},
    journal = {Journal of Big Data},
    year = {2021},
    month = {Oct},
    day = {27},
    volume = {8},
    number = {1},
    pages = {140},
    abstract = {Machine learning has been the corner stone in analysing and extracting information from data and often a problem of missing values is encountered. Missing values occur because of various factors like missing completely at random, missing at random or missing not at random. All these may result from system malfunction during data collection or human error during data pre-processing. Nevertheless, it is important to deal with missing values before analysing data since ignoring or omitting missing values may result in biased or misinformed analysis. In literature there have been several proposals for handling missing values. In this paper, we aggregate some of the literature on missing data particularly focusing on machine learning techniques. We also give insight on how the machine learning approaches work by highlighting the key features of missing values imputation techniques, how they perform, their limitations and the kind of data they are most suitable for. We propose and evaluate two methods, the k nearest neighbor and an iterative imputation method (missForest) based on the random forest algorithm. Evaluation is performed on the Iris and novel power plant fan data with induced missing values at missingness rate of 5{\%} to 20{\%}. We show that both missForest and the k nearest neighbor can successfully handle missing values and offer some possible future research direction.},
    issn = {2196-1115},
    doi = {10.1186/s40537-021-00516-9},
    url = {https://doi.org/10.1186/s40537-021-00516-9}
}

% no free lunch theorem  : https://machinelearningmastery.com/no-free-lunch-theorem-for-machine-learning/
@ARTICLE{585893,
    author = {Wolpert, D.H. and Macready, W.G.},
    journal = {IEEE Transactions on Evolutionary Computation},
    title = {No free lunch theorems for optimization},
    year = {1997},
    volume = {1},
    number = {1},
    pages = {67-82},
    doi = {10.1109/4235.585893} }

% no free lunch theorem  : https://machinelearningmastery.com/no-free-lunch-theorem-for-machine-learning/
@book{luke2012essentials,
    title = {Essentials of Metaheuristics (Second Edition)},
    author = {Luke, S.},
    isbn = {9781300549628},
    url = {https://books.google.co.za/books?id=5FDdsgEACAAJ},
    year = {2012},
    publisher = {Lulu.com}
}

@incollection{Wolpert2002,
    doi = {10.1007/978-1-4471-0123-9_3},
    url = {https://doi.org/10.1007/978-1-4471-0123-9_3},
    year = {2002},
    publisher = {Springer London},
    pages = {25--42},
    author = {David H. Wolpert},
    title = {The Supervised Learning No-Free-Lunch Theorems},
    booktitle = {Soft Computing and Industry}
}

% imputation of missing frames from a video
@article{huang2020rife,
    title = {RIFE: Real-Time Intermediate Flow Estimation for Video Frame Interpolation},
    author = {Huang, Zhewei and Zhang, Tianyuan and Heng, Wen and Shi, Boxin and Zhou, Shuchang},
    journal = {arXiv preprint arXiv:2011.06294},
    year = {2020}
}

@report{Wolpert1997,
    abstract = {A framework is developed to explore the connection between effective optimization algorithms and the problems they are solving. A number of "no free lunch" (NFL) theorems are presented which establish that for any algorithm, any elevated performance over one class of problems is offset by performance over another class. These theorems result in a geometric interpretation of what it means for an algorithm to be well suited to an optimization problem. Applications of the NFL theorems to information-theoretic aspects of optimization and benchmark measures of performance are also presented. Other issues addressed include time-varying optimization problems and a priori "head-to-head" minimax distinctions between optimization algorithms, distinctions that result despite the NFL theorems' enforcing of a type of uniformity over all algorithms.},
    author = {David H Wolpert and William G Macready},
    issue = {1},
    journal = {IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION},
    keywords = {Index Terms-Evolutionary algorithms,information theory,optimization},
    pages = {67},
    title = {No Free Lunch Theorems for Optimization},
    volume = {1},
    year = {1997},
}

@book{Domingos15,
    abstract = {Society is changing, one learning algorithm at a time, from search engines to online dating, personalized medicine to predicting the stock market. But learning algorithms are not just about Big Data - these algorithms take raw data and make it useful by creating more algorithms. This is something new under the sun: a technology that builds itself. In this book, Domingos reveals how machine learning is remaking business, politics, science and war. And he takes us on an awe-inspiring quest to find 'The Master Algorithm' - a universal learner capable of deriving all knowledge from data.},
    added-at = {2018-04-15T13:17:55.000+0200},
    address = {New York},
    author = {Domingos, Pedro},
    biburl = {https://www.bibsonomy.org/bibtex/2b48e9f824f83e98a132511b244ed8ad0/flint63},
    file = {eBook:2015/Domingos15.pdf:PDF;Basic Books Product Page:https\://www.basicbooks.com/titles/pedro-domingos/the-master-algorithm/9780465065707/:URL;Penguin Books Paperback:https\://www.penguin.co.uk/books/269590/the-master-algorithm/:URL;Amazon Search inside:http\://www.amazon.de/gp/reader/0465065708/:URL},
    groups = {public},
    interhash = {3d8bc19852ad9cab7580e2e00322a9c2},
    intrahash = {b48e9f824f83e98a132511b244ed8ad0},
    isbn = {978-0-465-06570-7},
    keywords = {01801 105 book shelf numerical ai science economy data information knowledge processing learn algorithm zzz.big},
    publisher = {Basic Books},
    timestamp = {2018-04-16T11:32:18.000+0200},
    title = {The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World},
    username = {flint63},
    year = 2015
}
@book{hastie2009elements,
    title = {The Elements of Statistical Learning: Data Mining, Inference, and Prediction},
    author = {Hastie, T. and Tibshirani, R. and Friedman, J.H.},
    isbn = {9780387848846},
    lccn = {2008941148},
    series = {Springer series in statistics},
    url = {https://books.google.co.za/books?id=eBSgoAEACAAJ},
    year = {2009},
    publisher = {Springer}
}

% regularization can improve generalization
@inproceedings{NIPS1991_8eefcfdf,
    author = {Krogh, Anders and Hertz, John},
    booktitle = {Advances in Neural Information Processing Systems},
    editor = {J. Moody and S. Hanson and R. P. Lippmann},
    pages = {},
    publisher = {Morgan-Kaufmann},
    title = {A Simple Weight Decay Can Improve Generalization},
    url = {https://proceedings.neurips.cc/paper/1991/file/8eefcfdf5990e441f0fb6f3fad709e21-Paper.pdf},
    volume = {4},
    year = {1992}
}

% elastic net penality
@ARTICLE{ZouHastie2005,
    title = {Regularization and variable selection via the elastic net},
    author = {Zou, Hui and Hastie, Trevor},
    year = {2005},
    journal = {Journal of the Royal Statistical Society Series B},
    volume = {67},
    number = {2},
    pages = {301-320},
    abstract = {Summary. We propose the elastic net, a new regularization and variable selection method. Real world data and a simulation study show that the elastic net often outperforms the lasso, while enjoying a similar sparsity of representation. In addition, the elastic net encourages a grouping effect, where strongly correlated predictors tend to be in or out of the model together. The elastic net is particularly useful when the number of predictors (p) is much bigger than the number of observations (n). By contrast, the lasso is not a very satisfactory variable selection method in the p≫n case. An algorithm called LARS‐EN is proposed for computing elastic net regularization paths efficiently, much like algorithm LARS does for the lasso.},
    url = {https://EconPapers.repec.org/RePEc:bla:jorssb:v:67:y:2005:i:2:p:301-320}
}

% cross validation
@Inbook{Refaeilzadeh2009,
    author = "Refaeilzadeh, Payam
              and Tang, Lei
              and Liu, Huan",
    editor = "LIU, LING
              and {\"O}ZSU, M. TAMER",
    title = "Cross-Validation",
    bookTitle = "Encyclopedia of Database Systems",
    year = "2009",
    publisher = "Springer US",
    address = "Boston, MA",
    pages = "532--538",
    isbn = "978-0-387-39940-9",
    doi = "10.1007/978-0-387-39940-9_565",
    url = "https://doi.org/10.1007/978-0-387-39940-9_565"
}

%    the embryo of an electronic computer that [the Navy] expects will be able
%    to walk, talk, see, write, reproduce itself and be conscious of its
%    existence.
@article{Olazaran1996,
    doi = {10.1177/030631296026003005},
    url = {https://doi.org/10.1177/030631296026003005},
    year = {1996},
    month = aug,
    publisher = {{SAGE} Publications},
    volume = {26},
    number = {3},
    pages = {611--659},
    author = {Mikel Olazaran},
    title = {A Sociological Study of the Official History of the Perceptrons Controversy},
    journal = {Social Studies of Science}
}


%https://towardsdatascience.com/regularization-in-machine-learning-76441ddcf99a
%https://towardsdatascience.com/l1-and-l2-regularization-methods-ce25e7fc831c


@Article{McCulloch1943,
    author = {McCulloch, Warren S.
and Pitts, Walter},
    title = {A logical calculus of the ideas immanent in nervous activity},
    journal = {The bulletin of mathematical biophysics},
    year = {1943},
    month = {Dec},
    day = {01},
    volume = {5},
    number = {4},
    pages = {115-133},
    abstract = {Because of the ``all-or-none'' character of nervous activity, neural events and the relations among them can be treated by means of propositional logic. It is found that the behavior of every net can be described in these terms, with the addition of more complicated logical means for nets containing circles; and that for any logical expression satisfying certain conditions, one can find a net behaving in the fashion it describes. It is shown that many particular choices among possible neurophysiological assumptions are equivalent, in the sense that for every net behaving under one assumption, there exists another net which behaves under the other and gives the same results, although perhaps not in the same time. Various applications of the calculus are discussed.},
    issn = {1522-9602},
    doi = {10.1007/BF02478259},
    url = {https://doi.org/10.1007/BF02478259}
}

@InProceedings{10.1007/978-3-642-70911-1_15,
    author = "Shaw, G. L.",
    editor = "Palm, G{\"u}nther
and Aertsen, Ad",
    title = "Donald Hebb: The Organization of Behavior",
    booktitle = "Brain Theory",
    year = "1986",
    publisher = "Springer Berlin Heidelberg",
    address = "Berlin, Heidelberg",
    pages = "231--233",
    abstract = "I consider this a great privilege to be able to briefly remark on D.O. Hebb's marvellous book ``Organization of Behavior: A Neuropsychological Theory'' which he wrote in 1949. Hebb's ideas have had a profound influence on brain theory, in particular his famous ``A Neurophysiological Postulate'' governing the correlated pre-post synaptic changes which are the basis for the engram or memory trace. Although, there are many different forms of Hebb's postulate, I believe that essentially all ``viable'' mammalian cortical models embody some version of his idea: ``Let us assume then that the persistence or repetition of a reverberatory activity (or ``trace'') tends to induce lasting cellular changes that add to its stability. The assumption can be precisely stated as follows:When an axon of cell A is near enough to excite cell B and repeatedly or persistently takes part in firing it, some growth process or metabolic change takes place in one or both cells such that A `s efficiency, as one of the cells firing B, is increased''.",
    isbn = "978-3-642-70911-1"
}

@article{doi:10.1126/science.7912852,
    author = {Matthew B. Dalva and Lawrence C. Katz },
    title = {Rearrangements of Synaptic Connections in Visual Cortex Revealed by Laser Photostimulation},
    journal = {Science},
    volume = {265},
    number = {5169},
    pages = {255-258},
    year = {1994},
    doi = {10.1126/science.7912852},
    URL = {https://www.science.org/doi/abs/10.1126/science.7912852},
    eprint = {https://www.science.org/doi/pdf/10.1126/science.7912852},
    abstract = { Assessing patterns of synaptic connections in the developing mammalian neocortex has relied primarily on anatomical studies. In a physiological approach described here, the patterns of synaptic connections in slices of developing ferret visual cortex were determined with scanning laser photostimulation. Functional synaptic inputs to pyramidal cells in cortical layers 2 and 3 originating from sites close to the neuronal cell body appeared at least 2 weeks before eye opening, prior to the formation of long-range horizontal connections. Extensive long-range horizontal connections appeared in the next 10 days of development. The number of local connections peaked at the time of eye opening; the number of these connections subsequently declined to the level found in the adult while the specificity of long-distance connections increased. Thus, the relative influence of local connections on the activity of layer 2 and layer 3 neurons declines as the cortex matures while the influence of longer range connections increases substantially. }
}

% NN OPTIMIZATION: Learning to Optimize
@article{Li2017,
    abstract = {Learning to Optimize is a recently proposed framework for learning optimization algorithms using reinforcement learning. In this paper, we explore learning an optimization algorithm for training shallow neural nets. Such high-dimensional stochastic optimization problems present interesting challenges for existing reinforcement learning algorithms. We develop an extension that is suited to learning optimization algorithms in this setting and demonstrate that the learned optimization algorithm consistently outperforms other known optimization algorithms even on unseen tasks and is robust to changes in stochasticity of gradients and the neural net architecture. More specifically, we show that an optimization algorithm trained with the proposed method on the problem of training a neural net on MNIST generalizes to the problems of training neural nets on the Toronto Faces Dataset, CIFAR-10 and CIFAR-100.},
    author = {Ke Li and Jitendra Malik},
    month = {3},
    title = {Learning to Optimize Neural Nets},
    url = {http://arxiv.org/abs/1703.00441},
    year = {2017},
}

% NN OPTIMIZATION: Adam
@misc{kingma2015adam,
    title = {Adam: A Method for Stochastic Optimization},
    author = {Diederik P. Kingma and Jimmy Ba},
    year = {2017},
    eprint = {1412.6980},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG}
}

% NN OPTIMIZATION: Overview
@misc{ruder2017overview,
    title = {An overview of gradient descent optimization algorithms},
    author = {Sebastian Ruder},
    year = {2017},
    eprint = {1609.04747},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG}
}

# momentum
@article{QIAN1999145,
    title = {On the momentum term in gradient descent learning algorithms},
    journal = {Neural Networks},
    volume = {12},
    number = {1},
    pages = {145-151},
    year = {1999},
    issn = {0893-6080},
    doi = {https://doi.org/10.1016/S0893-6080(98)00116-6},
    url = {https://www.sciencedirect.com/science/article/pii/S0893608098001166},
    author = {Ning Qian},
    keywords = {Momentum, Gradient descent learning algorithm, Damped harmonic oscillator, Critical damping, Learning rate, Speed of convergence},
    abstract = {A momentum term is usually included in the simulations of connectionist learning algorithms. Although it is well known that such a term greatly improves the speed of learning, there have been few rigorous studies of its mechanisms. In this paper, I show that in the limit of continuous time, the momentum parameter is analogous to the mass of Newtonian particles that move through a viscous medium in a conservative force field. The behavior of the system near a local minimum is equivalent to a set of coupled and damped harmonic oscillators. The momentum term improves the speed of convergence by bringing some eigen components of the system closer to critical damping. Similar results can be obtained for the discrete time case used in computer simulations. In particular, I derive the bounds for convergence on learning-rate and momentum parameters, and demonstrate that the momentum term can increase the range of learning rate over which the system converges. The optimal condition for convergence is also analyzed.}
}

# NAG
@inproceedings{Nesterov1983AMF,
    title = {A method for unconstrained convex minimization problem with the rate of convergence o(1/k^2)},
    author = {Yurii Nesterov},
    year = {1983}
}

# adagrad
@article{JMLR:v12:duchi11a,
    author = {John Duchi and Elad Hazan and Yoram Singer},
    title = {Adaptive Subgradient Methods for Online Learning and Stochastic Optimization},
    journal = {Journal of Machine Learning Research},
    year = {2011},
    volume = {12},
    number = {61},
    pages = {2121-2159},
    url = {http://jmlr.org/papers/v12/duchi11a.html}
}

# adadelta
@misc{zeiler2012adadelta,
    title = {ADADELTA: An Adaptive Learning Rate Method},
    author = {Matthew D. Zeiler},
    year = {2012},
    eprint = {1212.5701},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG}
}


@inproceedings{NIPS2014_5cce8ded,
    author = {McMahan, Brendan and Streeter, Matthew},
    booktitle = {Advances in Neural Information Processing Systems},
    editor = {Z. Ghahramani and M. Welling and C. Cortes and N. Lawrence and K. Q. Weinberger},
    pages = {},
    publisher = {Curran Associates, Inc.},
    title = {Delay-Tolerant Algorithms for Asynchronous Distributed Online Learning},
    url = {https://proceedings.neurips.cc/paper/2014/file/5cce8dede893813f879b873962fb669f-Paper.pdf},
    volume = {27},
    year = {2014}
}

@inproceedings{Kothari2020,
    abstract = {Machine learning, particularly deep learning, is being increasing utilised in space applications, mirroring the groundbreaking success in many earthbound problems. Deploying a space device, e.g. a satellite, is becoming more accessible to small actors due to the development of modular satellites and commercial space launches, which fuels further growth of this area. Deep learning's ability to deliver sophisticated computational intelligence makes it an attractive option to facilitate various tasks on space devices and reduce operational costs. In thiswork,we identify deep learning in space as one of development directions for mobile and embedded machine learning. We collate various applications of machine learning to space data, such as satellite imaging, and describe how on-device deep learning can meaningfully improve the operation of a spacecraft, such as by reducing communication costs or facilitating navigation.We detail and contextualise compute platform of satellites and draw parallels with embedded systems and current research in deep learning for resource-constrained environments.},
    author = {Vivek Kothari and Edgar Liberis and Nicholas D. Lane},
    doi = {10.1145/3376897.3377864},
    isbn = {9781450371162},
    journal = {HotMobile 2020 - Proceedings of the 21st International Workshop on Mobile Computing Systems and Applications},
    keywords = {Autonomy,Deep Learning,Hardware in Space},
    month = {3},
    pages = {45-49},
    publisher = {Association for Computing Machinery, Inc},
    title = {The final frontier: Deep learning in space},
    year = {2020},
}

@misc{esa_ai, title = {Artificial Intelligence in space}, url = {https://www.esa.int/Enabling_Support/Preparing_for_the_Future/Discovery_and_Preparation/Artificial_intelligence_in_space}, journal = {ESA} }


@generic{Montavon2018,
    abstract = {This paper provides an entry point to the problem of interpreting a deep neural network model and explaining its predictions. It is based on a tutorial given at ICASSP 2017. As a tutorial paper, the set of methods covered here is not exhaustive, but sufficiently representative to discuss a number of questions in interpretability, technical challenges, and possible applications. The second part of the tutorial focuses on the recently proposed layer-wise relevance propagation (LRP) technique, for which we provide theory, recommendations, and tricks, to make most efficient use of it on real data.},
    author = {Grégoire Montavon and Wojciech Samek and Klaus Robert Müller},
    doi = {10.1016/j.dsp.2017.10.011},
    issn = {10512004},
    journal = {Digital Signal Processing: A Review Journal},
    keywords = {Activation maximization,Deep neural networks,Layer-wise relevance propagation,Sensitivity analysis,Taylor decomposition},
    month = {2},
    pages = {1-15},
    publisher = {Elsevier Inc.},
    title = {Methods for interpreting and understanding deep neural networks},
    volume = {73},
    year = {2018},
}

@generic{Sheu2020,
    abstract = {Psychiatric research is often confronted with complex abstractions and dynamics that are not readily accessible or well-defined to our perception and measurements, making data-driven methods an appealing approach. Deep neural networks (DNNs) are capable of automatically learning abstractions in the data that can be entirely novel and have demonstrated superior performance over classical machine learning models across a range of tasks and, therefore, serve as a promising tool for making new discoveries in psychiatry. A key concern for the wider application of DNNs is their reputation as a “black box” approach—i.e., they are said to lack transparency or interpretability of how input data are transformed to model outputs. In fact, several existing and emerging tools are providing improvements in interpretability. However, most reviews of interpretability for DNNs focus on theoretical and/or engineering perspectives. This article reviews approaches to DNN interpretability issues that may be relevant to their application in psychiatric research and practice. It describes a framework for understanding these methods, reviews the conceptual basis of specific methods and their potential limitations, and discusses prospects for their implementation and future directions.},
    author = {Yi Han Sheu},
    doi = {10.3389/fpsyt.2020.551299},
    issn = {16640640},
    journal = {Frontiers in Psychiatry},
    keywords = {deep learning,deep neural networks,explainable AI,machine learning,model interpretability,psychiatry},
    month = {10},
    publisher = {Frontiers Media S.A.},
    title = {Illuminating the Black Box: Interpreting Deep Neural Network Models for Psychiatric Research},
    volume = {11},
    year = {2020},
}

@article{goh2021multimodal,
    author = {Goh, Gabriel and †, Nick Cammarata and †, Chelsea Voss and Carter, Shan and Petrov, Michael and Schubert, Ludwig and Radford, Alec and Olah, Chris},
    title = {Multimodal Neurons in Artificial Neural Networks},
    journal = {Distill},
    year = {2021},
    note = {https://distill.pub/2021/multimodal-neurons},
    doi = {10.23915/distill.00030}
}

@misc{molnar_2022, title = {Interpretable machine learning}, url = {https://christophm.github.io/interpretable-ml-book/neural-networks.html}, journal = {Chapter 10 Neural Network Interpretation}, author = {Molnar, Christoph}, year = {2022}, month = {Jan} }


@article{IzzoGeodesyNet2021,
    abstract = {We present a novel approach based on artificial neural networks, so-called geodesyNets, and present compelling evidence of their ability to serve as accurate geodetic models of highly irregular bodies using minimal prior information on the body. The approach does not rely on the body shape information but, if available, can harness it. GeodesyNets learn a three-dimensional, differentiable, function representing the body density, which we call neural density field. The body shape, as well as other geodetic properties, can easily be recovered. We investigate six different shapes including the bodies 101955 Bennu, 67P Churyumov-Gerasimenko, 433 Eros and 25143 Itokawa for which shape models developed during close proximity surveys are available. Both heterogeneous and homogeneous mass distributions are considered. The gravitational acceleration computed from the trained geodesyNets models, as well as the inferred body shape, show great accuracy in all cases with a relative error on the predicted acceleration smaller than 1\% even close to the asteroid surface. When the body shape information is available, geodesyNets can seamlessly exploit it and be trained to represent a high-fidelity neural density field able to give insights into the internal structure of the body. This work introduces a new unexplored approach to geodesy, adding a powerful tool to consolidated ones based on spherical harmonics, mascon models and polyhedral gravity.},
    author = {Dario Izzo and Pablo Gómez},
    month = {5},
    title = {Geodesy of irregular small bodies via neural density fields: geodesyNets},
    url = {http://arxiv.org/abs/2105.13031},
    year = {2021},
}

@article{IzzoBennu2021,
    abstract = {Asteroids and other small bodies in the solar system tend to have irregular shapes, owing to their low gravity. This irregularity does not only apply to the topology, but also to the underlying geology, potentially containing regions of different densities and materials. The topology can be derived from optical observations, while the mass density distribution of an object is only observable, to some extent, in its gravitational field. In a companion paper, we presented geodesyNets, a neural network approach to infer the mass density distribution of an object from measurements of its gravitational field. In the present work, we apply this approach to the asteroid Bennu using real data from the Osiris Rex mission. The mission measured the trajectories of not only the Osiris Rex spacecraft itself, but also of numerous pebble-sized rock particles which temporarily orbited Bennu. From these trajectory data, we obtain a representation of Bennu's mass density and validate it by propagating, in the resulting gravity field, multiple pebbles not used in the training process. The performance is comparable to that of a polyhedral gravity model of uniform density, but does not require a shape model. As little additional information is needed, we see this as a step towards autonomous on-board inversion of gravitational fields.},
    author = {Moritz von Looz and Pablo Gomez and Dario Izzo},
    month = {9},
    title = {Study of the asteroid Bennu using geodesyANNs and Osiris-Rex data},
    url = {http://arxiv.org/abs/2109.14427},
    year = {2021},
}

@inproceedings{belinkov-etal-2020-interpretability,
    title = "Interpretability and Analysis in Neural {NLP}",
    author = "Belinkov, Yonatan  and
      Gehrmann, Sebastian  and
      Pavlick, Ellie",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-tutorials.1",
    doi = "10.18653/v1/2020.acl-tutorials.1",
    pages = "1--5",
    abstract = "While deep learning has transformed the natural language processing (NLP) field and impacted the larger computational linguistics community, the rise of neural networks is stained by their opaque nature: It is challenging to interpret the inner workings of neural network models, and explicate their behavior. Therefore, in the last few years, an increasingly large body of work has been devoted to the analysis and interpretation of neural network models in NLP. This body of work is so far lacking a common framework and methodology. Moreover, approaching the analysis of modern neural networks can be difficult for newcomers to the field. This tutorial aims to fill this gap and introduce the nascent field of interpretability and analysis of neural networks in NLP. The tutorial will cover the main lines of analysis work, such as structural analyses using probing classifiers, behavioral studies and test suites, and interactive visualizations. We will highlight not only the most commonly applied analysis methods, but also the specific limitations and shortcomings of current approaches, in order to inform participants where to focus future efforts.",
}

@article{DBLP:journals/corr/abs-2108-04840,
    author = {Andreas Madsen and
 Siva Reddy and
 Sarath Chandar},
    title = {Post-hoc Interpretability for Neural {NLP:} {A} Survey},
    journal = {CoRR},
    volume = {abs/2108.04840},
    year = {2021},
    url = {https://arxiv.org/abs/2108.04840},
    eprinttype = {arXiv},
    eprint = {2108.04840},
    timestamp = {Wed, 18 Aug 2021 19:45:42 +0200},
    biburl = {https://dblp.org/rec/journals/corr/abs-2108-04840.bib},
    bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1802-00121,
    author = {Quanshi Zhang and
 Yu Yang and
 Ying Nian Wu and
 Song{-}Chun Zhu},
    title = {Interpreting CNNs via Decision Trees},
    journal = {CoRR},
    volume = {abs/1802.00121},
    year = {2018},
    url = {http://arxiv.org/abs/1802.00121},
    eprinttype = {arXiv},
    eprint = {1802.00121},
    timestamp = {Tue, 06 Jul 2021 11:50:29 +0200},
    biburl = {https://dblp.org/rec/journals/corr/abs-1802-00121.bib},
    bibsource = {dblp computer science bibliography, https://dblp.org}
}


@misc{planetary_data,
    author = {Tedesco, E.F., P.V. Noah, M. Noah, and S.D. Price.},
    title = {IRAS Minor Planet Survey},
    volume = {abs/1802.00121},
    journal = {NASA Planetary Data System},
    year = {2004},
    url = {http://www.psi.edu/pds/resource/imps.html},
}


@misc{parfeni2020detection,
    title = {Detection of asteroid trails in Hubble Space Telescope images using Deep Learning},
    author = {Andrei A. Parfeni and Laurentiu I. Caramete and Andreea M. Dobre and Nguyen Tran Bach},
    year = {2020},
    eprint = {2010.15425},
    archivePrefix = {arXiv},
    primaryClass = {astro-ph.IM}
}

@article{Chyba_Rabeendran_2021,
    doi = {10.1088/1538-3873/abc900},
    url = {https://doi.org/10.1088/1538-3873/abc900},
    year = 2021,
    month = {feb},
    publisher = {{IOP} Publishing},
    volume = {133},
    number = {1021},
    pages = {034501},
    author = {Amandin Chyba Rabeendran and Larry Denneau},
    title = {A Two-stage Deep Learning Detection Classifier for the {ATLAS} Asteroid Survey},
    journal = {Publications of the Astronomical Society of the Pacific},
    abstract = {In this paper we present a two-step neural network model to separate detections of solar system objects from optical and electronic artifacts in data obtained with the “Asteroid Terrestrial-impact Last Alert System” (ATLAS), a near-Earth asteroid sky survey system. A convolutional neural network is used to classify small “postage-stamp” images of candidate detections of astronomical sources into eight classes, followed by a multi-layered perceptron that provides a probability that a temporal sequence of four candidate detections represents a real astronomical source. The goal of this work is to reduce the time delay between Near-Earth Object (NEO) detections and submission to the Minor Planet Center. Due to the rare and hazardous nature of NEOs, a low false negative rate is a priority for the model. We show that the model reaches 99.6% accuracy on real asteroids in ATLAS data with a 0.4% false negative rate. Deployment of this model on ATLAS has reduced the amount of NEO candidates that astronomers must screen by 90%, thereby bringing ATLAS one step closer to full autonomy.}
}


@misc{bird2020model,
    title = {Model Optimization for Deep Space Exploration via Simulators and Deep Learning},
    author = {James Bird and Kellan Colburn and Linda Petzold and Philip Lubin},
    year = {2020},
    eprint = {2012.14092},
    archivePrefix = {arXiv},
    primaryClass = {astro-ph.IM}
}

@article{https://doi.org/10.1029/JA083iA06p02637,
    author = {Kessler, Donald J. and Cour-Palais, Burton G.},
    title = {Collision frequency of artificial satellites: The creation of a debris belt},
    journal = {Journal of Geophysical Research: Space Physics},
    volume = {83},
    number = {A6},
    pages = {2637-2646},
    doi = {https://doi.org/10.1029/JA083iA06p02637},
    url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/JA083iA06p02637},
    eprint = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/JA083iA06p02637},
    abstract = {As the number of artificial satellites in earth orbit increases, the probability of collisions between satellites also increases. Satellite collisions would produce orbiting fragments, each of which would increase the probability of further collisions, leading to the growth of a belt of debris around the earth. This process parallels certain theories concerning the growth of the asteroid belt. The debris flux in such an earth-orbiting belt could exceed the natural meteoroid flux, affecting future spacecraft designs. A mathematical model was used to predict the rate at which such a belt might form. Under certain conditions the belt could begin to form within this century and could be a significant problem during the next century. The possibility that numerous unobserved fragments already exist from spacecraft explosions would decrease this time interval. However, early implementation of specialized launch constraints and operational procedures could significantly delay the formation of the belt.},
    year = {1978}
}

@Article{Ren2020,
    author = {Ren, Xiaoyuan
and Jiang, Libing
and Wang, Zhuang},
    title = {Pose Estimation of Uncooperative Unknown Space Objects from a Single Image},
    journal = {International Journal of Aerospace Engineering},
    year = {2020},
    month = {Jul},
    day = {18},
    publisher = {Hindawi},
    volume = {2020},
    pages = {9966311},
    abstract = {Estimating the 3D pose of the space object from a single image is an important but challenging work. Most of the existing methods estimate the 3D pose of known space objects and assume that the detailed geometry of a specific object is known. These methods are not available for unknown objects without the known geometry of the object. In contrast to previous works, this paper devotes to estimate the 3D pose of the unknown space object from a single image. Our method estimates not only the pose but also the shape of the unknown object from a single image. In this paper, a hierarchical shape model is proposed to represent the prior structure information of typical space objects. On this basis, the parameters of the pose and shape are estimated simultaneously for unknown space objects. Experimental results demonstrate the effectiveness of our method to estimate the 3D pose and infer the geometry of unknown typical space objects from a single image. Moreover, experimental results show the advantage of our approach over the methods relying on the known geometry of the object.},
    issn = {1687-5966},
    doi = {10.1155/2020/9966311},
    url = {https://doi.org/10.1155/2020/9966311}
}


@article{doi:10.1177/0954410021996129,
    author = {Seongmin Lim and Jin-Hyung Kim and Hae-Dong Kim},
    title = {Strategy for on-orbit space object classification using deep learning},
    journal = {Proceedings of the Institution of Mechanical Engineers, Part G: Journal of Aerospace Engineering},
    volume = {235},
    number = {15},
    pages = {2326-2341},
    year = {2021},
    doi = {10.1177/0954410021996129},
    URL = {https://doi.org/10.1177/0954410021996129},
    eprint = {https://doi.org/10.1177/0954410021996129},
    abstract = { Since nanosatellites are spotlighted as a verification platform for space technology, new studies on on-orbit satellite servicing using nanosatellites are being conducted. This servicing is based on space robotics using vision-based sensors in the rendezvous state with a target satellite. The space environment, such as sunlight and Earth albedo, affects the mission. Simulation of the space environment on the ground is difficult, but the development of robust algorithms which reflect the effect is essential. In particular, missions such as active debris removal require a method for overcoming changes in any known information due to external factors such as collisions. This study proposes a new strategy on nanosatellite for on-orbit space object classification by applying deep learning to sensor-based orbit satellite service activity. When previously known information is changed, a method of online learning on orbit after obtaining additional data at a short relative distance can help determine the final service part. Using the images and point cloud data that simulate the space environment, we apply a convolutional neural network and PointNet to classify the objects. The learning environment is studied using a general desktop and a micro-graphics processing unit (GPU) board that can be mounted on a nanosatellite. For the training, we used self-produced data using 3D models of nanosatellites and asteroids with similar shapes, which are difficult to distinguish with existing algorithms. Consequently, the proposed strategy by the author shows feasibility of using nanosatellite’s micro GPU for on-orbit space object classification, and it is verified that point cloud–based methods are more suitable by utilizing deep learning for nanosatellites. The proposed method with processor of nanosatellite is applicable to satellite service missions in orbit, such as capturing of robotic parts for extending life span or removing space debris. }
}
"Ted IR. IRAS-A-FPA-3-RDR-IMPS-V6.0. , ."

@INPROCEEDINGS{8009786,
    author = {Zeng, Haoyue and Xia, Yong},
    booktitle = {2017 20th International Conference on Information Fusion (Fusion)},
    title = {Space target recognition based on deep learning},
    year = {2017},
    volume = {},
    number = {},
    pages = {1-5},
    doi = {10.23919/ICIF.2017.8009786} }

@inproceedings{Afshar2020,
    author = {Afshar,R. and Chu,Z. and Lu,S.},
    editor = {},
    year = {2020},
    title = {Simultaneous space object recognition and pose estimation by convolutional neural network},
    booktitle = {Proceedings of International Conference on Artificial Life and Robotics},
    volume = {2020},
    pages = {490-495},
    language = {English},
    url = {[www.scopus.com](http://www.scopus.com)},
}

@Article{Takahashi2014,
     author = {Takahashi, Yu and Scheeres, D. J.},
     title = {Small body surface gravity fields via spherical harmonic expansions},
     journal = {Celestial Mechanics and Dynamical Astronomy},
     year = {2014},
     month = {Jun},
     day = {01},
     volume = {119},
     number = {2},
     pages = {169-206},
     abstract = {Conventional gravity field expressions are derived from Laplace's equation, the result being the spherical harmonic gravity field. This gravity field is said to be the exterior spherical harmonic gravity field, as its convergence region is outside the Brillouin (i.e., circumscribing) sphere of the body. In contrast, there exists its counterpart called the interior spherical harmonic gravity field for which the convergence region lies within the interior Brillouin sphere that is not the same as the exterior Brillouin sphere. Thus, the exterior spherical harmonic gravity field cannot model the gravitation within the exterior Brillouin sphere except in some special cases, and the interior spherical harmonic gravity field cannot model the gravitation outside the interior Brillouin sphere. In this paper, we will discuss two types of other spherical harmonic gravity fields that bridge the null space of the exterior/interior gravity field expressions by solving Poisson's equation. These two gravity fields are obtained by assuming the form of Helmholtz's equation to Poisson's equation. This method renders the gravitational potentials as functions of spherical Bessel functions and spherical harmonic coefficients. We refer to these gravity fields as the interior/exterior spherical Bessel gravity fields and study their characteristics. The interior spherical Bessel gravity field is investigated in detail for proximity operation purposes around small primitive bodies. Particularly, we apply the theory to asteroids Bennu (formerly 1999 RQ36) and Castalia to quantify its performance around both nearly spheroidal and contact-binary asteroids, respectively. Furthermore, comparisons between the exterior gravity field, interior gravity field, interior spherical Bessel gravity field, and polyhedral gravity field are made and recommendations are given in order to aid planning of proximity operations for future small body missions.},
     issn = {1572-9478},
     doi = {10.1007/s10569-014-9552-9},
     url = {https://doi.org/10.1007/s10569-014-9552-9}
}

@misc{carruba2022machine,
      title={Machine Learning applied to asteroid dynamics: an emerging research field},
      author={V. Carruba and S. Aljbaae and R. C. Domingos and M. Huaman and W. Barletta},
      year={2022},
      eprint={2110.06611},
      archivePrefix={arXiv},
      primaryClass={astro-ph.EP}
}

@article{Izzo2021,
   abstract = {We present a novel approach based on artificial neural networks, so-called geodesyNets, and present compelling evidence of their ability to serve as accurate geodetic models of highly irregular bodies using minimal prior information on the body. The approach does not rely on the body shape information but, if available, can harness it. GeodesyNets learn a three-dimensional, differentiable, function representing the body density, which we call neural density field. The body shape, as well as other geodetic properties, can easily be recovered. We investigate six different shapes including the bodies 101955 Bennu, 67P Churyumov-Gerasimenko, 433 Eros and 25143 Itokawa for which shape models developed during close proximity surveys are available. Both heterogeneous and homogeneous mass distributions are considered. The gravitational acceleration computed from the trained geodesyNets models, as well as the inferred body shape, show great accuracy in all cases with a relative error on the predicted acceleration smaller than 1\% even close to the asteroid surface. When the body shape information is available, geodesyNets can seamlessly exploit it and be trained to represent a high-fidelity neural density field able to give insights into the internal structure of the body. This work introduces a new unexplored approach to geodesy, adding a powerful tool to consolidated ones based on spherical harmonics, mascon models and polyhedral gravity.},
   author = {Dario Izzo and Pablo Gómez},
   month = {5},
   title = {Geodesy of irregular small bodies via neural density fields: geodesyNets},
   url = {http://arxiv.org/abs/2105.13031},
   year = {2021},
}
